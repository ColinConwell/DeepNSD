"model_string","model","train_task","train_data","architecture","model_class","model_depth","display_name","description","total_feature_count","total_parameter_count","metric","score","compare_training","compare_architecture","compare_goal_slip","compare_goal_taskonomy_tasks","compare_goal_taskonomy_cluster","compare_goal_expertise","compare_diet_ipcl","compare_goal_selfsupervised","compare_goal_contrastive","compare_diet_imagenetsize"
"mobilenetv3_large_100_random","mobilenetv3_large_100","random",NA,"mobilenetv3_large_100","Convolutional",265,"MobileNet-V3-Large","MobileNet-V3-Large randomly initialized, with no training.",20046944,5483032,"crsa",0.0092489510687265,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"inception_v3_random","inception_v3","random",NA,"inception_v3","Convolutional",300,"Inception-V3","Inception-V3 randomly initialized, with no training.",15467136,23834568,"crsa",0.0163388506084938,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"convmixer_768_32_random","convmixer_768_32","random",NA,"convmixer_768_32","Hybrid",232,"ConvMixer-768-32","ConvMixer-768-32 randomly initialized, with no training.",178524368,21110248,"crsa",0.0170526739869458,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"dla34_random","dla34","random",NA,"dla34","Convolutional",151,"DLA34","DLA34 randomly initialized, with no training.",17578680,15742104,"crsa",0.017972850515147,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"hardcorenas_f_random","hardcorenas_f","random",NA,"hardcorenas_f","Convolutional",326,"HardCoreNAS-F","HardCoreNAS-F randomly initialized, with no training.",25099520,8199688,"crsa",0.0238783535503122,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"xcit_nano_12_p16_224_random","xcit_nano_12_p16_224","random",NA,"xcit_nano_12_p16_224","Transformer",NA,"XCIT-N-12-P16","XCIT-N-12-P16 randomly initialized, with no training.",NA,NA,"crsa",0.0263711998049711,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"hardcorenas_a_random","hardcorenas_a","random",NA,"hardcorenas_a","Convolutional",204,"HardCoreNAS-A","HardCoreNAS-A randomly initialized, with no training.",19698736,5260232,"crsa",0.0284509383735605,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"levit_128_random","levit_128","random",NA,"levit_128","Transformer",NA,"LeViT128","LeViT128 randomly initialized, with no training.",NA,NA,"crsa",0.0316217223493079,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"semnasnet_100_random","semnasnet_100","random",NA,"semnasnet_100","Convolutional",274,"SemNASNet100","SemNASNet100 randomly initialized, with no training.",27843180,3887038,"crsa",0.0324356048782161,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"resnet101_random","resnet101","random",NA,"resnet101","Convolutional",345,"ResNet101","ResNet101 randomly initialized, with no training.",56326608,44549160,"crsa",0.0326738621175726,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"resnet152_random","resnet152","random",NA,"resnet152","Convolutional",515,"ResNet152","ResNet152 randomly initialized, with no training.",79507920,60192808,"crsa",0.0354355937470488,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"random_weights_taskonomy","random_weights","taskonomy",NA,"resnet50","Convolutional",179,"Random Weights","Taskonomy architecture randomly initialized.",37564576,23655504,"crsa",0.0366683742114687,NA,NA,NA,"random_weights","Random",NA,NA,NA,NA,NA
"ghostnet_100_random","ghostnet_100","random",NA,"ghostnet_100","Convolutional",287,"GhostNet100","GhostNet100 randomly initialized, with no training.",13446920,5182508,"crsa",0.0370784391643127,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"xcit_nano_12_p8_224_random","xcit_nano_12_p8_224","random",NA,"xcit_nano_12_p8_224","Transformer",NA,"XCIT-N-12-P8","XCIT-N-12-P8 randomly initialized, with no training.",NA,NA,"crsa",0.0377491098194409,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"regnetx_064_random","regnetx_064","random",NA,"regnetx_064","Convolutional",373,"RegNetX-64","RegNetX-64 randomly initialized, with no training.",101428288,26209256,"crsa",0.0391958974096433,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"alexnet_random","alexnet","random",NA,"alexnet","Convolutional",22,"AlexNet","AlexNet randomly initialized, with no training.",1099216,61100840,"crsa",0.0393059297407748,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"resnet50_random","resnet50","random",NA,"resnet50","Convolutional",175,"ResNet50","ResNet50 randomly initialized, with no training.",37560784,25557032,"crsa",0.03939422286886,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"vgg16_random","vgg16","random",NA,"vgg16","Convolutional",40,"VGG16","VGG16 randomly initialized, with no training.",28677072,138357544,"crsa",0.0395677042402297,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"shufflenet_v2_x1_0_random","shufflenet_v2_x1_0","random",NA,"shufflenet_v2_x1_0","Convolutional",168,"ShuffleNet-V2-x1.0","ShuffleNet-V2-x1.0 randomly initialized, with no training.",6284192,2278604,"crsa",0.0405461169908239,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"cspresnet50_random","cspresnet50","random",NA,"cspresnet50","Convolutional",329,"CSP-ResNet50","CSP-ResNet50 randomly initialized, with no training.",51186592,21616168,"crsa",0.0407835686810568,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"mobilenet_v2_random","mobilenet_v2","random",NA,"mobilenet_v2","Convolutional",159,"MobileNet-V2","MobileNet-V2 randomly initialized, with no training.",20037616,3504872,"crsa",0.0433733266514322,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"skresnext50_32x4d_random","skresnext50_32x4d","random",NA,"skresnext50_32x4d","Convolutional",497,"SKResNext50-32x4D","SKResNext50-32x4D randomly initialized, with no training.",99238128,27479784,"crsa",0.0435352188400316,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"resnet18_random","resnet18","random",NA,"resnet18","Convolutional",69,"ResNet18","ResNet18 randomly initialized, with no training.",8231376,11689512,"crsa",0.0443841450982446,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"pit_ti_224_random","pit_ti_224","random",NA,"pit_ti_224","Transformer",236,"PiT-T-224","PiT-T-224 randomly initialized, with no training.",11698296,4800552,"crsa",0.0455926446336989,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"efficientnet_b1_random","efficientnet_b1","random",NA,"efficientnet_b1","Convolutional",435,"EfficientNet-B1","EfficientNet-B1 randomly initialized, with no training.",42450128,7794184,"crsa",0.0485452543198814,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"seresnext50_32x4d_random","seresnext50_32x4d","random",NA,"seresnext50_32x4d","Convolutional",305,"SEResNext50-32x4D","SEResNext50-32x4D randomly initialized, with no training.",58496224,27559896,"crsa",0.049269782244452,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"vit_base_patch16_224_random","vit_base_patch16_224","random",NA,"vit_base_patch16_224","Transformer",225,"ViT-B-P16","ViT-B-P16 randomly initialized, with no training.",57181664,86415592,"crsa",0.0506194007793982,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"vit_large_patch16_224_random","vit_large_patch16_224","random",NA,"vit_large_patch16_224","Transformer",441,"ViT-L-P16","ViT-L-P16 randomly initialized, with no training.",151473488,304123880,"crsa",0.0519490638911131,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"regnety_064_random","regnety_064","random",NA,"regnety_064","Convolutional",658,"RegNetY-64","RegNetY-64 randomly initialized, with no training.",103013924,30583252,"crsa",0.0521213467053496,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"vit_base_patch32_224_random","vit_base_patch32_224","random",NA,"vit_base_patch32_224","Transformer",225,"ViT-B-P32","ViT-B-P32 randomly initialized, with no training.",13455632,88185064,"crsa",0.0523047757291328,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"jx_nest_tiny_random","jx_nest_tiny","random",NA,"jx_nest_tiny","Transformer",213,"JX-NesT-Tiny","JX-NesT-Tiny randomly initialized, with no training.",52424528,16530760,"crsa",0.0525605904987183,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"crossvit_base_240_random","crossvit_base_240","random",NA,"crossvit_base_240","Transformer",383,"CrossViT-B","CrossViT-B randomly initialized, with no training.",80095620,104718800,"crsa",0.0532017504662578,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"convit_base_random","convit_base","random",NA,"convit_base","Hybrid",219,"ConViT-B","ConViT-B randomly initialized, with no training.",61295088,86388584,"crsa",0.0532574336407786,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"visformer_small_random","visformer_small","random",NA,"visformer_small","Transformer",226,"Visformer","Visformer randomly initialized, with no training.",31879784,39956168,"crsa",0.0533708803416315,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"deit_base_patch16_224_random","deit_base_patch16_224","random",NA,"deit_base_patch16_224","Transformer",225,"DeiT-B-P16-224","DeiT-B-P16-224 randomly initialized, with no training.",57181664,86415592,"crsa",0.0545362985766866,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"resmlp_12_224_random","resmlp_12_224","random",NA,"resmlp_12_224","MLP-Mixer",150,"ResMLP-12","ResMLP-12 randomly initialized, with no training.",19269584,15322456,"crsa",0.0552525635097467,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"googlenet_random","googlenet","random",NA,"googlenet","Convolutional",197,"GoogleNet","GoogleNet randomly initialized, with no training.",12335584,6624904,"crsa",0.0564195073398748,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"densenet121_random","densenet121","random",NA,"densenet121","Convolutional",429,"DenseNet121","DenseNet121 randomly initialized, with no training.",41096144,7978856,"crsa",0.0566887004807191,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"poolformer_s36_random","poolformer_s36","random",NA,"poolformer_s36","Transformer",483,"PoolFormer-S36","PoolFormer-S36 randomly initialized, with no training.",78339280,30842792,"crsa",0.0574040880844803,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"resmlp_big_24_224_random","resmlp_big_24_224","random",NA,"resmlp_big_24_224","MLP-Mixer",294,"ResMLP-Big-24","ResMLP-Big-24 randomly initialized, with no training.",305874896,129026152,"crsa",0.0580344527462001,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"resmlp_24_224_random","resmlp_24_224","random",NA,"resmlp_24_224","MLP-Mixer",294,"ResMLP-24","ResMLP-24 randomly initialized, with no training.",38236112,29964616,"crsa",0.0586939909081681,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"resmlp_36_224_random","resmlp_36_224","random",NA,"resmlp_36_224","MLP-Mixer",438,"ResMLP-36","ResMLP-36 randomly initialized, with no training.",57202640,44606776,"crsa",0.0589731723077557,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"keypoints2d_taskonomy","keypoints2d","taskonomy","taskonomy","resnet50","Convolutional",179,"2D Keypoints","Keypoint estimation from RGB-only (texture features).",37564576,23655504,"crsa",0.0596281879803069,NA,NA,NA,"keypoints2d","2D",NA,NA,NA,NA,NA
"vit_tiny_patch16_224_random","vit_tiny_patch16_224","random",NA,"vit_tiny_patch16_224","Transformer",225,"ViT-T-P16","ViT-T-P16 randomly initialized, with no training.",14296916,5679400,"crsa",0.0607946342274088,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"denoising_taskonomy","denoising","taskonomy","taskonomy","resnet50","Convolutional",179,"Denoising","Uncorrupted version of corrupted image.",37564576,23655504,"crsa",0.0614605195964906,NA,NA,NA,"denoising","Other",NA,NA,NA,NA,NA
"jigsaw_taskonomy","jigsaw","taskonomy","taskonomy","resnet50","Convolutional",179,"Jigsaw","Putting scrambled image pieces back together.",37564576,23655504,"crsa",0.0620318807403845,NA,NA,NA,"jigsaw","Geometric",NA,NA,NA,NA,NA
"xception_random","xception","random",NA,"xception","Convolutional",204,"XCeption","XCeption randomly initialized, with no training.",52151632,22855952,"crsa",0.0630226772371374,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"edge_texture_taskonomy","edge_texture","taskonomy","taskonomy","resnet50","Convolutional",179,"Texture Edges","Edges computed from RGB only (texture edges).",37564576,23655504,"crsa",0.0632708948734457,NA,NA,NA,"edge_texture","2D",NA,NA,NA,NA,NA
"swin_large_patch4_window7_224_random","swin_large_patch4_window7_224","random",NA,"swin_large_patch4_window7_224","Transformer",NA,"Swin-L-P4-W7","Swin-L-P4-W7 randomly initialized, with no training.",NA,NA,"crsa",0.0636480882278038,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"gmlp_s16_224_random","gmlp_s16_224","random",NA,"gmlp_s16_224","Convolutional",366,"GMLP-S16","GMLP-S16 randomly initialized, with no training.",49876944,19422656,"crsa",0.0646245104712275,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"mnasnet1_0_random","mnasnet1_0","random",NA,"mnasnet1_0","Convolutional",158,"MNASNet1.0","MNASNet1.0 randomly initialized, with no training.",16172496,4383312,"crsa",0.0653426626922753,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"eca_nfnet_l0_random","eca_nfnet_l0","random",NA,"eca_nfnet_l0","Convolutional",184,"ECA-NFNeT-L0","ECA-NFNeT-L0 randomly initialized, with no training.",32555168,24111108,"crsa",0.0670492621045515,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"coat_lite_tiny_random","coat_lite_tiny","random",NA,"coat_lite_tiny","Transformer",279,"CoaT-Lite-Tiny","CoaT-Lite-Tiny randomly initialized, with no training.",36283152,5878632,"crsa",0.0673297713485153,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"vit_small_patch32_224_random","vit_small_patch32_224","random",NA,"vit_small_patch32_224","Transformer",225,"ViT-S-P32","ViT-S-P32 randomly initialized, with no training.",6728816,22859368,"crsa",0.0675088435305148,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"pit_b_224_random","pit_b_224","random",NA,"pit_b_224","Transformer",254,"PiT-B-224","PiT-B-224 randomly initialized, with no training.",66195824,73518568,"crsa",0.0679405818943177,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"convit_tiny_random","convit_tiny","random",NA,"convit_tiny","Hybrid",219,"ConViT-T","ConViT-T randomly initialized, with no training.",15325272,5672648,"crsa",0.0687689140852061,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"vit_small_patch16_224_random","vit_small_patch16_224","random",NA,"vit_small_patch16_224","Transformer",225,"ViT-S-P16","ViT-S-P16 randomly initialized, with no training.",28591832,21974632,"crsa",0.0688983402541362,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"mixer_b16_224_random","mixer_b16_224","random",NA,"mixer_b16_224","MLP-Mixer",210,"MLP-Mixer-B16","MLP-Mixer-B16 randomly initialized, with no training.",52766672,59880472,"crsa",0.0693588336528996,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"squeezenet1_0_random","squeezenet1_0","random",NA,"squeezenet1_0","Convolutional",66,"SqueezeNet1.0","SqueezeNet1.0 randomly initialized, with no training.",12033376,1248424,"crsa",0.0706880866805416,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"swin_base_patch4_window7_224_random","swin_base_patch4_window7_224","random",NA,"swin_base_patch4_window7_224","Transformer",NA,"Swin-B-P4-W7","Swin-B-P4-W7 randomly initialized, with no training.",NA,NA,"crsa",0.0710217708491109,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"mixer_l16_224_random","mixer_l16_224","random",NA,"mixer_l16_224","MLP-Mixer",414,"MLP-Mixer-L16","MLP-Mixer-L16 randomly initialized, with no training.",149342160,208196168,"crsa",0.0720664532952614,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"convnext_base_random","convnext_base","random",NA,"convnext_base","Convolutional",382,"ConvNext-B","ConvNext-B randomly initialized, with no training.",91729872,88573416,"crsa",0.0722350925578655,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"gmixer_24_224_random","gmixer_24_224","random",NA,"gmixer_24_224","Convolutional",414,"GMixer-24","GMixer-24 randomly initialized, with no training.",41701328,24721096,"crsa",0.0731319883822192,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"convnext_large_random","convnext_large","random",NA,"convnext_large","Convolutional",382,"ConvNext-L","ConvNext-L randomly initialized, with no training.",137593808,197740264,"crsa",0.0735227676567837,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"tnt_s_patch16_224_random","tnt_s_patch16_224","random",NA,"tnt_s_patch16_224","Transformer",NA,"TnT-P16-224","TnT-P16-224 randomly initialized, with no training.",NA,NA,"crsa",0.0736280721806586,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"swin_tiny_patch4_window7_224_random","swin_tiny_patch4_window7_224","random",NA,"swin_tiny_patch4_window7_224","Transformer",NA,"Swin-T-P4-W7","Swin-T-P4-W7 randomly initialized, with no training.",NA,NA,"crsa",0.0742393565845669,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"autoencoding_taskonomy","autoencoding","taskonomy","taskonomy","resnet50","Convolutional",179,"Autoencoder","Image compression and decompression",37564576,23655504,"crsa",0.0766794642651252,NA,NA,NA,"autoencoding","2D",NA,NA,NA,NA,NA
"efficientnet_b3_random","efficientnet_b3","random",NA,"efficientnet_b3","Convolutional",492,"EfficientNet-B3","EfficientNet-B3 randomly initialized, with no training.",59058840,12233232,"crsa",0.0776257054185951,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"nfnet_l0_random","nfnet_l0","random",NA,"nfnet_l0","Convolutional",220,"NF-Net-L0","NF-Net-L0 randomly initialized, with no training.",32566496,35041672,"crsa",0.07988541093869,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"segment_unsup2d_taskonomy","segment_unsup2d","taskonomy","taskonomy","resnet50","Convolutional",179,"Unsupervised 2D Segmentation","Segmentation (graph cut approximation) on RGB.",37564576,23655504,"crsa",0.0808930437044785,NA,NA,NA,"segment_unsup2d","2D",NA,NA,NA,NA,NA
"nf_resnet50_random","nf_resnet50","random",NA,"nf_resnet50","Convolutional",151,"NF-ResNet50","NF-ResNet50 randomly initialized, with no training.",33527712,25530472,"crsa",0.0833226902598482,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"egomotion_taskonomy","egomotion","taskonomy","taskonomy","resnet50","Convolutional",179,"Egomotion","Odometry (camera poses) given three input images.",37564576,23655504,"crsa",0.0873840345132015,NA,NA,NA,"egomotion","Geometric",NA,NA,NA,NA,NA
"vanishing_point_taskonomy","vanishing_point","taskonomy","taskonomy","resnet50","Convolutional",179,"Vanishing Point","Three Manhattan-world vanishing points.",37564576,23655504,"crsa",0.0876787668773507,NA,NA,NA,"vanishing_point","Geometric",NA,NA,NA,NA,NA
"point_matching_taskonomy","point_matching","taskonomy","taskonomy","resnet50","Convolutional",179,"Point Matching","Classifying if centers of two images match or not.",37564576,23655504,"crsa",0.0934367868662969,NA,NA,NA,"point_matching","Geometric",NA,NA,NA,NA,NA
"nonfixated_pose_taskonomy","nonfixated_pose","taskonomy","taskonomy","resnet50","Convolutional",179,"Camera Pose (Nonfixated)","Relative camera pose with distinct optical centers.",37564576,23655504,"crsa",0.0949840851927135,NA,NA,NA,"nonfixated_pose","Geometric",NA,NA,NA,NA,NA
"inpainting_taskonomy","inpainting","taskonomy","taskonomy","resnet50","Convolutional",179,"Inpainting","Filling in masked center of image.",37564576,23655504,"crsa",0.095016333714225,NA,NA,NA,"inpainting","2D",NA,NA,NA,NA,NA
"fixated_pose_taskonomy","fixated_pose","taskonomy","taskonomy","resnet50","Convolutional",179,"Camera Pose (Fixated)","Relative camera pose with matching optical centers.",37564576,23655504,"crsa",0.0989262328214812,NA,NA,NA,"fixated_pose","Geometric",NA,NA,NA,NA,NA
"alexnet_gn_ipcl_vggface2_ipcl","alexnet_gn_ipcl_vggface2","ipcl","vggface2","alexnet_gn","Convolutional",NA,"AlexNet-GN-IPCLVGGFace2","AlexNet (modified with GroupNorm) trained via IPCL-Style-Self-Supervision on VGGFace2.",NA,NA,"crsa",0.101014602354822,NA,NA,NA,NA,NA,NA,"vggface2",NA,NA,NA
"depth_zbuffer_taskonomy","depth_zbuffer","taskonomy","taskonomy","resnet50","Convolutional",179,"Z-Buffer Depth","Depth estimation.",37564576,23655504,"crsa",0.131795050245562,NA,NA,NA,"depth_zbuffer","3D",NA,NA,NA,NA,NA
"curvature_taskonomy","curvature","taskonomy","taskonomy","resnet50","Convolutional",179,"Curvatures","Magnitude of 3D principal curvatures",37564576,23655504,"crsa",0.131913838120402,NA,NA,NA,"curvature","3D",NA,NA,NA,NA,NA
"room_layout_taskonomy","room_layout","taskonomy","taskonomy","resnet50","Convolutional",179,"Room Layout","Orientation and aspect ratio of cubic room layout.",37564576,23655504,"crsa",0.137072420129858,NA,NA,NA,"room_layout","Geometric",NA,NA,NA,NA,NA
"segment_semantic_taskonomy","segment_semantic","taskonomy","taskonomy","resnet50","Convolutional",179,"Semantic Segmentation","Pixel-wise semantic labeling (via knowledge distillation from MS COCO).",37564576,23655504,"crsa",0.1442811263009,NA,NA,NA,"segment_semantic","Semantic",NA,NA,NA,NA,NA
"class_scene_taskonomy","class_scene","taskonomy","taskonomy","resnet50","Convolutional",179,"Scene Classification","Scene Classification (via knowledge distillation from MIT Places).",37564576,23655504,"crsa",0.146553658871821,NA,NA,NA,"class_scene","Semantic",NA,NA,NA,NA,NA
"normal_taskonomy","normal","taskonomy","taskonomy","resnet50","Convolutional",179,"Surface Normals","Pixel-wise surface normals.",37564576,23655504,"crsa",0.153572558260563,NA,NA,NA,"normal","3D",NA,NA,NA,NA,NA
"reshading_taskonomy","reshading","taskonomy","taskonomy","resnet50","Convolutional",179,"Reshading","Reshading with new lighting placed at camera location.",37564576,23655504,"crsa",0.161052275206381,NA,NA,NA,"reshading","3D",NA,NA,NA,NA,NA
"edge_occlusion_taskonomy","edge_occlusion","taskonomy","taskonomy","resnet50","Convolutional",179,"Occlusion Edges","Edges which include parts of the scene.",37564576,23655504,"crsa",0.161763541809486,NA,NA,NA,"edge_occlusion","3D",NA,NA,NA,NA,NA
"keypoints3d_taskonomy","keypoints3d","taskonomy","taskonomy","resnet50","Convolutional",179,"3D Keypoints","3D Keypoint estimation from underlying scene 3D.",37564576,23655504,"crsa",0.16487126634867,NA,NA,NA,"keypoints3d","3D",NA,NA,NA,NA,NA
"segment_unsup25d_taskonomy","segment_unsup25d","taskonomy","taskonomy","resnet50","Convolutional",179,"Unsupervised 2.5D Segmentation","Segmentation (graph cut approximation) on RGB-D-Normals-Curvature image.",37564576,23655504,"crsa",0.17107190357517,NA,NA,NA,"segment_unsup25d","3D",NA,NA,NA,NA,NA
"depth_euclidean_taskonomy","depth_euclidean","taskonomy","taskonomy","resnet50","Convolutional",179,"Euclidean Depth","Depth estimation",37564576,23655504,"crsa",0.173323359615137,NA,NA,NA,"depth_euclidean","3D",NA,NA,NA,NA,NA
"class_object_taskonomy","class_object","taskonomy","taskonomy","resnet50","Convolutional",179,"Object Classification","1000-way object classification (via knowledge distillation from ImageNet).",37564576,23655504,"crsa",0.18923916050676,NA,NA,NA,"class_object","Semantic",NA,NA,NA,NA,NA
"MiDaS_monoculardepth","MiDaS","monoculardepth","ReDWeb,DIML,Movies,MegaDepth,WSVD,TartanAir,HRWSI,ApolloScape,BlendedMVS,IRS","MiDaS",NA,NA,"MiDaS","MiDaS, a monocular depth estimation model.",NA,NA,"crsa",0.199641580142373,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"mixer_l16_224_in21k_classification","mixer_l16_224_in21k","classification","imagenet21k","mixer_l16_224","MLP-Mixer",414,"Mixer-L16-IN22K","Mixer-L16-IN22K trained on image classification with the ImageNet21K dataset.",149383846,229560243,"crsa",0.234487758898889,NA,NA,NA,NA,NA,NA,NA,NA,NA,"imagenet21k"
"ResNet50-RotNet_selfsupervised","ResNet50-RotNet","selfsupervised","imagenet","ResNet50","Convolutional",175,"ResNet50-RotNet","ResNet50-RotNet, a self-supervised representation learner trained on ImageNet.",37562880,23508032,"crsa",0.238128720893577,NA,NA,NA,NA,NA,NA,NA,"RotNet","Non-Contrastive",NA
"alexnet_gn_ipcl_places256_ipcl","alexnet_gn_ipcl_places256","ipcl","places256","alexnet_gn","Convolutional",NA,"AlexNet-GN-IPCLPlaces256","AlexNet (modified with GroupNorm) trained via IPCL-Style-Self-Supervision on Places256.",NA,NA,"crsa",0.241788782168068,NA,NA,NA,NA,NA,NA,"places256",NA,NA,NA
"convnext_large_classification","convnext_large","classification","imagenet","convnext_large","Convolutional",382,"ConvNext-L","ConvNext-L trained on image classification with the ImageNet dataset.",137593808,197740264,"crsa",0.243149109916857,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,"imagenet"
"alexnet_gn_ipcl_openimages_ipcl","alexnet_gn_ipcl_openimages","ipcl","openimages","alexnet_gn","Convolutional",NA,"AlexNet-GN-IPCLOpenImages","AlexNet (modified with GroupNorm) trained via IPCL-Style-Self-Supervision on OpenImages.",NA,NA,"crsa",0.249447991311561,NA,NA,NA,NA,NA,NA,"openimages",NA,NA,NA
"ResNet50-JigSaw-Goyal19_selfsupervised","ResNet50-JigSaw-Goyal19","selfsupervised","imagenet","ResNet50","Convolutional",175,"ResNet50-JigSaw-Goyal19","ResNet50-JigSaw-Goyal19, a self-supervised representation learner trained on ImageNet.",37562880,23508032,"crsa",0.256946126486895,NA,NA,NA,NA,NA,NA,NA,"JigSaw-Goyal19","Non-Contrastive",NA
"DPT_Hybrid_monoculardepth","DPT_Hybrid","monoculardepth","ReDWeb,DIML,Movies,MegaDepth,WSVD,TartanAir,HRWSI,ApolloScape,BlendedMVS,IRS","DPT_Hybrid","Transformer",584,"DPT-Hybrid","DPT-Hybrid, a monocular depth estimation model.",167515152,120753921,"crsa",0.265462834464265,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"ResNet50-MoCoV2-BS256_selfsupervised","ResNet50-MoCoV2-BS256","selfsupervised","imagenet","ResNet50","Convolutional",175,"ResNet50-MoCoV2-BS256","ResNet50-MoCoV2-BS256, a self-supervised representation learner trained on ImageNet.",37562880,23508032,"crsa",0.265504085415745,NA,NA,NA,NA,NA,NA,NA,"MoCoV2-BS256","Contrastive",NA
"ResNet50-JigSaw-P100_selfsupervised","ResNet50-JigSaw-P100","selfsupervised","imagenet","ResNet50","Convolutional",175,"ResNet50-JigSaw-P100","ResNet50-JigSaw-P100, a self-supervised representation learner trained on ImageNet.",37562880,23508032,"crsa",0.266665973391301,NA,NA,NA,NA,NA,NA,NA,"JigSaw-P100","Non-Contrastive",NA
"mixer_b16_224_in21k_classification","mixer_b16_224_in21k","classification","imagenet21k","mixer_b16_224","MLP-Mixer",210,"Mixer-B16-IN22K","Mixer-B16-IN22K trained on image classification with the ImageNet21K dataset.",52808358,75908739,"crsa",0.26864952533446,NA,NA,NA,NA,NA,NA,NA,NA,NA,"imagenet21k"
"pit_b_224_classification","pit_b_224","classification","imagenet","pit_b_224","Transformer",254,"PiT-B-224","PiT-B-224 trained on image classification with the ImageNet dataset.",66195824,73518568,"crsa",0.271826037119732,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,NA
"alexnet_gn_ipcl_imagenet_ipcl","alexnet_gn_ipcl_imagenet","ipcl","imagenet","alexnet_gn","Convolutional",NA,"AlexNet-GN-IPCLImageNet","AlexNet (modified with GroupNorm) trained via IPCL-Style-Self-Supervision on ImageNet.",NA,NA,"crsa",0.272191057577333,NA,NA,NA,NA,NA,NA,"imagenet",NA,NA,NA
"tnt_s_patch16_224_classification","tnt_s_patch16_224","classification","imagenet","tnt_s_patch16_224","Transformer",NA,"TnT-P16-224","TnT-P16-224 trained on image classification with the ImageNet dataset.",NA,NA,"crsa",0.280892948739733,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,NA
"swin_large_patch4_window7_224_classification","swin_large_patch4_window7_224","classification","imagenet","swin_large_patch4_window7_224","Transformer",NA,"Swin-L-P4-W7","Swin-L-P4-W7 trained on image classification with the ImageNet dataset.",NA,NA,"crsa",0.282725557536005,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,"imagenet"
"ViT-L-CLIP-CC12M_slip","ViT-L-CLIP-CC12M","slip","YFCC15M","ViT-L","Transformer",225,"ViT-L-CLIP-CC12M","ViT-L-CLIP-CC12M trained via pure language supervision with the YFCC15M dataset.",57181200,85646592,"crsa",0.283097475470675,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"ViT-L-CLIP_slip","ViT-L-CLIP","slip","YFCC15M","ViT-L","Transformer",441,"ViT-L-CLIP","ViT-L-CLIP trained via pure language supervision with the YFCC15M dataset.",151473536,303098880,"crsa",0.28432126603456,NA,NA,"CLIP",NA,NA,NA,NA,NA,NA,NA
"convit_tiny_classification","convit_tiny","classification","imagenet","convit_tiny","Hybrid",219,"ConViT-T","ConViT-T trained on image classification with the ImageNet dataset.",15325272,5672648,"crsa",0.286469732026108,"classification","Hybrid",NA,NA,NA,NA,NA,NA,NA,NA
"vit_small_patch32_224_in21k_classification","vit_small_patch32_224_in21k","classification","imagenet21k","vit_small_patch32_224","Transformer",225,"ViT-S-P32-IN21K","ViT-S-P32-IN21K trained on image classification with the ImageNet21K dataset.",6770502,30883923,"crsa",0.286559357719256,NA,NA,NA,NA,NA,NA,NA,NA,NA,"imagenet21k"
"ViT-L-SLIP-CC12M_slip","ViT-L-SLIP-CC12M","slip","YFCC15M","ViT-L","Transformer",225,"ViT-L-SLIP-CC12M","ViT-L-SLIP-CC12M trained via combined self- and language supervision with the YFCC15M dataset.",57181200,85646592,"crsa",0.286828273345008,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"vit_small_patch32_224_classification","vit_small_patch32_224","classification","imagenet","vit_small_patch32_224","Transformer",225,"ViT-S-P32","ViT-S-P32 trained on image classification with the ImageNet dataset.",6728816,22859368,"crsa",0.288815811224477,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,"imagenet"
"vit_tiny_patch16_224_classification","vit_tiny_patch16_224","classification","imagenet","vit_tiny_patch16_224","Transformer",225,"ViT-T-P16","ViT-T-P16 trained on image classification with the ImageNet dataset.",14296916,5679400,"crsa",0.292787235092729,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,NA
"ViT-S-CLIP_slip","ViT-S-CLIP","slip","YFCC15M","ViT-S","Transformer",225,"ViT-S-CLIP","ViT-S-CLIP trained via pure language supervision with the YFCC15M dataset.",31384848,21589632,"crsa",0.293342267701608,NA,NA,"CLIP",NA,NA,NA,NA,NA,NA,NA
"ViT-B-CLIP_slip","ViT-B-CLIP","slip","YFCC15M","ViT-B","Transformer",225,"ViT-B-CLIP","ViT-B-CLIP trained via pure language supervision with the YFCC15M dataset.",57181200,85646592,"crsa",0.294206679038478,NA,NA,"CLIP",NA,NA,NA,NA,NA,NA,NA
"swin_base_patch4_window7_224_classification","swin_base_patch4_window7_224","classification","imagenet","swin_base_patch4_window7_224","Transformer",NA,"Swin-B-P4-W7","Swin-B-P4-W7 trained on image classification with the ImageNet dataset.",NA,NA,"crsa",0.296324883667926,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,"imagenet"
"convnext_base_classification","convnext_base","classification","imagenet","convnext_base","Convolutional",382,"ConvNext-B","ConvNext-B trained on image classification with the ImageNet dataset.",91729872,88573416,"crsa",0.298370451706448,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,"imagenet"
"regnetx_064_classification","regnetx_064","classification","imagenet","regnetx_064","Convolutional",373,"RegNetX-64","RegNetX-64 trained on image classification with the ImageNet dataset.",101428288,26209256,"crsa",0.303055881890433,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"vit_large_patch16_224_in21k_classification","vit_large_patch16_224_in21k","classification","imagenet21k","vit_large_patch16_224","Transformer",441,"ViT-L-P16-IN21K","ViT-L-P16-IN21K trained on image classification with the ImageNet21K dataset.",151515174,325487955,"crsa",0.305537491484398,NA,NA,NA,NA,NA,NA,NA,NA,NA,"imagenet21k"
"deit_base_patch16_224_classification","deit_base_patch16_224","classification","imagenet","deit_base_patch16_224","Transformer",225,"DeiT-B-P16-224","DeiT-B-P16-224 trained on image classification with the ImageNet dataset.",57181664,86415592,"crsa",0.309274833725458,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,NA
"vit_small_patch16_224_classification","vit_small_patch16_224","classification","imagenet","vit_small_patch16_224","Transformer",225,"ViT-S-P16","ViT-S-P16 trained on image classification with the ImageNet dataset.",28591832,21974632,"crsa",0.310563242421843,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,"imagenet"
"vit_base_patch16_224_in21k_classification","vit_base_patch16_224_in21k","classification","imagenet21k","vit_base_patch16_224","Transformer",225,"ViT-B-P16-IN21K","ViT-B-P16-IN21K trained on image classification with the ImageNet21K dataset.",57223350,102443859,"crsa",0.312214392129989,NA,NA,NA,NA,NA,NA,NA,NA,NA,"imagenet21k"
"ViT-L/14_clip","ViT-L/14","clip","openai400M","ViT-L/14","Transformer",173,"CLiP-ViT-L/14","CLiP-ViT-L/14, a hybrid vision-language model.",82898688,202153984,"crsa",0.314396265461297,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"crossvit_base_240_classification","crossvit_base_240","classification","imagenet","crossvit_base_240","Transformer",383,"CrossViT-B","CrossViT-B trained on image classification with the ImageNet dataset.",80095620,104718800,"crsa",0.314788230776295,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,NA
"swin_tiny_patch4_window7_224_classification","swin_tiny_patch4_window7_224","classification","imagenet","swin_tiny_patch4_window7_224","Transformer",NA,"Swin-T-P4-W7","Swin-T-P4-W7 trained on image classification with the ImageNet dataset.",NA,NA,"crsa",0.315281594122935,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,NA
"ViT-L-SLIP_slip","ViT-L-SLIP","slip","YFCC15M","ViT-L","Transformer",441,"ViT-L-SLIP","ViT-L-SLIP trained via combined self- and language supervision with the YFCC15M dataset.",151473536,303098880,"crsa",0.315422153636622,NA,NA,"SLIP",NA,NA,NA,NA,NA,NA,NA
"vit_base_patch16_224_classification","vit_base_patch16_224","classification","imagenet","vit_base_patch16_224","Transformer",225,"ViT-B-P16","ViT-B-P16 trained on image classification with the ImageNet dataset.",57181664,86415592,"crsa",0.318719878774665,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,"imagenet"
"vit_small_patch16_224_in21k_classification","vit_small_patch16_224_in21k","classification","imagenet21k","vit_small_patch16_224","Transformer",225,"ViT-S-P16-IN21K","ViT-S-P16-IN21K trained on image classification with the ImageNet21K dataset.",28633518,29999187,"crsa",0.319211953497736,NA,NA,NA,NA,NA,NA,NA,NA,NA,"imagenet21k"
"jx_nest_tiny_classification","jx_nest_tiny","classification","imagenet","jx_nest_tiny","Transformer",213,"JX-NesT-Tiny","JX-NesT-Tiny trained on image classification with the ImageNet dataset.",52424528,16530760,"crsa",0.319318911168437,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,NA
"vit_large_patch16_224_classification","vit_large_patch16_224","classification","imagenet","vit_large_patch16_224","Transformer",441,"ViT-L-P16","ViT-L-P16 trained on image classification with the ImageNet dataset.",151473488,304123880,"crsa",0.31970548199914,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,"imagenet"
"resnet101_classification","resnet101","classification","imagenet","resnet101","Convolutional",345,"ResNet101","ResNet101 trained on image classification with the ImageNet dataset.",56326608,44549160,"crsa",0.321730457432903,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"swin_base_patch4_window7_224_in22k_classification","swin_base_patch4_window7_224_in22k","classification","imagenet21k","swin_base_patch4_window7_224","Transformer",NA,"Swin-B-P4-W7-IN21K","Swin-B-P4-W7-IN21K trained on image classification with the ImageNet21K dataset.",NA,NA,"crsa",0.322634180986898,NA,NA,NA,NA,NA,NA,NA,NA,NA,"imagenet21k"
"squeezenet1_0_classification","squeezenet1_0","classification","imagenet","squeezenet1_0","Convolutional",66,"SqueezeNet1.0","SqueezeNet1.0 trained on image classification with the ImageNet dataset.",12033376,1248424,"crsa",0.322723104551099,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"coat_lite_tiny_classification","coat_lite_tiny","classification","imagenet","coat_lite_tiny","Transformer",279,"CoaT-Lite-Tiny","CoaT-Lite-Tiny trained on image classification with the ImageNet dataset.",36283152,5878632,"crsa",0.322903124063489,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,NA
"swin_large_patch4_window7_224_in22k_classification","swin_large_patch4_window7_224_in22k","classification","imagenet21k","swin_large_patch4_window7_224","Transformer",NA,"Swin-L-P4-W7-IN21K","Swin-L-P4-W7-IN21K trained on image classification with the ImageNet21K dataset.",NA,NA,"crsa",0.324342400438842,NA,NA,NA,NA,NA,NA,NA,NA,NA,"imagenet21k"
"resnet18_classification","resnet18","classification","imagenet","resnet18","Convolutional",69,"ResNet18","ResNet18 trained on image classification with the ImageNet dataset.",8231376,11689512,"crsa",0.324664339591631,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"ResNet50-ClusterFit-16K-RotNet_selfsupervised","ResNet50-ClusterFit-16K-RotNet","selfsupervised","imagenet","ResNet50","Convolutional",175,"ResNet50-ClusterFit-16K-RotNet","ResNet50-ClusterFit-16K-RotNet, a self-supervised representation learner trained on ImageNet.",37562880,23508032,"crsa",0.326249469829857,NA,NA,NA,NA,NA,NA,NA,"ClusterFit-16K-RotNet","Non-Contrastive",NA
"ViT-L-SimCLR_slip","ViT-L-SimCLR","slip","YFCC15M","ViT-L","Transformer",441,"ViT-L-SimCLR","ViT-L-SimCLR trained via pure self-supervision with the YFCC15M dataset.",151473536,303098880,"crsa",0.327152378902608,NA,NA,"SimCLR",NA,NA,NA,NA,NA,NA,NA
"ResNet50-DeepClusterV2-2x224+6x96_selfsupervised","ResNet50-DeepClusterV2-2x224+6x96","selfsupervised","imagenet","ResNet50","Convolutional",175,"ResNet50-DeepClusterV2","ResNet50-DeepClusterV2-2x224+6x96, a self-supervised representation learner trained on ImageNet.",37562880,23508032,"crsa",0.329791786118654,NA,NA,NA,NA,NA,NA,NA,"DeepClusterV2-2x224+6x96","Contrastive",NA
"convnext_base_in22k_classification","convnext_base_in22k","classification","imagenet21k","convnext_base","Convolutional",382,"ConvNext-Base-IN21K","ConvNext-Base-IN21K trained on image classification with the ImageNet21K dataset.",91771554,109935441,"crsa",0.329927807227396,NA,NA,NA,NA,NA,NA,NA,NA,NA,"imagenet21k"
"dino_vitb16_selfsupervised","dino_vitb16","selfsupervised","imagenet","vitb16","Transformer",NA,"Dino-VIT-B16","Dino-VIT-B16 trained via self supervision with the ImageNet dataset.",NA,NA,"crsa",0.330507749181776,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"RegNet-128Gf-SEER_seer","RegNet-128Gf-SEER","seer","random1B","RegNet-128Gf","Convolutional",NA,"RegNet-128Gf-SEER","RegNet-128Gf trained via large-scale self-supervision on 1 billion images.",NA,NA,"crsa",0.330694249834873,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"ViT-S-SLIP_slip","ViT-S-SLIP","slip","YFCC15M","ViT-S","Transformer",225,"ViT-S-SLIP","ViT-S-SLIP trained via combined self- and language supervision with the YFCC15M dataset.",31384848,21589632,"crsa",0.331338539671069,NA,NA,"SLIP",NA,NA,NA,NA,NA,NA,NA
"xception_classification","xception","classification","imagenet","xception","Convolutional",204,"XCeption","XCeption trained on image classification with the ImageNet dataset.",52151632,22855952,"crsa",0.332479620839789,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"RegNet-64Gf-SEER-INFT_seer","RegNet-64Gf-SEER-INFT","seer","random1B","RegNet-64Gf","Convolutional",NA,"RegNet-64Gf-SEER-INFT","RegNet-64Gf trained via large-scale self-supervision on 1 billion images.",NA,NA,"crsa",0.33250550984887,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"BiT-Expert-ResNet-V2-Flower_bit_expert","BiT-Expert-ResNet-V2-Flower","bit_expert","big_transfer","ResNet50-V2","Convolutional",168,"BiT-Expert-ResNet-V2-Flower","ResNet50-V2 trained first via ImageNet21K dataset, then as an expert on the Flower subset.",35578624,23496256,"crsa",0.33381418080141,NA,NA,NA,NA,NA,"Flower",NA,NA,NA,NA
"visformer_small_classification","visformer_small","classification","imagenet","visformer_small","Transformer",226,"Visformer","Visformer trained on image classification with the ImageNet dataset.",31879784,39956168,"crsa",0.334100804761502,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,NA
"vit_base_r50_s16_224_in21k_classification","vit_base_r50_s16_224_in21k","classification","imagenet21k","vit_base_r50_s16_224","Transformer",496,"ViT-B-R50-S16-IN21K","ViT-B-R50-S16-IN21K trained on image classification with the ImageNet21K dataset.",124710838,115125907,"crsa",0.334441067885782,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"ViT-B-SLIP_slip","ViT-B-SLIP","slip","YFCC15M","ViT-B","Transformer",225,"ViT-B-SLIP","ViT-B-SLIP trained via combined self- and language supervision with the YFCC15M dataset.",57181200,85646592,"crsa",0.334595198955539,NA,NA,"SLIP",NA,NA,NA,NA,NA,NA,NA
"ResNet50-SwAV-BS4096-2x224+6x96_selfsupervised","ResNet50-SwAV-BS4096-2x224+6x96","selfsupervised","imagenet","ResNet50","Convolutional",175,"ResNet50-SwAV-BS4096","ResNet50-SwAV-BS4096-2x224+6x96, a self-supervised representation learner trained on ImageNet.",37562880,23508032,"crsa",0.337453781311998,NA,NA,NA,NA,NA,NA,NA,"SwAV-BS4096-2x224+6x96","Contrastive",NA
"alexnet_classification","alexnet","classification","imagenet","alexnet","Convolutional",22,"AlexNet","AlexNet trained on image classification with the ImageNet dataset.",1099216,61100840,"crsa",0.338324954990206,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"ViT-S-SimCLR_slip","ViT-S-SimCLR","slip","YFCC15M","ViT-S","Transformer",225,"ViT-S-SimCLR","ViT-S-SimCLR trained via pure self-supervision with the YFCC15M dataset.",31384848,21589632,"crsa",0.339453470163235,NA,NA,"SimCLR",NA,NA,NA,NA,NA,NA,NA
"ViT-B-SimCLR_slip","ViT-B-SimCLR","slip","YFCC15M","ViT-B","Transformer",225,"ViT-B-SimCLR","ViT-B-SimCLR trained via pure self-supervision with the YFCC15M dataset.",57181200,85646592,"crsa",0.341172802777631,NA,NA,"SimCLR",NA,NA,NA,NA,NA,NA,NA
"RegNet-128Gf-SEER-INFT_seer","RegNet-128Gf-SEER-INFT","seer","random1B","RegNet-128Gf","Convolutional",NA,"RegNet-128Gf-SEER-INFT","RegNet-128Gf trained via large-scale self-supervision on 1 billion images.",NA,NA,"crsa",0.341703498281458,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"vgg16_classification","vgg16","classification","imagenet","vgg16","Convolutional",40,"VGG16","VGG16 trained on image classification with the ImageNet dataset.",28677072,138357544,"crsa",0.341786478691858,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"convmixer_768_32_classification","convmixer_768_32","classification","imagenet","convmixer_768_32","Hybrid",232,"ConvMixer-768-32","ConvMixer-768-32 trained on image classification with the ImageNet dataset.",178524368,21110248,"crsa",0.34240654411404,"classification","Hybrid",NA,NA,NA,NA,NA,NA,NA,NA
"gmixer_24_224_classification","gmixer_24_224","classification","imagenet","gmixer_24_224","Convolutional",414,"GMixer-24","GMixer-24 trained on image classification with the ImageNet dataset.",41701328,24721096,"crsa",0.343638077749623,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"convit_base_classification","convit_base","classification","imagenet","convit_base","Hybrid",219,"ConViT-B","ConViT-B trained on image classification with the ImageNet dataset.",61295088,86388584,"crsa",0.34505962631262,"classification","Hybrid",NA,NA,NA,NA,NA,NA,NA,NA
"RN50_clip","RN50","clip","openai400M","ResNet50","Convolutional",200,"CLiP-ResNet50","CLiP-ResNet50, a hybrid vision-language model.",43479552,23527264,"crsa",0.345875571518963,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"resmlp_36_224_classification","resmlp_36_224","classification","imagenet","resmlp_36_224","MLP-Mixer",438,"ResMLP-36","ResMLP-36 trained on image classification with the ImageNet dataset.",57202640,44606776,"crsa",0.346077192820591,"classification","MLP-Mixer",NA,NA,NA,NA,NA,NA,NA,NA
"BiT-Expert-ResNet-V2-Object_bit_expert","BiT-Expert-ResNet-V2-Object","bit_expert","big_transfer","ResNet50-V2","Convolutional",168,"BiT-Expert-ResNet-V2-Object","ResNet50-V2 trained first via ImageNet21K dataset, then as an expert on the Object subset.",35578624,23496256,"crsa",0.348372138070172,NA,NA,NA,NA,NA,"Object",NA,NA,NA,NA
"BiT-Expert-ResNet-V2-Bird_bit_expert","BiT-Expert-ResNet-V2-Bird","bit_expert","big_transfer","ResNet50-V2","Convolutional",168,"BiT-Expert-ResNet-V2-Bird","ResNet50-V2 trained first via ImageNet21K dataset, then as an expert on the Bird subset.",35578624,23496256,"crsa",0.348665674593437,NA,NA,NA,NA,NA,"Bird",NA,NA,NA,NA
"resnet152_classification","resnet152","classification","imagenet","resnet152","Convolutional",515,"ResNet152","ResNet152 trained on image classification with the ImageNet dataset.",79507920,60192808,"crsa",0.348755843158559,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"mixer_b16_224_classification","mixer_b16_224","classification","imagenet","mixer_b16_224","MLP-Mixer",210,"MLP-Mixer-B16","MLP-Mixer-B16 trained on image classification with the ImageNet dataset.",52766672,59880472,"crsa",0.348874320187685,"classification","MLP-Mixer",NA,NA,NA,NA,NA,NA,NA,"imagenet"
"ViT-B/32_clip","ViT-B/32","clip","openai400M","ViT-B/32","Transformer",89,"CLiP-ViT-B/32","CLiP-ViT-B/32, a hybrid vision-language model.",6106112,59068416,"crsa",0.349047116977608,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"keypoint_rcnn_R_50_FPN_3x_segmentation","keypoint_rcnn_R_50_FPN_3x","segmentation","coco2017","keypoint_rcnn_R_50_FPN_3x","Convolutional",NA,"Keypoint-RCNN-ResNet50-FPN","Keypoint-RCNN-ResNet50-FPN, trained on segmentation with the CoCo2017 dataset.",NA,NA,"crsa",0.349293934695126,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"BiT-Expert-ResNet-V2-Abstraction_bit_expert","BiT-Expert-ResNet-V2-Abstraction","bit_expert","big_transfer","ResNet50-V2","Convolutional",168,"BiT-Expert-ResNet-V2-Abstraction","ResNet50-V2 trained first via ImageNet21K dataset, then as an expert on the Abstraction subset.",35578624,23496256,"crsa",0.349655249718515,NA,NA,NA,NA,NA,"Abstraction",NA,NA,NA,NA
"BiT-Expert-ResNet-V2-Mammal_bit_expert","BiT-Expert-ResNet-V2-Mammal","bit_expert","big_transfer","ResNet50-V2","Convolutional",168,"BiT-Expert-ResNet-V2-Mammal","ResNet50-V2 trained first via ImageNet21K dataset, then as an expert on the Mammal subset.",35578624,23496256,"crsa",0.349801222969057,NA,NA,NA,NA,NA,"Mammal",NA,NA,NA,NA
"BiT-Expert-ResNet-V2-Vehicle_bit_expert","BiT-Expert-ResNet-V2-Vehicle","bit_expert","big_transfer","ResNet50-V2","Convolutional",168,"BiT-Expert-ResNet-V2-Vehicle","ResNet50-V2 trained first via ImageNet21K dataset, then as an expert on the Vehicle subset.",35578624,23496256,"crsa",0.350099594577561,NA,NA,NA,NA,NA,"Vehicle",NA,NA,NA,NA
"yolov5l_yolo","yolov5l","yolo","coco,voc","yolov5l","Convolutional",NA,"YOLO-V5-L","YOLO-V5-L, an object detection model.",NA,NA,"crsa",0.350105683846968,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"ViT-B/16_clip","ViT-B/16","clip","openai400M","ViT-B/16","Transformer",89,"CLiP-ViT-B/32","CLiP-ViT-B/32, a hybrid vision-language model.",24056576,57298944,"crsa",0.350411378306599,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"mixer_l16_224_classification","mixer_l16_224","classification","imagenet","mixer_l16_224","MLP-Mixer",414,"MLP-Mixer-L16","MLP-Mixer-L16 trained on image classification with the ImageNet dataset.",149342160,208196168,"crsa",0.350827997602639,"classification","MLP-Mixer",NA,NA,NA,NA,NA,NA,NA,"imagenet"
"RegNet-64Gf-SEER_seer","RegNet-64Gf-SEER","seer","random1B","RegNet-64Gf","Convolutional",NA,"RegNet-64Gf-SEER","RegNet-64Gf trained via large-scale self-supervision on 1 billion images.",NA,NA,"crsa",0.35123101888529,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"RegNet-32Gf-SEER_seer","RegNet-32Gf-SEER","seer","random1B","RegNet-32Gf","Convolutional",NA,"RegNet-32Gf-SEER","RegNet-32Gf trained via large-scale self-supervision on 1 billion images.",NA,NA,"crsa",0.352421395952412,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"BiT-Expert-ResNet-V2-Instrument_bit_expert","BiT-Expert-ResNet-V2-Instrument","bit_expert","big_transfer","ResNet50-V2","Convolutional",168,"BiT-Expert-ResNet-V2-Instrument","ResNet50-V2 trained first via ImageNet21K dataset, then as an expert on the Instrument subset.",35578624,23496256,"crsa",0.352846419702904,NA,NA,NA,NA,NA,"Instrument",NA,NA,NA,NA
"convnext_large_in22k_classification","convnext_large_in22k","classification","imagenet21k","convnext_large","Convolutional",382,"ConvNext-Large-IN21K","ConvNext-Large-IN21K trained on image classification with the ImageNet21K dataset.",137635490,229772881,"crsa",0.353059432157135,NA,NA,NA,NA,NA,NA,NA,NA,NA,"imagenet21k"
"RN101_clip","RN101","clip","openai400M","ResNet101","Convolutional",387,"CLiP-ResNet101","CLiP-ResNet101, a hybrid vision-language model.",63097344,42519392,"crsa",0.35317309169339,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"ResNet50-PIRL_selfsupervised","ResNet50-PIRL","selfsupervised","imagenet","ResNet50","Convolutional",175,"ResNet50-PIRL","ResNet50-PIRL, a self-supervised representation learner trained on ImageNet.",37562880,23508032,"crsa",0.354787522151078,NA,NA,NA,NA,NA,NA,NA,"PIRL","Contrastive",NA
"skresnext50_32x4d_classification","skresnext50_32x4d","classification","imagenet","skresnext50_32x4d","Convolutional",497,"SKResNext50-32x4D","SKResNext50-32x4D trained on image classification with the ImageNet dataset.",99238128,27479784,"crsa",0.355387632629078,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"BiT-Expert-ResNet-V2-Relation_bit_expert","BiT-Expert-ResNet-V2-Relation","bit_expert","big_transfer","ResNet50-V2","Convolutional",168,"BiT-Expert-ResNet-V2-Relation","ResNet50-V2 trained first via ImageNet21K dataset, then as an expert on the Relation subset.",35578624,23496256,"crsa",0.355761982308024,NA,NA,NA,NA,NA,"Relation",NA,NA,NA,NA
"BiT-Expert-ResNet-V2-Food_bit_expert","BiT-Expert-ResNet-V2-Food","bit_expert","big_transfer","ResNet50-V2","Convolutional",168,"BiT-Expert-ResNet-V2-Food","ResNet50-V2 trained first via ImageNet21K dataset, then as an expert on the Food subset.",35578624,23496256,"crsa",0.355948333116041,NA,NA,NA,NA,NA,"Food",NA,NA,NA,NA
"yolov5s_yolo","yolov5s","yolo","coco,voc","yolov5s","Convolutional",NA,"YOLO-V5-S","YOLO-V5-S, an object detection model.",NA,NA,"crsa",0.356176820136808,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"BiT-Expert-ResNet-V2-Animal_bit_expert","BiT-Expert-ResNet-V2-Animal","bit_expert","big_transfer","ResNet50-V2","Convolutional",168,"BiT-Expert-ResNet-V2-Animal","ResNet50-V2 trained first via ImageNet21K dataset, then as an expert on the Animal subset.",35578624,23496256,"crsa",0.356768240635451,NA,NA,NA,NA,NA,"Animal",NA,NA,NA,NA
"shufflenet_v2_x1_0_classification","shufflenet_v2_x1_0","classification","imagenet","shufflenet_v2_x1_0","Convolutional",168,"ShuffleNet-V2-x1.0","ShuffleNet-V2-x1.0 trained on image classification with the ImageNet dataset.",6284192,2278604,"crsa",0.357103687443078,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"retinanet_R_50_FPN_3x_detection","retinanet_R_50_FPN_3x","detection","coco2017","retinanet_R_50_FPN_3x","Convolutional",NA,"RetinaNet-ResNet50-FPN","RetinaNet-ResNet50-FPN, trained on detection with the CoCo2017 dataset.",NA,NA,"crsa",0.357217188086672,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"mobilenet_v2_classification","mobilenet_v2","classification","imagenet","mobilenet_v2","Convolutional",159,"MobileNet-V2","MobileNet-V2 trained on image classification with the ImageNet dataset.",20037616,3504872,"crsa",0.357820482482453,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"dino_resnet50_selfsupervised","dino_resnet50","selfsupervised","imagenet","resnet50","Convolutional",NA,"Dino-ResNet50","Dino-ResNet50 trained via self supervision with the ImageNet dataset.",NA,NA,"crsa",0.358136871302894,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"dla34_classification","dla34","classification","imagenet","dla34","Convolutional",151,"DLA34","DLA34 trained on image classification with the ImageNet dataset.",17578680,15742104,"crsa",0.358758579261343,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"BiT-Expert-ResNet-V2-Arthropod_bit_expert","BiT-Expert-ResNet-V2-Arthropod","bit_expert","big_transfer","ResNet50-V2","Convolutional",168,"BiT-Expert-ResNet-V2-Arthropod","ResNet50-V2 trained first via ImageNet21K dataset, then as an expert on the Arthropod subset.",35578624,23496256,"crsa",0.36119397481086,NA,NA,NA,NA,NA,"Arthropod",NA,NA,NA,NA
"resmlp_big_24_224_classification","resmlp_big_24_224","classification","imagenet","resmlp_big_24_224","MLP-Mixer",294,"ResMLP-Big-24","ResMLP-Big-24 trained on image classification with the ImageNet dataset.",305874896,129026152,"crsa",0.361541200186061,"classification","MLP-Mixer",NA,NA,NA,NA,NA,NA,NA,"imagenet"
"ResNet50-SimCLR_selfsupervised","ResNet50-SimCLR","selfsupervised","imagenet","ResNet50","Convolutional",175,"ResNet50-SimCLR","ResNet50-SimCLR, a self-supervised representation learner trained on ImageNet.",37562880,23508032,"crsa",0.361619689289492,NA,NA,NA,NA,NA,NA,NA,"SimCLR","Contrastive",NA
"RegNet-32Gf-SEER-INFT_seer","RegNet-32Gf-SEER-INFT","seer","random1B","RegNet-32Gf","Convolutional",NA,"RegNet-32Gf-SEER-INFT","RegNet-32Gf trained via large-scale self-supervision on 1 billion images.",NA,NA,"crsa",0.361970473708285,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"mask_rcnn_R_50_FPN_3x_segmentation","mask_rcnn_R_50_FPN_3x","segmentation","coco2017","mask_rcnn_R_50_FPN_3x","Convolutional",NA,"Mask-RCNN-ResNet50-FPN","Mask-RCNN-ResNet50-FPN, trained on segmentation with the CoCo2017 dataset.",NA,NA,"crsa",0.3633896697386,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"xcit_nano_12_p8_224_classification","xcit_nano_12_p8_224","classification","imagenet","xcit_nano_12_p8_224","Transformer",NA,"XCIT-N-12-P8","XCIT-N-12-P8 trained on image classification with the ImageNet dataset.",NA,NA,"crsa",0.363516807787596,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,NA
"poolformer_s36_classification","poolformer_s36","classification","imagenet","poolformer_s36","Transformer",483,"PoolFormer-S36","PoolFormer-S36 trained on image classification with the ImageNet dataset.",78339280,30842792,"crsa",0.3636489765994,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,NA
"vit_base_patch32_224_in21k_classification","vit_base_patch32_224_in21k","classification","imagenet21k","vit_base_patch32_224","Transformer",225,"ViT-B-P32-IN21K","ViT-B-P32-IN21K trained on image classification with the ImageNet21K dataset.",13497318,104213331,"crsa",0.364406970599356,NA,NA,NA,NA,NA,NA,NA,NA,NA,"imagenet21k"
"resmlp_12_224_classification","resmlp_12_224","classification","imagenet","resmlp_12_224","MLP-Mixer",150,"ResMLP-12","ResMLP-12 trained on image classification with the ImageNet dataset.",19269584,15322456,"crsa",0.364914539892309,"classification","MLP-Mixer",NA,NA,NA,NA,NA,NA,NA,NA
"ResNet50-BarlowTwins-BS2048_selfsupervised","ResNet50-BarlowTwins-BS2048","selfsupervised","imagenet","ResNet50","Convolutional",175,"ResNet50-BarlowTwins-BS2048","ResNet50-BarlowTwins-BS2048, a self-supervised representation learner trained on ImageNet.",37562880,23508032,"crsa",0.36704799817766,NA,NA,NA,NA,NA,NA,NA,"BarlowTwins-BS2048","Contrastive",NA
"resmlp_24_224_classification","resmlp_24_224","classification","imagenet","resmlp_24_224","MLP-Mixer",294,"ResMLP-24","ResMLP-24 trained on image classification with the ImageNet dataset.",38236112,29964616,"crsa",0.368411515940519,"classification","MLP-Mixer",NA,NA,NA,NA,NA,NA,NA,NA
"densenet121_classification","densenet121","classification","imagenet","densenet121","Convolutional",429,"DenseNet121","DenseNet121 trained on image classification with the ImageNet dataset.",41096144,7978856,"crsa",0.368812779436822,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"mnasnet1_0_classification","mnasnet1_0","classification","imagenet","mnasnet1_0","Convolutional",158,"MNASNet1.0","MNASNet1.0 trained on image classification with the ImageNet dataset.",16172496,4383312,"crsa",0.368975838905901,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"yolov5m_yolo","yolov5m","yolo","coco,voc","yolov5m","Convolutional",NA,"YOLO-V5-M","YOLO-V5-M, an object detection model.",NA,NA,"crsa",0.370379541308488,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"faster_rcnn_R_50_FPN_3x_detection","faster_rcnn_R_50_FPN_3x","detection","coco2017","faster_rcnn_R_50_FPN_3x","Convolutional",NA,"Faster-RCNN-ResNet50-FPN","Faster-RCNN-ResNet50-FPN, trained on detection with the CoCo2017 dataset.",NA,NA,"crsa",0.370387426849006,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"regnety_064_classification","regnety_064","classification","imagenet","regnety_064","Convolutional",658,"RegNetY-64","RegNetY-64 trained on image classification with the ImageNet dataset.",103013924,30583252,"crsa",0.372330858512492,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"googlenet_classification","googlenet","classification","imagenet","googlenet","Convolutional",197,"GoogleNet","GoogleNet trained on image classification with the ImageNet dataset.",12335584,6624904,"crsa",0.376684864851218,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"resnet50_classification","resnet50","classification","imagenet","resnet50","Convolutional",175,"ResNet50","ResNet50 trained on image classification with the ImageNet dataset.",37560784,25557032,"crsa",0.378881404661809,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"seresnext50_32x4d_classification","seresnext50_32x4d","classification","imagenet","seresnext50_32x4d","Convolutional",305,"SEResNext50-32x4D","SEResNext50-32x4D trained on image classification with the ImageNet dataset.",58496224,27559896,"crsa",0.383631520019587,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"vit_base_patch32_224_classification","vit_base_patch32_224","classification","imagenet","vit_base_patch32_224","Transformer",225,"ViT-B-P32","ViT-B-P32 trained on image classification with the ImageNet dataset.",13455632,88185064,"crsa",0.385180952115794,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,"imagenet"
"xcit_nano_12_p16_224_classification","xcit_nano_12_p16_224","classification","imagenet","xcit_nano_12_p16_224","Transformer",NA,"XCIT-N-12-P16","XCIT-N-12-P16 trained on image classification with the ImageNet dataset.",NA,NA,"crsa",0.392453915336771,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,NA
"pit_ti_224_classification","pit_ti_224","classification","imagenet","pit_ti_224","Transformer",236,"PiT-T-224","PiT-T-224 trained on image classification with the ImageNet dataset.",11698296,4800552,"crsa",0.394388362950118,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,NA
"resmlp_big_24_224_in22ft1k_classification","resmlp_big_24_224_in22ft1k","classification","imagenet21k","resmlp_big_24_224","MLP-Mixer",294,"ResMLP-Big-24-IN21K","ResMLP-Big-24-IN21K trained on image classification with the ImageNet21K dataset.",305874896,129026152,"crsa",0.394690777150952,NA,NA,NA,NA,NA,NA,NA,NA,NA,"imagenet21k"
"ghostnet_100_classification","ghostnet_100","classification","imagenet","ghostnet_100","Convolutional",287,"GhostNet100","GhostNet100 trained on image classification with the ImageNet dataset.",13446920,5182508,"crsa",0.398520091000847,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"cspresnet50_classification","cspresnet50","classification","imagenet","cspresnet50","Convolutional",329,"CSP-ResNet50","CSP-ResNet50 trained on image classification with the ImageNet dataset.",51186592,21616168,"crsa",0.399676758956653,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"nf_resnet50_classification","nf_resnet50","classification","imagenet","nf_resnet50","Convolutional",151,"NF-ResNet50","NF-ResNet50 trained on image classification with the ImageNet dataset.",33527712,25530472,"crsa",0.400664952115988,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"eca_nfnet_l0_classification","eca_nfnet_l0","classification","imagenet","eca_nfnet_l0","Convolutional",184,"ECA-NFNeT-L0","ECA-NFNeT-L0 trained on image classification with the ImageNet dataset.",32555168,24111108,"crsa",0.400956167547613,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"gmlp_s16_224_classification","gmlp_s16_224","classification","imagenet","gmlp_s16_224","Convolutional",366,"GMLP-S16","GMLP-S16 trained on image classification with the ImageNet dataset.",49876944,19422656,"crsa",0.402046371536414,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"semnasnet_100_classification","semnasnet_100","classification","imagenet","semnasnet_100","Convolutional",274,"SemNASNet100","SemNASNet100 trained on image classification with the ImageNet dataset.",27843180,3887038,"crsa",0.404970484242164,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"mobilenetv3_large_100_classification","mobilenetv3_large_100","classification","imagenet","mobilenetv3_large_100","Convolutional",265,"MobileNet-V3-Large","MobileNet-V3-Large trained on image classification with the ImageNet dataset.",20046944,5483032,"crsa",0.412016541417,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"inception_v3_classification","inception_v3","classification","imagenet","inception_v3","Convolutional",300,"Inception-V3","Inception-V3 trained on image classification with the ImageNet dataset.",15467136,23834568,"crsa",0.416620290720153,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"nfnet_l0_classification","nfnet_l0","classification","imagenet","nfnet_l0","Convolutional",220,"NF-Net-L0","NF-Net-L0 trained on image classification with the ImageNet dataset.",32566496,35041672,"crsa",0.417204964333812,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"hardcorenas_a_classification","hardcorenas_a","classification","imagenet","hardcorenas_a","Convolutional",204,"HardCoreNAS-A","HardCoreNAS-A trained on image classification with the ImageNet dataset.",19698736,5260232,"crsa",0.421924612226752,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"efficientnet_b1_classification","efficientnet_b1","classification","imagenet","efficientnet_b1","Convolutional",435,"EfficientNet-B1","EfficientNet-B1 trained on image classification with the ImageNet dataset.",42450128,7794184,"crsa",0.422370289084752,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"levit_128_classification","levit_128","classification","imagenet","levit_128","Transformer",NA,"LeViT128","LeViT128 trained on image classification with the ImageNet dataset.",NA,NA,"crsa",0.424757505187661,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,NA
"efficientnet_b3_classification","efficientnet_b3","classification","imagenet","efficientnet_b3","Convolutional",492,"EfficientNet-B3","EfficientNet-B3 trained on image classification with the ImageNet dataset.",59058840,12233232,"crsa",0.430582847816565,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"hardcorenas_f_classification","hardcorenas_f","classification","imagenet","hardcorenas_f","Convolutional",326,"HardCoreNAS-F","HardCoreNAS-F trained on image classification with the ImageNet dataset.",25099520,8199688,"crsa",0.435452821789894,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"keypoints2d_taskonomy","keypoints2d","taskonomy","taskonomy","resnet50","Convolutional",179,"2D Keypoints","Keypoint estimation from RGB-only (texture features).",37564576,23655504,"srpr",0.0822385025646629,NA,NA,NA,"keypoints2d","2D",NA,NA,NA,NA,NA
"mobilenetv3_large_100_random","mobilenetv3_large_100","random",NA,"mobilenetv3_large_100","Convolutional",265,"MobileNet-V3-Large","MobileNet-V3-Large randomly initialized, with no training.",20046944,5483032,"srpr",0.0848256682166093,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"edge_texture_taskonomy","edge_texture","taskonomy","taskonomy","resnet50","Convolutional",179,"Texture Edges","Edges computed from RGB only (texture edges).",37564576,23655504,"srpr",0.0927670819148608,NA,NA,NA,"edge_texture","2D",NA,NA,NA,NA,NA
"resnet101_random","resnet101","random",NA,"resnet101","Convolutional",345,"ResNet101","ResNet101 randomly initialized, with no training.",56326608,44549160,"srpr",0.0938390012623139,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"resnet152_random","resnet152","random",NA,"resnet152","Convolutional",515,"ResNet152","ResNet152 randomly initialized, with no training.",79507920,60192808,"srpr",0.0947038697059117,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"efficientnet_b1_random","efficientnet_b1","random",NA,"efficientnet_b1","Convolutional",435,"EfficientNet-B1","EfficientNet-B1 randomly initialized, with no training.",42450128,7794184,"srpr",0.0958303017335094,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"convmixer_768_32_random","convmixer_768_32","random",NA,"convmixer_768_32","Hybrid",232,"ConvMixer-768-32","ConvMixer-768-32 randomly initialized, with no training.",178524368,21110248,"srpr",0.0985707332488358,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"regnetx_064_random","regnetx_064","random",NA,"regnetx_064","Convolutional",373,"RegNetX-64","RegNetX-64 randomly initialized, with no training.",101428288,26209256,"srpr",0.0991604562795823,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"vit_tiny_patch16_224_random","vit_tiny_patch16_224","random",NA,"vit_tiny_patch16_224","Transformer",225,"ViT-T-P16","ViT-T-P16 randomly initialized, with no training.",14296916,5679400,"srpr",0.0996664784980888,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"eca_nfnet_l0_random","eca_nfnet_l0","random",NA,"eca_nfnet_l0","Convolutional",184,"ECA-NFNeT-L0","ECA-NFNeT-L0 randomly initialized, with no training.",32555168,24111108,"srpr",0.100995640535449,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"gmixer_24_224_random","gmixer_24_224","random",NA,"gmixer_24_224","Convolutional",414,"GMixer-24","GMixer-24 randomly initialized, with no training.",41701328,24721096,"srpr",0.101264658234565,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"levit_128_random","levit_128","random",NA,"levit_128","Transformer",NA,"LeViT128","LeViT128 randomly initialized, with no training.",NA,NA,"srpr",0.102730201145494,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"dla34_random","dla34","random",NA,"dla34","Convolutional",151,"DLA34","DLA34 randomly initialized, with no training.",17578680,15742104,"srpr",0.10298617037524,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"coat_lite_tiny_random","coat_lite_tiny","random",NA,"coat_lite_tiny","Transformer",279,"CoaT-Lite-Tiny","CoaT-Lite-Tiny randomly initialized, with no training.",36283152,5878632,"srpr",0.10387784685101,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"semnasnet_100_random","semnasnet_100","random",NA,"semnasnet_100","Convolutional",274,"SemNASNet100","SemNASNet100 randomly initialized, with no training.",27843180,3887038,"srpr",0.104537497626909,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"nfnet_l0_random","nfnet_l0","random",NA,"nfnet_l0","Convolutional",220,"NF-Net-L0","NF-Net-L0 randomly initialized, with no training.",32566496,35041672,"srpr",0.104630060689466,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"poolformer_s36_random","poolformer_s36","random",NA,"poolformer_s36","Transformer",483,"PoolFormer-S36","PoolFormer-S36 randomly initialized, with no training.",78339280,30842792,"srpr",0.105040128502295,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"shufflenet_v2_x1_0_random","shufflenet_v2_x1_0","random",NA,"shufflenet_v2_x1_0","Convolutional",168,"ShuffleNet-V2-x1.0","ShuffleNet-V2-x1.0 randomly initialized, with no training.",6284192,2278604,"srpr",0.105365050467407,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"efficientnet_b3_random","efficientnet_b3","random",NA,"efficientnet_b3","Convolutional",492,"EfficientNet-B3","EfficientNet-B3 randomly initialized, with no training.",59058840,12233232,"srpr",0.105832601875438,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"convnext_large_random","convnext_large","random",NA,"convnext_large","Convolutional",382,"ConvNext-L","ConvNext-L randomly initialized, with no training.",137593808,197740264,"srpr",0.106521438608765,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"pit_ti_224_random","pit_ti_224","random",NA,"pit_ti_224","Transformer",236,"PiT-T-224","PiT-T-224 randomly initialized, with no training.",11698296,4800552,"srpr",0.106637579142484,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"vit_small_patch32_224_random","vit_small_patch32_224","random",NA,"vit_small_patch32_224","Transformer",225,"ViT-S-P32","ViT-S-P32 randomly initialized, with no training.",6728816,22859368,"srpr",0.107216070586909,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"tnt_s_patch16_224_random","tnt_s_patch16_224","random",NA,"tnt_s_patch16_224","Transformer",NA,"TnT-P16-224","TnT-P16-224 randomly initialized, with no training.",NA,NA,"srpr",0.107216090900975,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"convnext_base_random","convnext_base","random",NA,"convnext_base","Convolutional",382,"ConvNext-B","ConvNext-B randomly initialized, with no training.",91729872,88573416,"srpr",0.107324860136,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"hardcorenas_f_random","hardcorenas_f","random",NA,"hardcorenas_f","Convolutional",326,"HardCoreNAS-F","HardCoreNAS-F randomly initialized, with no training.",25099520,8199688,"srpr",0.107505811852832,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"crossvit_base_240_random","crossvit_base_240","random",NA,"crossvit_base_240","Transformer",383,"CrossViT-B","CrossViT-B randomly initialized, with no training.",80095620,104718800,"srpr",0.107966426832408,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"resmlp_36_224_random","resmlp_36_224","random",NA,"resmlp_36_224","MLP-Mixer",438,"ResMLP-36","ResMLP-36 randomly initialized, with no training.",57202640,44606776,"srpr",0.108633639033717,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"convit_tiny_random","convit_tiny","random",NA,"convit_tiny","Hybrid",219,"ConViT-T","ConViT-T randomly initialized, with no training.",15325272,5672648,"srpr",0.109607079756286,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"resmlp_24_224_random","resmlp_24_224","random",NA,"resmlp_24_224","MLP-Mixer",294,"ResMLP-24","ResMLP-24 randomly initialized, with no training.",38236112,29964616,"srpr",0.110383947389642,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"resmlp_big_24_224_random","resmlp_big_24_224","random",NA,"resmlp_big_24_224","MLP-Mixer",294,"ResMLP-Big-24","ResMLP-Big-24 randomly initialized, with no training.",305874896,129026152,"srpr",0.110733449761379,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"resmlp_12_224_random","resmlp_12_224","random",NA,"resmlp_12_224","MLP-Mixer",150,"ResMLP-12","ResMLP-12 randomly initialized, with no training.",19269584,15322456,"srpr",0.11143616818082,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"pit_b_224_random","pit_b_224","random",NA,"pit_b_224","Transformer",254,"PiT-B-224","PiT-B-224 randomly initialized, with no training.",66195824,73518568,"srpr",0.112280512955341,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"swin_tiny_patch4_window7_224_random","swin_tiny_patch4_window7_224","random",NA,"swin_tiny_patch4_window7_224","Transformer",NA,"Swin-T-P4-W7","Swin-T-P4-W7 randomly initialized, with no training.",NA,NA,"srpr",0.11309622273521,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"resnet50_random","resnet50","random",NA,"resnet50","Convolutional",175,"ResNet50","ResNet50 randomly initialized, with no training.",37560784,25557032,"srpr",0.113297449723881,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"vit_small_patch16_224_random","vit_small_patch16_224","random",NA,"vit_small_patch16_224","Transformer",225,"ViT-S-P16","ViT-S-P16 randomly initialized, with no training.",28591832,21974632,"srpr",0.113451892005766,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"denoising_taskonomy","denoising","taskonomy","taskonomy","resnet50","Convolutional",179,"Denoising","Uncorrupted version of corrupted image.",37564576,23655504,"srpr",0.113552646320002,NA,NA,NA,"denoising","Other",NA,NA,NA,NA,NA
"xcit_nano_12_p16_224_random","xcit_nano_12_p16_224","random",NA,"xcit_nano_12_p16_224","Transformer",NA,"XCIT-N-12-P16","XCIT-N-12-P16 randomly initialized, with no training.",NA,NA,"srpr",0.113774196749373,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"gmlp_s16_224_random","gmlp_s16_224","random",NA,"gmlp_s16_224","Convolutional",366,"GMLP-S16","GMLP-S16 randomly initialized, with no training.",49876944,19422656,"srpr",0.114901440836531,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"mobilenet_v2_random","mobilenet_v2","random",NA,"mobilenet_v2","Convolutional",159,"MobileNet-V2","MobileNet-V2 randomly initialized, with no training.",20037616,3504872,"srpr",0.115885343327472,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"deit_base_patch16_224_random","deit_base_patch16_224","random",NA,"deit_base_patch16_224","Transformer",225,"DeiT-B-P16-224","DeiT-B-P16-224 randomly initialized, with no training.",57181664,86415592,"srpr",0.116702726170541,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"seresnext50_32x4d_random","seresnext50_32x4d","random",NA,"seresnext50_32x4d","Convolutional",305,"SEResNext50-32x4D","SEResNext50-32x4D randomly initialized, with no training.",58496224,27559896,"srpr",0.116951460198959,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"vit_base_patch16_224_random","vit_base_patch16_224","random",NA,"vit_base_patch16_224","Transformer",225,"ViT-B-P16","ViT-B-P16 randomly initialized, with no training.",57181664,86415592,"srpr",0.117039347407638,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"ghostnet_100_random","ghostnet_100","random",NA,"ghostnet_100","Convolutional",287,"GhostNet100","GhostNet100 randomly initialized, with no training.",13446920,5182508,"srpr",0.117327890152526,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"vit_base_patch32_224_random","vit_base_patch32_224","random",NA,"vit_base_patch32_224","Transformer",225,"ViT-B-P32","ViT-B-P32 randomly initialized, with no training.",13455632,88185064,"srpr",0.117364986404434,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"mnasnet1_0_random","mnasnet1_0","random",NA,"mnasnet1_0","Convolutional",158,"MNASNet1.0","MNASNet1.0 randomly initialized, with no training.",16172496,4383312,"srpr",0.11747339395323,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"mixer_l16_224_random","mixer_l16_224","random",NA,"mixer_l16_224","MLP-Mixer",414,"MLP-Mixer-L16","MLP-Mixer-L16 randomly initialized, with no training.",149342160,208196168,"srpr",0.118656587062421,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"mixer_b16_224_random","mixer_b16_224","random",NA,"mixer_b16_224","MLP-Mixer",210,"MLP-Mixer-B16","MLP-Mixer-B16 randomly initialized, with no training.",52766672,59880472,"srpr",0.119617770830774,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"convit_base_random","convit_base","random",NA,"convit_base","Hybrid",219,"ConViT-B","ConViT-B randomly initialized, with no training.",61295088,86388584,"srpr",0.119666048154626,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"hardcorenas_a_random","hardcorenas_a","random",NA,"hardcorenas_a","Convolutional",204,"HardCoreNAS-A","HardCoreNAS-A randomly initialized, with no training.",19698736,5260232,"srpr",0.120287346099315,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"swin_large_patch4_window7_224_random","swin_large_patch4_window7_224","random",NA,"swin_large_patch4_window7_224","Transformer",NA,"Swin-L-P4-W7","Swin-L-P4-W7 randomly initialized, with no training.",NA,NA,"srpr",0.122662502843743,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"regnety_064_random","regnety_064","random",NA,"regnety_064","Convolutional",658,"RegNetY-64","RegNetY-64 randomly initialized, with no training.",103013924,30583252,"srpr",0.122935189380118,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"vit_large_patch16_224_random","vit_large_patch16_224","random",NA,"vit_large_patch16_224","Transformer",441,"ViT-L-P16","ViT-L-P16 randomly initialized, with no training.",151473488,304123880,"srpr",0.123127700023522,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"visformer_small_random","visformer_small","random",NA,"visformer_small","Transformer",226,"Visformer","Visformer randomly initialized, with no training.",31879784,39956168,"srpr",0.124060306256559,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"swin_base_patch4_window7_224_random","swin_base_patch4_window7_224","random",NA,"swin_base_patch4_window7_224","Transformer",NA,"Swin-B-P4-W7","Swin-B-P4-W7 randomly initialized, with no training.",NA,NA,"srpr",0.125088029345571,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"vgg16_random","vgg16","random",NA,"vgg16","Convolutional",40,"VGG16","VGG16 randomly initialized, with no training.",28677072,138357544,"srpr",0.125243468773529,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"random_weights_taskonomy","random_weights","taskonomy",NA,"resnet50","Convolutional",179,"Random Weights","Taskonomy architecture randomly initialized.",37564576,23655504,"srpr",0.126388875545783,NA,NA,NA,"random_weights","Random",NA,NA,NA,NA,NA
"xcit_nano_12_p8_224_random","xcit_nano_12_p8_224","random",NA,"xcit_nano_12_p8_224","Transformer",NA,"XCIT-N-12-P8","XCIT-N-12-P8 randomly initialized, with no training.",NA,NA,"srpr",0.127665756300325,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"cspresnet50_random","cspresnet50","random",NA,"cspresnet50","Convolutional",329,"CSP-ResNet50","CSP-ResNet50 randomly initialized, with no training.",51186592,21616168,"srpr",0.128581715817134,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"autoencoding_taskonomy","autoencoding","taskonomy","taskonomy","resnet50","Convolutional",179,"Autoencoder","Image compression and decompression",37564576,23655504,"srpr",0.129198356655757,NA,NA,NA,"autoencoding","2D",NA,NA,NA,NA,NA
"resnet18_random","resnet18","random",NA,"resnet18","Convolutional",69,"ResNet18","ResNet18 randomly initialized, with no training.",8231376,11689512,"srpr",0.129952762781892,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"inception_v3_random","inception_v3","random",NA,"inception_v3","Convolutional",300,"Inception-V3","Inception-V3 randomly initialized, with no training.",15467136,23834568,"srpr",0.129958832401615,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"skresnext50_32x4d_random","skresnext50_32x4d","random",NA,"skresnext50_32x4d","Convolutional",497,"SKResNext50-32x4D","SKResNext50-32x4D randomly initialized, with no training.",99238128,27479784,"srpr",0.131972536896102,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"squeezenet1_0_random","squeezenet1_0","random",NA,"squeezenet1_0","Convolutional",66,"SqueezeNet1.0","SqueezeNet1.0 randomly initialized, with no training.",12033376,1248424,"srpr",0.133315389609003,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"vanishing_point_taskonomy","vanishing_point","taskonomy","taskonomy","resnet50","Convolutional",179,"Vanishing Point","Three Manhattan-world vanishing points.",37564576,23655504,"srpr",0.140949261246682,NA,NA,NA,"vanishing_point","Geometric",NA,NA,NA,NA,NA
"jigsaw_taskonomy","jigsaw","taskonomy","taskonomy","resnet50","Convolutional",179,"Jigsaw","Putting scrambled image pieces back together.",37564576,23655504,"srpr",0.141650117397355,NA,NA,NA,"jigsaw","Geometric",NA,NA,NA,NA,NA
"xception_random","xception","random",NA,"xception","Convolutional",204,"XCeption","XCeption randomly initialized, with no training.",52151632,22855952,"srpr",0.14450902022516,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"alexnet_random","alexnet","random",NA,"alexnet","Convolutional",22,"AlexNet","AlexNet randomly initialized, with no training.",1099216,61100840,"srpr",0.149376635092919,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"densenet121_random","densenet121","random",NA,"densenet121","Convolutional",429,"DenseNet121","DenseNet121 randomly initialized, with no training.",41096144,7978856,"srpr",0.150058521107051,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"jx_nest_tiny_random","jx_nest_tiny","random",NA,"jx_nest_tiny","Transformer",213,"JX-NesT-Tiny","JX-NesT-Tiny randomly initialized, with no training.",52424528,16530760,"srpr",0.155652978655545,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"nonfixated_pose_taskonomy","nonfixated_pose","taskonomy","taskonomy","resnet50","Convolutional",179,"Camera Pose (Nonfixated)","Relative camera pose with distinct optical centers.",37564576,23655504,"srpr",0.156733702955373,NA,NA,NA,"nonfixated_pose","Geometric",NA,NA,NA,NA,NA
"segment_unsup2d_taskonomy","segment_unsup2d","taskonomy","taskonomy","resnet50","Convolutional",179,"Unsupervised 2D Segmentation","Segmentation (graph cut approximation) on RGB.",37564576,23655504,"srpr",0.158666196799007,NA,NA,NA,"segment_unsup2d","2D",NA,NA,NA,NA,NA
"googlenet_random","googlenet","random",NA,"googlenet","Convolutional",197,"GoogleNet","GoogleNet randomly initialized, with no training.",12335584,6624904,"srpr",0.15894482081769,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"egomotion_taskonomy","egomotion","taskonomy","taskonomy","resnet50","Convolutional",179,"Egomotion","Odometry (camera poses) given three input images.",37564576,23655504,"srpr",0.169346607940887,NA,NA,NA,"egomotion","Geometric",NA,NA,NA,NA,NA
"inpainting_taskonomy","inpainting","taskonomy","taskonomy","resnet50","Convolutional",179,"Inpainting","Filling in masked center of image.",37564576,23655504,"srpr",0.169791367244862,NA,NA,NA,"inpainting","2D",NA,NA,NA,NA,NA
"nf_resnet50_random","nf_resnet50","random",NA,"nf_resnet50","Convolutional",151,"NF-ResNet50","NF-ResNet50 randomly initialized, with no training.",33527712,25530472,"srpr",0.170186020712107,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"fixated_pose_taskonomy","fixated_pose","taskonomy","taskonomy","resnet50","Convolutional",179,"Camera Pose (Fixated)","Relative camera pose with matching optical centers.",37564576,23655504,"srpr",0.185099672890333,NA,NA,NA,"fixated_pose","Geometric",NA,NA,NA,NA,NA
"point_matching_taskonomy","point_matching","taskonomy","taskonomy","resnet50","Convolutional",179,"Point Matching","Classifying if centers of two images match or not.",37564576,23655504,"srpr",0.189386716180516,NA,NA,NA,"point_matching","Geometric",NA,NA,NA,NA,NA
"curvature_taskonomy","curvature","taskonomy","taskonomy","resnet50","Convolutional",179,"Curvatures","Magnitude of 3D principal curvatures",37564576,23655504,"srpr",0.216447165922202,NA,NA,NA,"curvature","3D",NA,NA,NA,NA,NA
"alexnet_gn_ipcl_vggface2_ipcl","alexnet_gn_ipcl_vggface2","ipcl","vggface2","alexnet_gn","Convolutional",NA,"AlexNet-GN-IPCLVGGFace2","AlexNet (modified with GroupNorm) trained via IPCL-Style-Self-Supervision on VGGFace2.",NA,NA,"srpr",0.216648590976135,NA,NA,NA,NA,NA,NA,"vggface2",NA,NA,NA
"room_layout_taskonomy","room_layout","taskonomy","taskonomy","resnet50","Convolutional",179,"Room Layout","Orientation and aspect ratio of cubic room layout.",37564576,23655504,"srpr",0.217757709797586,NA,NA,NA,"room_layout","Geometric",NA,NA,NA,NA,NA
"segment_semantic_taskonomy","segment_semantic","taskonomy","taskonomy","resnet50","Convolutional",179,"Semantic Segmentation","Pixel-wise semantic labeling (via knowledge distillation from MS COCO).",37564576,23655504,"srpr",0.23327719098131,NA,NA,NA,"segment_semantic","Semantic",NA,NA,NA,NA,NA
"depth_zbuffer_taskonomy","depth_zbuffer","taskonomy","taskonomy","resnet50","Convolutional",179,"Z-Buffer Depth","Depth estimation.",37564576,23655504,"srpr",0.236541829348589,NA,NA,NA,"depth_zbuffer","3D",NA,NA,NA,NA,NA
"segment_unsup25d_taskonomy","segment_unsup25d","taskonomy","taskonomy","resnet50","Convolutional",179,"Unsupervised 2.5D Segmentation","Segmentation (graph cut approximation) on RGB-D-Normals-Curvature image.",37564576,23655504,"srpr",0.237831995399626,NA,NA,NA,"segment_unsup25d","3D",NA,NA,NA,NA,NA
"normal_taskonomy","normal","taskonomy","taskonomy","resnet50","Convolutional",179,"Surface Normals","Pixel-wise surface normals.",37564576,23655504,"srpr",0.24365490637392,NA,NA,NA,"normal","3D",NA,NA,NA,NA,NA
"depth_euclidean_taskonomy","depth_euclidean","taskonomy","taskonomy","resnet50","Convolutional",179,"Euclidean Depth","Depth estimation",37564576,23655504,"srpr",0.245934586761638,NA,NA,NA,"depth_euclidean","3D",NA,NA,NA,NA,NA
"edge_occlusion_taskonomy","edge_occlusion","taskonomy","taskonomy","resnet50","Convolutional",179,"Occlusion Edges","Edges which include parts of the scene.",37564576,23655504,"srpr",0.24682541326213,NA,NA,NA,"edge_occlusion","3D",NA,NA,NA,NA,NA
"reshading_taskonomy","reshading","taskonomy","taskonomy","resnet50","Convolutional",179,"Reshading","Reshading with new lighting placed at camera location.",37564576,23655504,"srpr",0.248097194119517,NA,NA,NA,"reshading","3D",NA,NA,NA,NA,NA
"keypoints3d_taskonomy","keypoints3d","taskonomy","taskonomy","resnet50","Convolutional",179,"3D Keypoints","3D Keypoint estimation from underlying scene 3D.",37564576,23655504,"srpr",0.254554834271112,NA,NA,NA,"keypoints3d","3D",NA,NA,NA,NA,NA
"class_scene_taskonomy","class_scene","taskonomy","taskonomy","resnet50","Convolutional",179,"Scene Classification","Scene Classification (via knowledge distillation from MIT Places).",37564576,23655504,"srpr",0.286302076476033,NA,NA,NA,"class_scene","Semantic",NA,NA,NA,NA,NA
"class_object_taskonomy","class_object","taskonomy","taskonomy","resnet50","Convolutional",179,"Object Classification","1000-way object classification (via knowledge distillation from ImageNet).",37564576,23655504,"srpr",0.289656702183116,NA,NA,NA,"class_object","Semantic",NA,NA,NA,NA,NA
"alexnet_gn_ipcl_places256_ipcl","alexnet_gn_ipcl_places256","ipcl","places256","alexnet_gn","Convolutional",NA,"AlexNet-GN-IPCLPlaces256","AlexNet (modified with GroupNorm) trained via IPCL-Style-Self-Supervision on Places256.",NA,NA,"srpr",0.296718026524128,NA,NA,NA,NA,NA,NA,"places256",NA,NA,NA
"alexnet_gn_ipcl_openimages_ipcl","alexnet_gn_ipcl_openimages","ipcl","openimages","alexnet_gn","Convolutional",NA,"AlexNet-GN-IPCLOpenImages","AlexNet (modified with GroupNorm) trained via IPCL-Style-Self-Supervision on OpenImages.",NA,NA,"srpr",0.308696086718687,NA,NA,NA,NA,NA,NA,"openimages",NA,NA,NA
"alexnet_gn_ipcl_imagenet_ipcl","alexnet_gn_ipcl_imagenet","ipcl","imagenet","alexnet_gn","Convolutional",NA,"AlexNet-GN-IPCLImageNet","AlexNet (modified with GroupNorm) trained via IPCL-Style-Self-Supervision on ImageNet.",NA,NA,"srpr",0.328272717477119,NA,NA,NA,NA,NA,NA,"imagenet",NA,NA,NA
"ResNet50-RotNet_selfsupervised","ResNet50-RotNet","selfsupervised","imagenet","ResNet50","Convolutional",175,"ResNet50-RotNet","ResNet50-RotNet, a self-supervised representation learner trained on ImageNet.",37562880,23508032,"srpr",0.332064504992629,NA,NA,NA,NA,NA,NA,NA,"RotNet","Non-Contrastive",NA
"ResNet50-JigSaw-Goyal19_selfsupervised","ResNet50-JigSaw-Goyal19","selfsupervised","imagenet","ResNet50","Convolutional",175,"ResNet50-JigSaw-Goyal19","ResNet50-JigSaw-Goyal19, a self-supervised representation learner trained on ImageNet.",37562880,23508032,"srpr",0.336906352065773,NA,NA,NA,NA,NA,NA,NA,"JigSaw-Goyal19","Non-Contrastive",NA
"ResNet50-MoCoV2-BS256_selfsupervised","ResNet50-MoCoV2-BS256","selfsupervised","imagenet","ResNet50","Convolutional",175,"ResNet50-MoCoV2-BS256","ResNet50-MoCoV2-BS256, a self-supervised representation learner trained on ImageNet.",37562880,23508032,"srpr",0.338708595891208,NA,NA,NA,NA,NA,NA,NA,"MoCoV2-BS256","Contrastive",NA
"vit_tiny_patch16_224_classification","vit_tiny_patch16_224","classification","imagenet","vit_tiny_patch16_224","Transformer",225,"ViT-T-P16","ViT-T-P16 trained on image classification with the ImageNet dataset.",14296916,5679400,"srpr",0.340434547775727,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,NA
"ViT-L-CLIP_slip","ViT-L-CLIP","slip","YFCC15M","ViT-L","Transformer",441,"ViT-L-CLIP","ViT-L-CLIP trained via pure language supervision with the YFCC15M dataset.",151473536,303098880,"srpr",0.341715828576884,NA,NA,"CLIP",NA,NA,NA,NA,NA,NA,NA
"ResNet50-JigSaw-P100_selfsupervised","ResNet50-JigSaw-P100","selfsupervised","imagenet","ResNet50","Convolutional",175,"ResNet50-JigSaw-P100","ResNet50-JigSaw-P100, a self-supervised representation learner trained on ImageNet.",37562880,23508032,"srpr",0.342658619078337,NA,NA,NA,NA,NA,NA,NA,"JigSaw-P100","Non-Contrastive",NA
"MiDaS_monoculardepth","MiDaS","monoculardepth","ReDWeb,DIML,Movies,MegaDepth,WSVD,TartanAir,HRWSI,ApolloScape,BlendedMVS,IRS","MiDaS",NA,NA,"MiDaS","MiDaS, a monocular depth estimation model.",NA,NA,"srpr",0.349044409056368,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"alexnet_classification","alexnet","classification","imagenet","alexnet","Convolutional",22,"AlexNet","AlexNet trained on image classification with the ImageNet dataset.",1099216,61100840,"srpr",0.350091236824547,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"vit_small_patch32_224_in21k_classification","vit_small_patch32_224_in21k","classification","imagenet21k","vit_small_patch32_224","Transformer",225,"ViT-S-P32-IN21K","ViT-S-P32-IN21K trained on image classification with the ImageNet21K dataset.",6770502,30883923,"srpr",0.351598068075274,NA,NA,NA,NA,NA,NA,NA,NA,NA,"imagenet21k"
"squeezenet1_0_classification","squeezenet1_0","classification","imagenet","squeezenet1_0","Convolutional",66,"SqueezeNet1.0","SqueezeNet1.0 trained on image classification with the ImageNet dataset.",12033376,1248424,"srpr",0.352422712564796,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"vit_small_patch32_224_classification","vit_small_patch32_224","classification","imagenet","vit_small_patch32_224","Transformer",225,"ViT-S-P32","ViT-S-P32 trained on image classification with the ImageNet dataset.",6728816,22859368,"srpr",0.353057366798529,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,"imagenet"
"ResNet50-ClusterFit-16K-RotNet_selfsupervised","ResNet50-ClusterFit-16K-RotNet","selfsupervised","imagenet","ResNet50","Convolutional",175,"ResNet50-ClusterFit-16K-RotNet","ResNet50-ClusterFit-16K-RotNet, a self-supervised representation learner trained on ImageNet.",37562880,23508032,"srpr",0.355058404123133,NA,NA,NA,NA,NA,NA,NA,"ClusterFit-16K-RotNet","Non-Contrastive",NA
"vit_small_patch16_224_in21k_classification","vit_small_patch16_224_in21k","classification","imagenet21k","vit_small_patch16_224","Transformer",225,"ViT-S-P16-IN21K","ViT-S-P16-IN21K trained on image classification with the ImageNet21K dataset.",28633518,29999187,"srpr",0.35582888302363,NA,NA,NA,NA,NA,NA,NA,NA,NA,"imagenet21k"
"DPT_Hybrid_monoculardepth","DPT_Hybrid","monoculardepth","ReDWeb,DIML,Movies,MegaDepth,WSVD,TartanAir,HRWSI,ApolloScape,BlendedMVS,IRS","DPT_Hybrid","Transformer",584,"DPT-Hybrid","DPT-Hybrid, a monocular depth estimation model.",167515152,120753921,"srpr",0.355935498842211,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"ViT-S-CLIP_slip","ViT-S-CLIP","slip","YFCC15M","ViT-S","Transformer",225,"ViT-S-CLIP","ViT-S-CLIP trained via pure language supervision with the YFCC15M dataset.",31384848,21589632,"srpr",0.356432294751358,NA,NA,"CLIP",NA,NA,NA,NA,NA,NA,NA
"ViT-L-SimCLR_slip","ViT-L-SimCLR","slip","YFCC15M","ViT-L","Transformer",441,"ViT-L-SimCLR","ViT-L-SimCLR trained via pure self-supervision with the YFCC15M dataset.",151473536,303098880,"srpr",0.358585123837369,NA,NA,"SimCLR",NA,NA,NA,NA,NA,NA,NA
"keypoint_rcnn_R_50_FPN_3x_segmentation","keypoint_rcnn_R_50_FPN_3x","segmentation","coco2017","keypoint_rcnn_R_50_FPN_3x","Convolutional",NA,"Keypoint-RCNN-ResNet50-FPN","Keypoint-RCNN-ResNet50-FPN, trained on segmentation with the CoCo2017 dataset.",NA,NA,"srpr",0.358611519034415,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"crossvit_base_240_classification","crossvit_base_240","classification","imagenet","crossvit_base_240","Transformer",383,"CrossViT-B","CrossViT-B trained on image classification with the ImageNet dataset.",80095620,104718800,"srpr",0.359044434920278,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,NA
"vit_base_patch16_224_in21k_classification","vit_base_patch16_224_in21k","classification","imagenet21k","vit_base_patch16_224","Transformer",225,"ViT-B-P16-IN21K","ViT-B-P16-IN21K trained on image classification with the ImageNet21K dataset.",57223350,102443859,"srpr",0.359102373725841,NA,NA,NA,NA,NA,NA,NA,NA,NA,"imagenet21k"
"vgg16_classification","vgg16","classification","imagenet","vgg16","Convolutional",40,"VGG16","VGG16 trained on image classification with the ImageNet dataset.",28677072,138357544,"srpr",0.359138281241716,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"ViT-L-SLIP-CC12M_slip","ViT-L-SLIP-CC12M","slip","YFCC15M","ViT-L","Transformer",225,"ViT-L-SLIP-CC12M","ViT-L-SLIP-CC12M trained via combined self- and language supervision with the YFCC15M dataset.",57181200,85646592,"srpr",0.359949225579971,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"deit_base_patch16_224_classification","deit_base_patch16_224","classification","imagenet","deit_base_patch16_224","Transformer",225,"DeiT-B-P16-224","DeiT-B-P16-224 trained on image classification with the ImageNet dataset.",57181664,86415592,"srpr",0.360004042997585,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,NA
"convit_base_classification","convit_base","classification","imagenet","convit_base","Hybrid",219,"ConViT-B","ConViT-B trained on image classification with the ImageNet dataset.",61295088,86388584,"srpr",0.360232641603476,"classification","Hybrid",NA,NA,NA,NA,NA,NA,NA,NA
"resnet18_classification","resnet18","classification","imagenet","resnet18","Convolutional",69,"ResNet18","ResNet18 trained on image classification with the ImageNet dataset.",8231376,11689512,"srpr",0.360396078360941,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"vit_base_patch16_224_classification","vit_base_patch16_224","classification","imagenet","vit_base_patch16_224","Transformer",225,"ViT-B-P16","ViT-B-P16 trained on image classification with the ImageNet dataset.",57181664,86415592,"srpr",0.360701098265523,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,"imagenet"
"vit_base_patch32_224_classification","vit_base_patch32_224","classification","imagenet","vit_base_patch32_224","Transformer",225,"ViT-B-P32","ViT-B-P32 trained on image classification with the ImageNet dataset.",13455632,88185064,"srpr",0.360841728668949,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,"imagenet"
"ViT-B-SLIP_slip","ViT-B-SLIP","slip","YFCC15M","ViT-B","Transformer",225,"ViT-B-SLIP","ViT-B-SLIP trained via combined self- and language supervision with the YFCC15M dataset.",57181200,85646592,"srpr",0.361142211761156,NA,NA,"SLIP",NA,NA,NA,NA,NA,NA,NA
"dino_vitb16_selfsupervised","dino_vitb16","selfsupervised","imagenet","vitb16","Transformer",NA,"Dino-VIT-B16","Dino-VIT-B16 trained via self supervision with the ImageNet dataset.",NA,NA,"srpr",0.361474819085899,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"ViT-B-CLIP_slip","ViT-B-CLIP","slip","YFCC15M","ViT-B","Transformer",225,"ViT-B-CLIP","ViT-B-CLIP trained via pure language supervision with the YFCC15M dataset.",57181200,85646592,"srpr",0.361988333010233,NA,NA,"CLIP",NA,NA,NA,NA,NA,NA,NA
"vit_small_patch16_224_classification","vit_small_patch16_224","classification","imagenet","vit_small_patch16_224","Transformer",225,"ViT-S-P16","ViT-S-P16 trained on image classification with the ImageNet dataset.",28591832,21974632,"srpr",0.361995113869152,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,"imagenet"
"convit_tiny_classification","convit_tiny","classification","imagenet","convit_tiny","Hybrid",219,"ConViT-T","ConViT-T trained on image classification with the ImageNet dataset.",15325272,5672648,"srpr",0.362456480375796,"classification","Hybrid",NA,NA,NA,NA,NA,NA,NA,NA
"ViT-B-SimCLR_slip","ViT-B-SimCLR","slip","YFCC15M","ViT-B","Transformer",225,"ViT-B-SimCLR","ViT-B-SimCLR trained via pure self-supervision with the YFCC15M dataset.",57181200,85646592,"srpr",0.362555511031417,NA,NA,"SimCLR",NA,NA,NA,NA,NA,NA,NA
"ViT-S-SimCLR_slip","ViT-S-SimCLR","slip","YFCC15M","ViT-S","Transformer",225,"ViT-S-SimCLR","ViT-S-SimCLR trained via pure self-supervision with the YFCC15M dataset.",31384848,21589632,"srpr",0.362615712269531,NA,NA,"SimCLR",NA,NA,NA,NA,NA,NA,NA
"mixer_b16_224_in21k_classification","mixer_b16_224_in21k","classification","imagenet21k","mixer_b16_224","MLP-Mixer",210,"Mixer-B16-IN22K","Mixer-B16-IN22K trained on image classification with the ImageNet21K dataset.",52808358,75908739,"srpr",0.362690171431537,NA,NA,NA,NA,NA,NA,NA,NA,NA,"imagenet21k"
"ViT-L-SLIP_slip","ViT-L-SLIP","slip","YFCC15M","ViT-L","Transformer",441,"ViT-L-SLIP","ViT-L-SLIP trained via combined self- and language supervision with the YFCC15M dataset.",151473536,303098880,"srpr",0.363152577698829,NA,NA,"SLIP",NA,NA,NA,NA,NA,NA,NA
"ViT-L-CLIP-CC12M_slip","ViT-L-CLIP-CC12M","slip","YFCC15M","ViT-L","Transformer",225,"ViT-L-CLIP-CC12M","ViT-L-CLIP-CC12M trained via pure language supervision with the YFCC15M dataset.",57181200,85646592,"srpr",0.363216613899044,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"regnetx_064_classification","regnetx_064","classification","imagenet","regnetx_064","Convolutional",373,"RegNetX-64","RegNetX-64 trained on image classification with the ImageNet dataset.",101428288,26209256,"srpr",0.363429892716458,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"vit_base_patch32_224_in21k_classification","vit_base_patch32_224_in21k","classification","imagenet21k","vit_base_patch32_224","Transformer",225,"ViT-B-P32-IN21K","ViT-B-P32-IN21K trained on image classification with the ImageNet21K dataset.",13497318,104213331,"srpr",0.363919375655843,NA,NA,NA,NA,NA,NA,NA,NA,NA,"imagenet21k"
"regnety_064_classification","regnety_064","classification","imagenet","regnety_064","Convolutional",658,"RegNetY-64","RegNetY-64 trained on image classification with the ImageNet dataset.",103013924,30583252,"srpr",0.364268107664421,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"tnt_s_patch16_224_classification","tnt_s_patch16_224","classification","imagenet","tnt_s_patch16_224","Transformer",NA,"TnT-P16-224","TnT-P16-224 trained on image classification with the ImageNet dataset.",NA,NA,"srpr",0.364340243502079,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,NA
"vit_large_patch16_224_in21k_classification","vit_large_patch16_224_in21k","classification","imagenet21k","vit_large_patch16_224","Transformer",441,"ViT-L-P16-IN21K","ViT-L-P16-IN21K trained on image classification with the ImageNet21K dataset.",151515174,325487955,"srpr",0.365933579988809,NA,NA,NA,NA,NA,NA,NA,NA,NA,"imagenet21k"
"pit_b_224_classification","pit_b_224","classification","imagenet","pit_b_224","Transformer",254,"PiT-B-224","PiT-B-224 trained on image classification with the ImageNet dataset.",66195824,73518568,"srpr",0.366701215586786,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,NA
"ViT-S-SLIP_slip","ViT-S-SLIP","slip","YFCC15M","ViT-S","Transformer",225,"ViT-S-SLIP","ViT-S-SLIP trained via combined self- and language supervision with the YFCC15M dataset.",31384848,21589632,"srpr",0.366778266453753,NA,NA,"SLIP",NA,NA,NA,NA,NA,NA,NA
"resnet101_classification","resnet101","classification","imagenet","resnet101","Convolutional",345,"ResNet101","ResNet101 trained on image classification with the ImageNet dataset.",56326608,44549160,"srpr",0.366835865628897,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"visformer_small_classification","visformer_small","classification","imagenet","visformer_small","Transformer",226,"Visformer","Visformer trained on image classification with the ImageNet dataset.",31879784,39956168,"srpr",0.366929592785275,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,NA
"inception_v3_classification","inception_v3","classification","imagenet","inception_v3","Convolutional",300,"Inception-V3","Inception-V3 trained on image classification with the ImageNet dataset.",15467136,23834568,"srpr",0.367628711690657,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"mixer_l16_224_classification","mixer_l16_224","classification","imagenet","mixer_l16_224","MLP-Mixer",414,"MLP-Mixer-L16","MLP-Mixer-L16 trained on image classification with the ImageNet dataset.",149342160,208196168,"srpr",0.367649020426015,"classification","MLP-Mixer",NA,NA,NA,NA,NA,NA,NA,"imagenet"
"resnet152_classification","resnet152","classification","imagenet","resnet152","Convolutional",515,"ResNet152","ResNet152 trained on image classification with the ImageNet dataset.",79507920,60192808,"srpr",0.367662629445824,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"ResNet50-PIRL_selfsupervised","ResNet50-PIRL","selfsupervised","imagenet","ResNet50","Convolutional",175,"ResNet50-PIRL","ResNet50-PIRL, a self-supervised representation learner trained on ImageNet.",37562880,23508032,"srpr",0.368270323478444,NA,NA,NA,NA,NA,NA,NA,"PIRL","Contrastive",NA
"seresnext50_32x4d_classification","seresnext50_32x4d","classification","imagenet","seresnext50_32x4d","Convolutional",305,"SEResNext50-32x4D","SEResNext50-32x4D trained on image classification with the ImageNet dataset.",58496224,27559896,"srpr",0.368805017349781,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"vit_large_patch16_224_classification","vit_large_patch16_224","classification","imagenet","vit_large_patch16_224","Transformer",441,"ViT-L-P16","ViT-L-P16 trained on image classification with the ImageNet dataset.",151473488,304123880,"srpr",0.370026240401105,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,"imagenet"
"mixer_l16_224_in21k_classification","mixer_l16_224_in21k","classification","imagenet21k","mixer_l16_224","MLP-Mixer",414,"Mixer-L16-IN22K","Mixer-L16-IN22K trained on image classification with the ImageNet21K dataset.",149383846,229560243,"srpr",0.370307134055699,NA,NA,NA,NA,NA,NA,NA,NA,NA,"imagenet21k"
"retinanet_R_50_FPN_3x_detection","retinanet_R_50_FPN_3x","detection","coco2017","retinanet_R_50_FPN_3x","Convolutional",NA,"RetinaNet-ResNet50-FPN","RetinaNet-ResNet50-FPN, trained on detection with the CoCo2017 dataset.",NA,NA,"srpr",0.370917895695478,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"resmlp_12_224_classification","resmlp_12_224","classification","imagenet","resmlp_12_224","MLP-Mixer",150,"ResMLP-12","ResMLP-12 trained on image classification with the ImageNet dataset.",19269584,15322456,"srpr",0.370945251674132,"classification","MLP-Mixer",NA,NA,NA,NA,NA,NA,NA,NA
"dla34_classification","dla34","classification","imagenet","dla34","Convolutional",151,"DLA34","DLA34 trained on image classification with the ImageNet dataset.",17578680,15742104,"srpr",0.370989785979009,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"mixer_b16_224_classification","mixer_b16_224","classification","imagenet","mixer_b16_224","MLP-Mixer",210,"MLP-Mixer-B16","MLP-Mixer-B16 trained on image classification with the ImageNet dataset.",52766672,59880472,"srpr",0.371272255233467,"classification","MLP-Mixer",NA,NA,NA,NA,NA,NA,NA,"imagenet"
"skresnext50_32x4d_classification","skresnext50_32x4d","classification","imagenet","skresnext50_32x4d","Convolutional",497,"SKResNext50-32x4D","SKResNext50-32x4D trained on image classification with the ImageNet dataset.",99238128,27479784,"srpr",0.37143492598498,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"xcit_nano_12_p16_224_classification","xcit_nano_12_p16_224","classification","imagenet","xcit_nano_12_p16_224","Transformer",NA,"XCIT-N-12-P16","XCIT-N-12-P16 trained on image classification with the ImageNet dataset.",NA,NA,"srpr",0.371985606557022,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,NA
"faster_rcnn_R_50_FPN_3x_detection","faster_rcnn_R_50_FPN_3x","detection","coco2017","faster_rcnn_R_50_FPN_3x","Convolutional",NA,"Faster-RCNN-ResNet50-FPN","Faster-RCNN-ResNet50-FPN, trained on detection with the CoCo2017 dataset.",NA,NA,"srpr",0.372096823017697,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"ghostnet_100_classification","ghostnet_100","classification","imagenet","ghostnet_100","Convolutional",287,"GhostNet100","GhostNet100 trained on image classification with the ImageNet dataset.",13446920,5182508,"srpr",0.372382223926051,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"pit_ti_224_classification","pit_ti_224","classification","imagenet","pit_ti_224","Transformer",236,"PiT-T-224","PiT-T-224 trained on image classification with the ImageNet dataset.",11698296,4800552,"srpr",0.372527974467732,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,NA
"mask_rcnn_R_50_FPN_3x_segmentation","mask_rcnn_R_50_FPN_3x","segmentation","coco2017","mask_rcnn_R_50_FPN_3x","Convolutional",NA,"Mask-RCNN-ResNet50-FPN","Mask-RCNN-ResNet50-FPN, trained on segmentation with the CoCo2017 dataset.",NA,NA,"srpr",0.372598157766612,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"xcit_nano_12_p8_224_classification","xcit_nano_12_p8_224","classification","imagenet","xcit_nano_12_p8_224","Transformer",NA,"XCIT-N-12-P8","XCIT-N-12-P8 trained on image classification with the ImageNet dataset.",NA,NA,"srpr",0.372708219257361,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,NA
"convnext_large_classification","convnext_large","classification","imagenet","convnext_large","Convolutional",382,"ConvNext-L","ConvNext-L trained on image classification with the ImageNet dataset.",137593808,197740264,"srpr",0.372724353171289,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,"imagenet"
"semnasnet_100_classification","semnasnet_100","classification","imagenet","semnasnet_100","Convolutional",274,"SemNASNet100","SemNASNet100 trained on image classification with the ImageNet dataset.",27843180,3887038,"srpr",0.37317315375324,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"ViT-B/16_clip","ViT-B/16","clip","openai400M","ViT-B/16","Transformer",89,"CLiP-ViT-B/32","CLiP-ViT-B/32, a hybrid vision-language model.",24056576,57298944,"srpr",0.373424547008727,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"efficientnet_b1_classification","efficientnet_b1","classification","imagenet","efficientnet_b1","Convolutional",435,"EfficientNet-B1","EfficientNet-B1 trained on image classification with the ImageNet dataset.",42450128,7794184,"srpr",0.373602111635317,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"shufflenet_v2_x1_0_classification","shufflenet_v2_x1_0","classification","imagenet","shufflenet_v2_x1_0","Convolutional",168,"ShuffleNet-V2-x1.0","ShuffleNet-V2-x1.0 trained on image classification with the ImageNet dataset.",6284192,2278604,"srpr",0.373714016483843,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"swin_base_patch4_window7_224_classification","swin_base_patch4_window7_224","classification","imagenet","swin_base_patch4_window7_224","Transformer",NA,"Swin-B-P4-W7","Swin-B-P4-W7 trained on image classification with the ImageNet dataset.",NA,NA,"srpr",0.374169525378722,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,"imagenet"
"efficientnet_b3_classification","efficientnet_b3","classification","imagenet","efficientnet_b3","Convolutional",492,"EfficientNet-B3","EfficientNet-B3 trained on image classification with the ImageNet dataset.",59058840,12233232,"srpr",0.374265227726235,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"vit_base_r50_s16_224_in21k_classification","vit_base_r50_s16_224_in21k","classification","imagenet21k","vit_base_r50_s16_224","Transformer",496,"ViT-B-R50-S16-IN21K","ViT-B-R50-S16-IN21K trained on image classification with the ImageNet21K dataset.",124710838,115125907,"srpr",0.374418031780095,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"swin_large_patch4_window7_224_classification","swin_large_patch4_window7_224","classification","imagenet","swin_large_patch4_window7_224","Transformer",NA,"Swin-L-P4-W7","Swin-L-P4-W7 trained on image classification with the ImageNet dataset.",NA,NA,"srpr",0.374940014929394,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,"imagenet"
"xception_classification","xception","classification","imagenet","xception","Convolutional",204,"XCeption","XCeption trained on image classification with the ImageNet dataset.",52151632,22855952,"srpr",0.375358835645471,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"swin_base_patch4_window7_224_in22k_classification","swin_base_patch4_window7_224_in22k","classification","imagenet21k","swin_base_patch4_window7_224","Transformer",NA,"Swin-B-P4-W7-IN21K","Swin-B-P4-W7-IN21K trained on image classification with the ImageNet21K dataset.",NA,NA,"srpr",0.375563520099759,NA,NA,NA,NA,NA,NA,NA,NA,NA,"imagenet21k"
"ViT-L/14_clip","ViT-L/14","clip","openai400M","ViT-L/14","Transformer",173,"CLiP-ViT-L/14","CLiP-ViT-L/14, a hybrid vision-language model.",82898688,202153984,"srpr",0.376087889753873,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"googlenet_classification","googlenet","classification","imagenet","googlenet","Convolutional",197,"GoogleNet","GoogleNet trained on image classification with the ImageNet dataset.",12335584,6624904,"srpr",0.376263516462356,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"mobilenetv3_large_100_classification","mobilenetv3_large_100","classification","imagenet","mobilenetv3_large_100","Convolutional",265,"MobileNet-V3-Large","MobileNet-V3-Large trained on image classification with the ImageNet dataset.",20046944,5483032,"srpr",0.376416075884129,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"hardcorenas_f_classification","hardcorenas_f","classification","imagenet","hardcorenas_f","Convolutional",326,"HardCoreNAS-F","HardCoreNAS-F trained on image classification with the ImageNet dataset.",25099520,8199688,"srpr",0.376603683686562,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"ResNet50-BarlowTwins-BS2048_selfsupervised","ResNet50-BarlowTwins-BS2048","selfsupervised","imagenet","ResNet50","Convolutional",175,"ResNet50-BarlowTwins-BS2048","ResNet50-BarlowTwins-BS2048, a self-supervised representation learner trained on ImageNet.",37562880,23508032,"srpr",0.376752569529619,NA,NA,NA,NA,NA,NA,NA,"BarlowTwins-BS2048","Contrastive",NA
"jx_nest_tiny_classification","jx_nest_tiny","classification","imagenet","jx_nest_tiny","Transformer",213,"JX-NesT-Tiny","JX-NesT-Tiny trained on image classification with the ImageNet dataset.",52424528,16530760,"srpr",0.376900773478593,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,NA
"resnet50_classification","resnet50","classification","imagenet","resnet50","Convolutional",175,"ResNet50","ResNet50 trained on image classification with the ImageNet dataset.",37560784,25557032,"srpr",0.377139987051103,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"eca_nfnet_l0_classification","eca_nfnet_l0","classification","imagenet","eca_nfnet_l0","Convolutional",184,"ECA-NFNeT-L0","ECA-NFNeT-L0 trained on image classification with the ImageNet dataset.",32555168,24111108,"srpr",0.377184055124845,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"densenet121_classification","densenet121","classification","imagenet","densenet121","Convolutional",429,"DenseNet121","DenseNet121 trained on image classification with the ImageNet dataset.",41096144,7978856,"srpr",0.377349673337281,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"convmixer_768_32_classification","convmixer_768_32","classification","imagenet","convmixer_768_32","Hybrid",232,"ConvMixer-768-32","ConvMixer-768-32 trained on image classification with the ImageNet dataset.",178524368,21110248,"srpr",0.37741747943438,"classification","Hybrid",NA,NA,NA,NA,NA,NA,NA,NA
"nfnet_l0_classification","nfnet_l0","classification","imagenet","nfnet_l0","Convolutional",220,"NF-Net-L0","NF-Net-L0 trained on image classification with the ImageNet dataset.",32566496,35041672,"srpr",0.377827955861241,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"mnasnet1_0_classification","mnasnet1_0","classification","imagenet","mnasnet1_0","Convolutional",158,"MNASNet1.0","MNASNet1.0 trained on image classification with the ImageNet dataset.",16172496,4383312,"srpr",0.377888909223153,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"swin_large_patch4_window7_224_in22k_classification","swin_large_patch4_window7_224_in22k","classification","imagenet21k","swin_large_patch4_window7_224","Transformer",NA,"Swin-L-P4-W7-IN21K","Swin-L-P4-W7-IN21K trained on image classification with the ImageNet21K dataset.",NA,NA,"srpr",0.378316514575918,NA,NA,NA,NA,NA,NA,NA,NA,NA,"imagenet21k"
"nf_resnet50_classification","nf_resnet50","classification","imagenet","nf_resnet50","Convolutional",151,"NF-ResNet50","NF-ResNet50 trained on image classification with the ImageNet dataset.",33527712,25530472,"srpr",0.378349924443186,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"gmixer_24_224_classification","gmixer_24_224","classification","imagenet","gmixer_24_224","Convolutional",414,"GMixer-24","GMixer-24 trained on image classification with the ImageNet dataset.",41701328,24721096,"srpr",0.378759402099727,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"hardcorenas_a_classification","hardcorenas_a","classification","imagenet","hardcorenas_a","Convolutional",204,"HardCoreNAS-A","HardCoreNAS-A trained on image classification with the ImageNet dataset.",19698736,5260232,"srpr",0.379152174921648,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"ResNet50-SimCLR_selfsupervised","ResNet50-SimCLR","selfsupervised","imagenet","ResNet50","Convolutional",175,"ResNet50-SimCLR","ResNet50-SimCLR, a self-supervised representation learner trained on ImageNet.",37562880,23508032,"srpr",0.379201326422581,NA,NA,NA,NA,NA,NA,NA,"SimCLR","Contrastive",NA
"yolov5m_yolo","yolov5m","yolo","coco,voc","yolov5m","Convolutional",NA,"YOLO-V5-M","YOLO-V5-M, an object detection model.",NA,NA,"srpr",0.379381838688708,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"ResNet50-SwAV-BS4096-2x224+6x96_selfsupervised","ResNet50-SwAV-BS4096-2x224+6x96","selfsupervised","imagenet","ResNet50","Convolutional",175,"ResNet50-SwAV-BS4096","ResNet50-SwAV-BS4096-2x224+6x96, a self-supervised representation learner trained on ImageNet.",37562880,23508032,"srpr",0.379807316602141,NA,NA,NA,NA,NA,NA,NA,"SwAV-BS4096-2x224+6x96","Contrastive",NA
"ResNet50-DeepClusterV2-2x224+6x96_selfsupervised","ResNet50-DeepClusterV2-2x224+6x96","selfsupervised","imagenet","ResNet50","Convolutional",175,"ResNet50-DeepClusterV2","ResNet50-DeepClusterV2-2x224+6x96, a self-supervised representation learner trained on ImageNet.",37562880,23508032,"srpr",0.379963541173272,NA,NA,NA,NA,NA,NA,NA,"DeepClusterV2-2x224+6x96","Contrastive",NA
"dino_resnet50_selfsupervised","dino_resnet50","selfsupervised","imagenet","resnet50","Convolutional",NA,"Dino-ResNet50","Dino-ResNet50 trained via self supervision with the ImageNet dataset.",NA,NA,"srpr",0.3804089720085,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"RegNet-64Gf-SEER-INFT_seer","RegNet-64Gf-SEER-INFT","seer","random1B","RegNet-64Gf","Convolutional",NA,"RegNet-64Gf-SEER-INFT","RegNet-64Gf trained via large-scale self-supervision on 1 billion images.",NA,NA,"srpr",0.380620471703826,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"convnext_base_classification","convnext_base","classification","imagenet","convnext_base","Convolutional",382,"ConvNext-B","ConvNext-B trained on image classification with the ImageNet dataset.",91729872,88573416,"srpr",0.380623259371016,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,"imagenet"
"mobilenet_v2_classification","mobilenet_v2","classification","imagenet","mobilenet_v2","Convolutional",159,"MobileNet-V2","MobileNet-V2 trained on image classification with the ImageNet dataset.",20037616,3504872,"srpr",0.380700688391469,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"swin_tiny_patch4_window7_224_classification","swin_tiny_patch4_window7_224","classification","imagenet","swin_tiny_patch4_window7_224","Transformer",NA,"Swin-T-P4-W7","Swin-T-P4-W7 trained on image classification with the ImageNet dataset.",NA,NA,"srpr",0.380861000038704,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,NA
"resmlp_24_224_classification","resmlp_24_224","classification","imagenet","resmlp_24_224","MLP-Mixer",294,"ResMLP-24","ResMLP-24 trained on image classification with the ImageNet dataset.",38236112,29964616,"srpr",0.380981555708929,"classification","MLP-Mixer",NA,NA,NA,NA,NA,NA,NA,NA
"BiT-Expert-ResNet-V2-Bird_bit_expert","BiT-Expert-ResNet-V2-Bird","bit_expert","big_transfer","ResNet50-V2","Convolutional",168,"BiT-Expert-ResNet-V2-Bird","ResNet50-V2 trained first via ImageNet21K dataset, then as an expert on the Bird subset.",35578624,23496256,"srpr",0.381216571004133,NA,NA,NA,NA,NA,"Bird",NA,NA,NA,NA
"yolov5s_yolo","yolov5s","yolo","coco,voc","yolov5s","Convolutional",NA,"YOLO-V5-S","YOLO-V5-S, an object detection model.",NA,NA,"srpr",0.38134012826202,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"poolformer_s36_classification","poolformer_s36","classification","imagenet","poolformer_s36","Transformer",483,"PoolFormer-S36","PoolFormer-S36 trained on image classification with the ImageNet dataset.",78339280,30842792,"srpr",0.381347261780746,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,NA
"coat_lite_tiny_classification","coat_lite_tiny","classification","imagenet","coat_lite_tiny","Transformer",279,"CoaT-Lite-Tiny","CoaT-Lite-Tiny trained on image classification with the ImageNet dataset.",36283152,5878632,"srpr",0.381500540875735,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,NA
"ViT-B/32_clip","ViT-B/32","clip","openai400M","ViT-B/32","Transformer",89,"CLiP-ViT-B/32","CLiP-ViT-B/32, a hybrid vision-language model.",6106112,59068416,"srpr",0.381598652041944,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"RegNet-128Gf-SEER-INFT_seer","RegNet-128Gf-SEER-INFT","seer","random1B","RegNet-128Gf","Convolutional",NA,"RegNet-128Gf-SEER-INFT","RegNet-128Gf trained via large-scale self-supervision on 1 billion images.",NA,NA,"srpr",0.381942456030229,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"yolov5l_yolo","yolov5l","yolo","coco,voc","yolov5l","Convolutional",NA,"YOLO-V5-L","YOLO-V5-L, an object detection model.",NA,NA,"srpr",0.382078643820392,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"BiT-Expert-ResNet-V2-Flower_bit_expert","BiT-Expert-ResNet-V2-Flower","bit_expert","big_transfer","ResNet50-V2","Convolutional",168,"BiT-Expert-ResNet-V2-Flower","ResNet50-V2 trained first via ImageNet21K dataset, then as an expert on the Flower subset.",35578624,23496256,"srpr",0.382409151268333,NA,NA,NA,NA,NA,"Flower",NA,NA,NA,NA
"cspresnet50_classification","cspresnet50","classification","imagenet","cspresnet50","Convolutional",329,"CSP-ResNet50","CSP-ResNet50 trained on image classification with the ImageNet dataset.",51186592,21616168,"srpr",0.38265824134162,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"BiT-Expert-ResNet-V2-Instrument_bit_expert","BiT-Expert-ResNet-V2-Instrument","bit_expert","big_transfer","ResNet50-V2","Convolutional",168,"BiT-Expert-ResNet-V2-Instrument","ResNet50-V2 trained first via ImageNet21K dataset, then as an expert on the Instrument subset.",35578624,23496256,"srpr",0.382733491983884,NA,NA,NA,NA,NA,"Instrument",NA,NA,NA,NA
"BiT-Expert-ResNet-V2-Vehicle_bit_expert","BiT-Expert-ResNet-V2-Vehicle","bit_expert","big_transfer","ResNet50-V2","Convolutional",168,"BiT-Expert-ResNet-V2-Vehicle","ResNet50-V2 trained first via ImageNet21K dataset, then as an expert on the Vehicle subset.",35578624,23496256,"srpr",0.382770877921798,NA,NA,NA,NA,NA,"Vehicle",NA,NA,NA,NA
"BiT-Expert-ResNet-V2-Mammal_bit_expert","BiT-Expert-ResNet-V2-Mammal","bit_expert","big_transfer","ResNet50-V2","Convolutional",168,"BiT-Expert-ResNet-V2-Mammal","ResNet50-V2 trained first via ImageNet21K dataset, then as an expert on the Mammal subset.",35578624,23496256,"srpr",0.382864667345842,NA,NA,NA,NA,NA,"Mammal",NA,NA,NA,NA
"BiT-Expert-ResNet-V2-Animal_bit_expert","BiT-Expert-ResNet-V2-Animal","bit_expert","big_transfer","ResNet50-V2","Convolutional",168,"BiT-Expert-ResNet-V2-Animal","ResNet50-V2 trained first via ImageNet21K dataset, then as an expert on the Animal subset.",35578624,23496256,"srpr",0.383162925724214,NA,NA,NA,NA,NA,"Animal",NA,NA,NA,NA
"resmlp_36_224_classification","resmlp_36_224","classification","imagenet","resmlp_36_224","MLP-Mixer",438,"ResMLP-36","ResMLP-36 trained on image classification with the ImageNet dataset.",57202640,44606776,"srpr",0.383253234683088,"classification","MLP-Mixer",NA,NA,NA,NA,NA,NA,NA,NA
"BiT-Expert-ResNet-V2-Food_bit_expert","BiT-Expert-ResNet-V2-Food","bit_expert","big_transfer","ResNet50-V2","Convolutional",168,"BiT-Expert-ResNet-V2-Food","ResNet50-V2 trained first via ImageNet21K dataset, then as an expert on the Food subset.",35578624,23496256,"srpr",0.383688141281276,NA,NA,NA,NA,NA,"Food",NA,NA,NA,NA
"levit_128_classification","levit_128","classification","imagenet","levit_128","Transformer",NA,"LeViT128","LeViT128 trained on image classification with the ImageNet dataset.",NA,NA,"srpr",0.383924828264403,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,NA
"BiT-Expert-ResNet-V2-Arthropod_bit_expert","BiT-Expert-ResNet-V2-Arthropod","bit_expert","big_transfer","ResNet50-V2","Convolutional",168,"BiT-Expert-ResNet-V2-Arthropod","ResNet50-V2 trained first via ImageNet21K dataset, then as an expert on the Arthropod subset.",35578624,23496256,"srpr",0.38418258082998,NA,NA,NA,NA,NA,"Arthropod",NA,NA,NA,NA
"BiT-Expert-ResNet-V2-Relation_bit_expert","BiT-Expert-ResNet-V2-Relation","bit_expert","big_transfer","ResNet50-V2","Convolutional",168,"BiT-Expert-ResNet-V2-Relation","ResNet50-V2 trained first via ImageNet21K dataset, then as an expert on the Relation subset.",35578624,23496256,"srpr",0.384333879285846,NA,NA,NA,NA,NA,"Relation",NA,NA,NA,NA
"RegNet-32Gf-SEER-INFT_seer","RegNet-32Gf-SEER-INFT","seer","random1B","RegNet-32Gf","Convolutional",NA,"RegNet-32Gf-SEER-INFT","RegNet-32Gf trained via large-scale self-supervision on 1 billion images.",NA,NA,"srpr",0.384379974145801,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"RegNet-128Gf-SEER_seer","RegNet-128Gf-SEER","seer","random1B","RegNet-128Gf","Convolutional",NA,"RegNet-128Gf-SEER","RegNet-128Gf trained via large-scale self-supervision on 1 billion images.",NA,NA,"srpr",0.385398745230844,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"resmlp_big_24_224_classification","resmlp_big_24_224","classification","imagenet","resmlp_big_24_224","MLP-Mixer",294,"ResMLP-Big-24","ResMLP-Big-24 trained on image classification with the ImageNet dataset.",305874896,129026152,"srpr",0.385517686425353,"classification","MLP-Mixer",NA,NA,NA,NA,NA,NA,NA,"imagenet"
"RN101_clip","RN101","clip","openai400M","ResNet101","Convolutional",387,"CLiP-ResNet101","CLiP-ResNet101, a hybrid vision-language model.",63097344,42519392,"srpr",0.385703422688185,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"BiT-Expert-ResNet-V2-Abstraction_bit_expert","BiT-Expert-ResNet-V2-Abstraction","bit_expert","big_transfer","ResNet50-V2","Convolutional",168,"BiT-Expert-ResNet-V2-Abstraction","ResNet50-V2 trained first via ImageNet21K dataset, then as an expert on the Abstraction subset.",35578624,23496256,"srpr",0.386060794692325,NA,NA,NA,NA,NA,"Abstraction",NA,NA,NA,NA
"BiT-Expert-ResNet-V2-Object_bit_expert","BiT-Expert-ResNet-V2-Object","bit_expert","big_transfer","ResNet50-V2","Convolutional",168,"BiT-Expert-ResNet-V2-Object","ResNet50-V2 trained first via ImageNet21K dataset, then as an expert on the Object subset.",35578624,23496256,"srpr",0.386261481150798,NA,NA,NA,NA,NA,"Object",NA,NA,NA,NA
"RegNet-32Gf-SEER_seer","RegNet-32Gf-SEER","seer","random1B","RegNet-32Gf","Convolutional",NA,"RegNet-32Gf-SEER","RegNet-32Gf trained via large-scale self-supervision on 1 billion images.",NA,NA,"srpr",0.386614578406024,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"gmlp_s16_224_classification","gmlp_s16_224","classification","imagenet","gmlp_s16_224","Convolutional",366,"GMLP-S16","GMLP-S16 trained on image classification with the ImageNet dataset.",49876944,19422656,"srpr",0.387527637268852,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"RegNet-64Gf-SEER_seer","RegNet-64Gf-SEER","seer","random1B","RegNet-64Gf","Convolutional",NA,"RegNet-64Gf-SEER","RegNet-64Gf trained via large-scale self-supervision on 1 billion images.",NA,NA,"srpr",0.389183580389383,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"convnext_base_in22k_classification","convnext_base_in22k","classification","imagenet21k","convnext_base","Convolutional",382,"ConvNext-Base-IN21K","ConvNext-Base-IN21K trained on image classification with the ImageNet21K dataset.",91771554,109935441,"srpr",0.389265983637907,NA,NA,NA,NA,NA,NA,NA,NA,NA,"imagenet21k"
"convnext_large_in22k_classification","convnext_large_in22k","classification","imagenet21k","convnext_large","Convolutional",382,"ConvNext-Large-IN21K","ConvNext-Large-IN21K trained on image classification with the ImageNet21K dataset.",137635490,229772881,"srpr",0.392918306585928,NA,NA,NA,NA,NA,NA,NA,NA,NA,"imagenet21k"
"RN50_clip","RN50","clip","openai400M","ResNet50","Convolutional",200,"CLiP-ResNet50","CLiP-ResNet50, a hybrid vision-language model.",43479552,23527264,"srpr",0.39498890847139,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"resmlp_big_24_224_in22ft1k_classification","resmlp_big_24_224_in22ft1k","classification","imagenet21k","resmlp_big_24_224","MLP-Mixer",294,"ResMLP-Big-24-IN21K","ResMLP-Big-24-IN21K trained on image classification with the ImageNet21K dataset.",305874896,129026152,"srpr",0.398387253697393,NA,NA,NA,NA,NA,NA,NA,NA,NA,"imagenet21k"
"shufflenet_v2_x1_0_random","shufflenet_v2_x1_0","random",NA,"shufflenet_v2_x1_0","Convolutional",168,"ShuffleNet-V2-x1.0","ShuffleNet-V2-x1.0 randomly initialized, with no training.",6284192,2278604,"wrsa",0.0484111170014511,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"mobilenetv3_large_100_random","mobilenetv3_large_100","random",NA,"mobilenetv3_large_100","Convolutional",265,"MobileNet-V3-Large","MobileNet-V3-Large randomly initialized, with no training.",20046944,5483032,"wrsa",0.0570721362434575,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"regnetx_064_random","regnetx_064","random",NA,"regnetx_064","Convolutional",373,"RegNetX-64","RegNetX-64 randomly initialized, with no training.",101428288,26209256,"wrsa",0.0753292879536618,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"resnet152_random","resnet152","random",NA,"resnet152","Convolutional",515,"ResNet152","ResNet152 randomly initialized, with no training.",79507920,60192808,"wrsa",0.0753971550785051,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"gmixer_24_224_random","gmixer_24_224","random",NA,"gmixer_24_224","Convolutional",414,"GMixer-24","GMixer-24 randomly initialized, with no training.",41701328,24721096,"wrsa",0.0782555879401682,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"convmixer_768_32_random","convmixer_768_32","random",NA,"convmixer_768_32","Hybrid",232,"ConvMixer-768-32","ConvMixer-768-32 randomly initialized, with no training.",178524368,21110248,"wrsa",0.0823022326917199,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"efficientnet_b1_random","efficientnet_b1","random",NA,"efficientnet_b1","Convolutional",435,"EfficientNet-B1","EfficientNet-B1 randomly initialized, with no training.",42450128,7794184,"wrsa",0.084832218326512,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"resnet101_random","resnet101","random",NA,"resnet101","Convolutional",345,"ResNet101","ResNet101 randomly initialized, with no training.",56326608,44549160,"wrsa",0.0856224005472952,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"tnt_s_patch16_224_random","tnt_s_patch16_224","random",NA,"tnt_s_patch16_224","Transformer",NA,"TnT-P16-224","TnT-P16-224 randomly initialized, with no training.",NA,NA,"wrsa",0.0893335210621157,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"semnasnet_100_random","semnasnet_100","random",NA,"semnasnet_100","Convolutional",274,"SemNASNet100","SemNASNet100 randomly initialized, with no training.",27843180,3887038,"wrsa",0.0895982684190234,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"resnet50_random","resnet50","random",NA,"resnet50","Convolutional",175,"ResNet50","ResNet50 randomly initialized, with no training.",37560784,25557032,"wrsa",0.0927240565216247,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"pit_ti_224_random","pit_ti_224","random",NA,"pit_ti_224","Transformer",236,"PiT-T-224","PiT-T-224 randomly initialized, with no training.",11698296,4800552,"wrsa",0.0930978601743859,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"nfnet_l0_random","nfnet_l0","random",NA,"nfnet_l0","Convolutional",220,"NF-Net-L0","NF-Net-L0 randomly initialized, with no training.",32566496,35041672,"wrsa",0.093717142706907,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"poolformer_s36_random","poolformer_s36","random",NA,"poolformer_s36","Transformer",483,"PoolFormer-S36","PoolFormer-S36 randomly initialized, with no training.",78339280,30842792,"wrsa",0.0942273195435448,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"levit_128_random","levit_128","random",NA,"levit_128","Transformer",NA,"LeViT128","LeViT128 randomly initialized, with no training.",NA,NA,"wrsa",0.0953406106613421,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"convit_tiny_random","convit_tiny","random",NA,"convit_tiny","Hybrid",219,"ConViT-T","ConViT-T randomly initialized, with no training.",15325272,5672648,"wrsa",0.0962812794593525,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"coat_lite_tiny_random","coat_lite_tiny","random",NA,"coat_lite_tiny","Transformer",279,"CoaT-Lite-Tiny","CoaT-Lite-Tiny randomly initialized, with no training.",36283152,5878632,"wrsa",0.096478006812647,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"vit_tiny_patch16_224_random","vit_tiny_patch16_224","random",NA,"vit_tiny_patch16_224","Transformer",225,"ViT-T-P16","ViT-T-P16 randomly initialized, with no training.",14296916,5679400,"wrsa",0.0967475017787395,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"pit_b_224_random","pit_b_224","random",NA,"pit_b_224","Transformer",254,"PiT-B-224","PiT-B-224 randomly initialized, with no training.",66195824,73518568,"wrsa",0.0977833412839977,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"resmlp_big_24_224_random","resmlp_big_24_224","random",NA,"resmlp_big_24_224","MLP-Mixer",294,"ResMLP-Big-24","ResMLP-Big-24 randomly initialized, with no training.",305874896,129026152,"wrsa",0.0982949004527945,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"mobilenet_v2_random","mobilenet_v2","random",NA,"mobilenet_v2","Convolutional",159,"MobileNet-V2","MobileNet-V2 randomly initialized, with no training.",20037616,3504872,"wrsa",0.0998487672642903,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"crossvit_base_240_random","crossvit_base_240","random",NA,"crossvit_base_240","Transformer",383,"CrossViT-B","CrossViT-B randomly initialized, with no training.",80095620,104718800,"wrsa",0.10021241534237,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"resmlp_24_224_random","resmlp_24_224","random",NA,"resmlp_24_224","MLP-Mixer",294,"ResMLP-24","ResMLP-24 randomly initialized, with no training.",38236112,29964616,"wrsa",0.100697672157939,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"resmlp_36_224_random","resmlp_36_224","random",NA,"resmlp_36_224","MLP-Mixer",438,"ResMLP-36","ResMLP-36 randomly initialized, with no training.",57202640,44606776,"wrsa",0.100966158828301,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"convnext_base_random","convnext_base","random",NA,"convnext_base","Convolutional",382,"ConvNext-B","ConvNext-B randomly initialized, with no training.",91729872,88573416,"wrsa",0.101573748020998,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"efficientnet_b3_random","efficientnet_b3","random",NA,"efficientnet_b3","Convolutional",492,"EfficientNet-B3","EfficientNet-B3 randomly initialized, with no training.",59058840,12233232,"wrsa",0.101986587329274,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"mixer_b16_224_random","mixer_b16_224","random",NA,"mixer_b16_224","MLP-Mixer",210,"MLP-Mixer-B16","MLP-Mixer-B16 randomly initialized, with no training.",52766672,59880472,"wrsa",0.10264415578698,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"autoencoding_taskonomy","autoencoding","taskonomy","taskonomy","resnet50","Convolutional",179,"Autoencoder","Image compression and decompression",37564576,23655504,"wrsa",0.103054515047104,NA,NA,NA,"autoencoding","2D",NA,NA,NA,NA,NA
"resmlp_12_224_random","resmlp_12_224","random",NA,"resmlp_12_224","MLP-Mixer",150,"ResMLP-12","ResMLP-12 randomly initialized, with no training.",19269584,15322456,"wrsa",0.10305792347042,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"vit_small_patch32_224_random","vit_small_patch32_224","random",NA,"vit_small_patch32_224","Transformer",225,"ViT-S-P32","ViT-S-P32 randomly initialized, with no training.",6728816,22859368,"wrsa",0.105929944355862,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"vit_small_patch16_224_random","vit_small_patch16_224","random",NA,"vit_small_patch16_224","Transformer",225,"ViT-S-P16","ViT-S-P16 randomly initialized, with no training.",28591832,21974632,"wrsa",0.106113516154755,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"xcit_nano_12_p16_224_random","xcit_nano_12_p16_224","random",NA,"xcit_nano_12_p16_224","Transformer",NA,"XCIT-N-12-P16","XCIT-N-12-P16 randomly initialized, with no training.",NA,NA,"wrsa",0.106375443302492,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"convnext_large_random","convnext_large","random",NA,"convnext_large","Convolutional",382,"ConvNext-L","ConvNext-L randomly initialized, with no training.",137593808,197740264,"wrsa",0.106915540208708,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"eca_nfnet_l0_random","eca_nfnet_l0","random",NA,"eca_nfnet_l0","Convolutional",184,"ECA-NFNeT-L0","ECA-NFNeT-L0 randomly initialized, with no training.",32555168,24111108,"wrsa",0.108979729706682,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"inception_v3_random","inception_v3","random",NA,"inception_v3","Convolutional",300,"Inception-V3","Inception-V3 randomly initialized, with no training.",15467136,23834568,"wrsa",0.109487186892379,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"swin_tiny_patch4_window7_224_random","swin_tiny_patch4_window7_224","random",NA,"swin_tiny_patch4_window7_224","Transformer",NA,"Swin-T-P4-W7","Swin-T-P4-W7 randomly initialized, with no training.",NA,NA,"wrsa",0.110466715880929,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"swin_base_patch4_window7_224_random","swin_base_patch4_window7_224","random",NA,"swin_base_patch4_window7_224","Transformer",NA,"Swin-B-P4-W7","Swin-B-P4-W7 randomly initialized, with no training.",NA,NA,"wrsa",0.110710114465379,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"gmlp_s16_224_random","gmlp_s16_224","random",NA,"gmlp_s16_224","Convolutional",366,"GMLP-S16","GMLP-S16 randomly initialized, with no training.",49876944,19422656,"wrsa",0.111295995524232,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"deit_base_patch16_224_random","deit_base_patch16_224","random",NA,"deit_base_patch16_224","Transformer",225,"DeiT-B-P16-224","DeiT-B-P16-224 randomly initialized, with no training.",57181664,86415592,"wrsa",0.111822031413063,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"resnet18_random","resnet18","random",NA,"resnet18","Convolutional",69,"ResNet18","ResNet18 randomly initialized, with no training.",8231376,11689512,"wrsa",0.112547105325948,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"mixer_l16_224_random","mixer_l16_224","random",NA,"mixer_l16_224","MLP-Mixer",414,"MLP-Mixer-L16","MLP-Mixer-L16 randomly initialized, with no training.",149342160,208196168,"wrsa",0.112686206450459,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"vit_base_patch16_224_random","vit_base_patch16_224","random",NA,"vit_base_patch16_224","Transformer",225,"ViT-B-P16","ViT-B-P16 randomly initialized, with no training.",57181664,86415592,"wrsa",0.113179556685399,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"ghostnet_100_random","ghostnet_100","random",NA,"ghostnet_100","Convolutional",287,"GhostNet100","GhostNet100 randomly initialized, with no training.",13446920,5182508,"wrsa",0.114032100524357,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"hardcorenas_f_random","hardcorenas_f","random",NA,"hardcorenas_f","Convolutional",326,"HardCoreNAS-F","HardCoreNAS-F randomly initialized, with no training.",25099520,8199688,"wrsa",0.114184934575579,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"seresnext50_32x4d_random","seresnext50_32x4d","random",NA,"seresnext50_32x4d","Convolutional",305,"SEResNext50-32x4D","SEResNext50-32x4D randomly initialized, with no training.",58496224,27559896,"wrsa",0.115083793325796,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"regnety_064_random","regnety_064","random",NA,"regnety_064","Convolutional",658,"RegNetY-64","RegNetY-64 randomly initialized, with no training.",103013924,30583252,"wrsa",0.115307269900153,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"swin_large_patch4_window7_224_random","swin_large_patch4_window7_224","random",NA,"swin_large_patch4_window7_224","Transformer",NA,"Swin-L-P4-W7","Swin-L-P4-W7 randomly initialized, with no training.",NA,NA,"wrsa",0.11547264488855,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"mnasnet1_0_random","mnasnet1_0","random",NA,"mnasnet1_0","Convolutional",158,"MNASNet1.0","MNASNet1.0 randomly initialized, with no training.",16172496,4383312,"wrsa",0.115479322111051,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"vit_base_patch32_224_random","vit_base_patch32_224","random",NA,"vit_base_patch32_224","Transformer",225,"ViT-B-P32","ViT-B-P32 randomly initialized, with no training.",13455632,88185064,"wrsa",0.116324585367619,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"convit_base_random","convit_base","random",NA,"convit_base","Hybrid",219,"ConViT-B","ConViT-B randomly initialized, with no training.",61295088,86388584,"wrsa",0.117913466217995,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"keypoints2d_taskonomy","keypoints2d","taskonomy","taskonomy","resnet50","Convolutional",179,"2D Keypoints","Keypoint estimation from RGB-only (texture features).",37564576,23655504,"wrsa",0.118008558924159,NA,NA,NA,"keypoints2d","2D",NA,NA,NA,NA,NA
"dla34_random","dla34","random",NA,"dla34","Convolutional",151,"DLA34","DLA34 randomly initialized, with no training.",17578680,15742104,"wrsa",0.118052737570364,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"squeezenet1_0_random","squeezenet1_0","random",NA,"squeezenet1_0","Convolutional",66,"SqueezeNet1.0","SqueezeNet1.0 randomly initialized, with no training.",12033376,1248424,"wrsa",0.12147117888474,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"vgg16_random","vgg16","random",NA,"vgg16","Convolutional",40,"VGG16","VGG16 randomly initialized, with no training.",28677072,138357544,"wrsa",0.122278165457196,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"vit_large_patch16_224_random","vit_large_patch16_224","random",NA,"vit_large_patch16_224","Transformer",441,"ViT-L-P16","ViT-L-P16 randomly initialized, with no training.",151473488,304123880,"wrsa",0.122540426652489,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"visformer_small_random","visformer_small","random",NA,"visformer_small","Transformer",226,"Visformer","Visformer randomly initialized, with no training.",31879784,39956168,"wrsa",0.123006259521695,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"random_weights_taskonomy","random_weights","taskonomy",NA,"resnet50","Convolutional",179,"Random Weights","Taskonomy architecture randomly initialized.",37564576,23655504,"wrsa",0.124592851008857,NA,NA,NA,"random_weights","Random",NA,NA,NA,NA,NA
"cspresnet50_random","cspresnet50","random",NA,"cspresnet50","Convolutional",329,"CSP-ResNet50","CSP-ResNet50 randomly initialized, with no training.",51186592,21616168,"wrsa",0.130713126173613,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"densenet121_random","densenet121","random",NA,"densenet121","Convolutional",429,"DenseNet121","DenseNet121 randomly initialized, with no training.",41096144,7978856,"wrsa",0.131889290863765,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"alexnet_random","alexnet","random",NA,"alexnet","Convolutional",22,"AlexNet","AlexNet randomly initialized, with no training.",1099216,61100840,"wrsa",0.133154536096829,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"skresnext50_32x4d_random","skresnext50_32x4d","random",NA,"skresnext50_32x4d","Convolutional",497,"SKResNext50-32x4D","SKResNext50-32x4D randomly initialized, with no training.",99238128,27479784,"wrsa",0.1345556901375,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"xcit_nano_12_p8_224_random","xcit_nano_12_p8_224","random",NA,"xcit_nano_12_p8_224","Transformer",NA,"XCIT-N-12-P8","XCIT-N-12-P8 randomly initialized, with no training.",NA,NA,"wrsa",0.137995415630422,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"hardcorenas_a_random","hardcorenas_a","random",NA,"hardcorenas_a","Convolutional",204,"HardCoreNAS-A","HardCoreNAS-A randomly initialized, with no training.",19698736,5260232,"wrsa",0.140216063709411,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"denoising_taskonomy","denoising","taskonomy","taskonomy","resnet50","Convolutional",179,"Denoising","Uncorrupted version of corrupted image.",37564576,23655504,"wrsa",0.142459039420514,NA,NA,NA,"denoising","Other",NA,NA,NA,NA,NA
"xception_random","xception","random",NA,"xception","Convolutional",204,"XCeption","XCeption randomly initialized, with no training.",52151632,22855952,"wrsa",0.150478535269003,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"nonfixated_pose_taskonomy","nonfixated_pose","taskonomy","taskonomy","resnet50","Convolutional",179,"Camera Pose (Nonfixated)","Relative camera pose with distinct optical centers.",37564576,23655504,"wrsa",0.153339096670095,NA,NA,NA,"nonfixated_pose","Geometric",NA,NA,NA,NA,NA
"jigsaw_taskonomy","jigsaw","taskonomy","taskonomy","resnet50","Convolutional",179,"Jigsaw","Putting scrambled image pieces back together.",37564576,23655504,"wrsa",0.155103150115625,NA,NA,NA,"jigsaw","Geometric",NA,NA,NA,NA,NA
"googlenet_random","googlenet","random",NA,"googlenet","Convolutional",197,"GoogleNet","GoogleNet randomly initialized, with no training.",12335584,6624904,"wrsa",0.160861661858028,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"edge_texture_taskonomy","edge_texture","taskonomy","taskonomy","resnet50","Convolutional",179,"Texture Edges","Edges computed from RGB only (texture edges).",37564576,23655504,"wrsa",0.166035680530001,NA,NA,NA,"edge_texture","2D",NA,NA,NA,NA,NA
"segment_unsup2d_taskonomy","segment_unsup2d","taskonomy","taskonomy","resnet50","Convolutional",179,"Unsupervised 2D Segmentation","Segmentation (graph cut approximation) on RGB.",37564576,23655504,"wrsa",0.169582166271173,NA,NA,NA,"segment_unsup2d","2D",NA,NA,NA,NA,NA
"jx_nest_tiny_random","jx_nest_tiny","random",NA,"jx_nest_tiny","Transformer",213,"JX-NesT-Tiny","JX-NesT-Tiny randomly initialized, with no training.",52424528,16530760,"wrsa",0.174921216613881,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"vanishing_point_taskonomy","vanishing_point","taskonomy","taskonomy","resnet50","Convolutional",179,"Vanishing Point","Three Manhattan-world vanishing points.",37564576,23655504,"wrsa",0.183634531154779,NA,NA,NA,"vanishing_point","Geometric",NA,NA,NA,NA,NA
"inpainting_taskonomy","inpainting","taskonomy","taskonomy","resnet50","Convolutional",179,"Inpainting","Filling in masked center of image.",37564576,23655504,"wrsa",0.195174615231136,NA,NA,NA,"inpainting","2D",NA,NA,NA,NA,NA
"egomotion_taskonomy","egomotion","taskonomy","taskonomy","resnet50","Convolutional",179,"Egomotion","Odometry (camera poses) given three input images.",37564576,23655504,"wrsa",0.197485877204509,NA,NA,NA,"egomotion","Geometric",NA,NA,NA,NA,NA
"point_matching_taskonomy","point_matching","taskonomy","taskonomy","resnet50","Convolutional",179,"Point Matching","Classifying if centers of two images match or not.",37564576,23655504,"wrsa",0.215527704622801,NA,NA,NA,"point_matching","Geometric",NA,NA,NA,NA,NA
"fixated_pose_taskonomy","fixated_pose","taskonomy","taskonomy","resnet50","Convolutional",179,"Camera Pose (Fixated)","Relative camera pose with matching optical centers.",37564576,23655504,"wrsa",0.235927716849598,NA,NA,NA,"fixated_pose","Geometric",NA,NA,NA,NA,NA
"nf_resnet50_random","nf_resnet50","random",NA,"nf_resnet50","Convolutional",151,"NF-ResNet50","NF-ResNet50 randomly initialized, with no training.",33527712,25530472,"wrsa",0.280178340781254,"random",NA,NA,NA,NA,NA,NA,NA,NA,NA
"alexnet_gn_ipcl_vggface2_ipcl","alexnet_gn_ipcl_vggface2","ipcl","vggface2","alexnet_gn","Convolutional",NA,"AlexNet-GN-IPCLVGGFace2","AlexNet (modified with GroupNorm) trained via IPCL-Style-Self-Supervision on VGGFace2.",NA,NA,"wrsa",0.289686661596372,NA,NA,NA,NA,NA,NA,"vggface2",NA,NA,NA
"room_layout_taskonomy","room_layout","taskonomy","taskonomy","resnet50","Convolutional",179,"Room Layout","Orientation and aspect ratio of cubic room layout.",37564576,23655504,"wrsa",0.308685400103079,NA,NA,NA,"room_layout","Geometric",NA,NA,NA,NA,NA
"segment_unsup25d_taskonomy","segment_unsup25d","taskonomy","taskonomy","resnet50","Convolutional",179,"Unsupervised 2.5D Segmentation","Segmentation (graph cut approximation) on RGB-D-Normals-Curvature image.",37564576,23655504,"wrsa",0.313026993640113,NA,NA,NA,"segment_unsup25d","3D",NA,NA,NA,NA,NA
"curvature_taskonomy","curvature","taskonomy","taskonomy","resnet50","Convolutional",179,"Curvatures","Magnitude of 3D principal curvatures",37564576,23655504,"wrsa",0.320142659400121,NA,NA,NA,"curvature","3D",NA,NA,NA,NA,NA
"segment_semantic_taskonomy","segment_semantic","taskonomy","taskonomy","resnet50","Convolutional",179,"Semantic Segmentation","Pixel-wise semantic labeling (via knowledge distillation from MS COCO).",37564576,23655504,"wrsa",0.32444837356152,NA,NA,NA,"segment_semantic","Semantic",NA,NA,NA,NA,NA
"depth_zbuffer_taskonomy","depth_zbuffer","taskonomy","taskonomy","resnet50","Convolutional",179,"Z-Buffer Depth","Depth estimation.",37564576,23655504,"wrsa",0.330888267235098,NA,NA,NA,"depth_zbuffer","3D",NA,NA,NA,NA,NA
"normal_taskonomy","normal","taskonomy","taskonomy","resnet50","Convolutional",179,"Surface Normals","Pixel-wise surface normals.",37564576,23655504,"wrsa",0.338698014974659,NA,NA,NA,"normal","3D",NA,NA,NA,NA,NA
"edge_occlusion_taskonomy","edge_occlusion","taskonomy","taskonomy","resnet50","Convolutional",179,"Occlusion Edges","Edges which include parts of the scene.",37564576,23655504,"wrsa",0.347592445873302,NA,NA,NA,"edge_occlusion","3D",NA,NA,NA,NA,NA
"reshading_taskonomy","reshading","taskonomy","taskonomy","resnet50","Convolutional",179,"Reshading","Reshading with new lighting placed at camera location.",37564576,23655504,"wrsa",0.357853176909959,NA,NA,NA,"reshading","3D",NA,NA,NA,NA,NA
"depth_euclidean_taskonomy","depth_euclidean","taskonomy","taskonomy","resnet50","Convolutional",179,"Euclidean Depth","Depth estimation",37564576,23655504,"wrsa",0.361066707222347,NA,NA,NA,"depth_euclidean","3D",NA,NA,NA,NA,NA
"keypoints3d_taskonomy","keypoints3d","taskonomy","taskonomy","resnet50","Convolutional",179,"3D Keypoints","3D Keypoint estimation from underlying scene 3D.",37564576,23655504,"wrsa",0.361683115605629,NA,NA,NA,"keypoints3d","3D",NA,NA,NA,NA,NA
"class_scene_taskonomy","class_scene","taskonomy","taskonomy","resnet50","Convolutional",179,"Scene Classification","Scene Classification (via knowledge distillation from MIT Places).",37564576,23655504,"wrsa",0.425503530784422,NA,NA,NA,"class_scene","Semantic",NA,NA,NA,NA,NA
"class_object_taskonomy","class_object","taskonomy","taskonomy","resnet50","Convolutional",179,"Object Classification","1000-way object classification (via knowledge distillation from ImageNet).",37564576,23655504,"wrsa",0.435715092750933,NA,NA,NA,"class_object","Semantic",NA,NA,NA,NA,NA
"alexnet_gn_ipcl_places256_ipcl","alexnet_gn_ipcl_places256","ipcl","places256","alexnet_gn","Convolutional",NA,"AlexNet-GN-IPCLPlaces256","AlexNet (modified with GroupNorm) trained via IPCL-Style-Self-Supervision on Places256.",NA,NA,"wrsa",0.49458977131199,NA,NA,NA,NA,NA,NA,"places256",NA,NA,NA
"alexnet_gn_ipcl_openimages_ipcl","alexnet_gn_ipcl_openimages","ipcl","openimages","alexnet_gn","Convolutional",NA,"AlexNet-GN-IPCLOpenImages","AlexNet (modified with GroupNorm) trained via IPCL-Style-Self-Supervision on OpenImages.",NA,NA,"wrsa",0.516822703041956,NA,NA,NA,NA,NA,NA,"openimages",NA,NA,NA
"alexnet_gn_ipcl_imagenet_ipcl","alexnet_gn_ipcl_imagenet","ipcl","imagenet","alexnet_gn","Convolutional",NA,"AlexNet-GN-IPCLImageNet","AlexNet (modified with GroupNorm) trained via IPCL-Style-Self-Supervision on ImageNet.",NA,NA,"wrsa",0.561646501496023,NA,NA,NA,NA,NA,NA,"imagenet",NA,NA,NA
"ResNet50-JigSaw-Goyal19_selfsupervised","ResNet50-JigSaw-Goyal19","selfsupervised","imagenet","ResNet50","Convolutional",175,"ResNet50-JigSaw-Goyal19","ResNet50-JigSaw-Goyal19, a self-supervised representation learner trained on ImageNet.",37562880,23508032,"wrsa",0.564793138640511,NA,NA,NA,NA,NA,NA,NA,"JigSaw-Goyal19","Non-Contrastive",NA
"ResNet50-RotNet_selfsupervised","ResNet50-RotNet","selfsupervised","imagenet","ResNet50","Convolutional",175,"ResNet50-RotNet","ResNet50-RotNet, a self-supervised representation learner trained on ImageNet.",37562880,23508032,"wrsa",0.572062263675848,NA,NA,NA,NA,NA,NA,NA,"RotNet","Non-Contrastive",NA
"ResNet50-JigSaw-P100_selfsupervised","ResNet50-JigSaw-P100","selfsupervised","imagenet","ResNet50","Convolutional",175,"ResNet50-JigSaw-P100","ResNet50-JigSaw-P100, a self-supervised representation learner trained on ImageNet.",37562880,23508032,"wrsa",0.577186795648082,NA,NA,NA,NA,NA,NA,NA,"JigSaw-P100","Non-Contrastive",NA
"vit_tiny_patch16_224_classification","vit_tiny_patch16_224","classification","imagenet","vit_tiny_patch16_224","Transformer",225,"ViT-T-P16","ViT-T-P16 trained on image classification with the ImageNet dataset.",14296916,5679400,"wrsa",0.589880898576647,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,NA
"ResNet50-MoCoV2-BS256_selfsupervised","ResNet50-MoCoV2-BS256","selfsupervised","imagenet","ResNet50","Convolutional",175,"ResNet50-MoCoV2-BS256","ResNet50-MoCoV2-BS256, a self-supervised representation learner trained on ImageNet.",37562880,23508032,"wrsa",0.610037999120178,NA,NA,NA,NA,NA,NA,NA,"MoCoV2-BS256","Contrastive",NA
"MiDaS_monoculardepth","MiDaS","monoculardepth","ReDWeb,DIML,Movies,MegaDepth,WSVD,TartanAir,HRWSI,ApolloScape,BlendedMVS,IRS","MiDaS",NA,NA,"MiDaS","MiDaS, a monocular depth estimation model.",NA,NA,"wrsa",0.618679797978706,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"DPT_Hybrid_monoculardepth","DPT_Hybrid","monoculardepth","ReDWeb,DIML,Movies,MegaDepth,WSVD,TartanAir,HRWSI,ApolloScape,BlendedMVS,IRS","DPT_Hybrid","Transformer",584,"DPT-Hybrid","DPT-Hybrid, a monocular depth estimation model.",167515152,120753921,"wrsa",0.620368535815224,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"squeezenet1_0_classification","squeezenet1_0","classification","imagenet","squeezenet1_0","Convolutional",66,"SqueezeNet1.0","SqueezeNet1.0 trained on image classification with the ImageNet dataset.",12033376,1248424,"wrsa",0.622896447988761,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"keypoint_rcnn_R_50_FPN_3x_segmentation","keypoint_rcnn_R_50_FPN_3x","segmentation","coco2017","keypoint_rcnn_R_50_FPN_3x","Convolutional",NA,"Keypoint-RCNN-ResNet50-FPN","Keypoint-RCNN-ResNet50-FPN, trained on segmentation with the CoCo2017 dataset.",NA,NA,"wrsa",0.626937301298994,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"convit_tiny_classification","convit_tiny","classification","imagenet","convit_tiny","Hybrid",219,"ConViT-T","ConViT-T trained on image classification with the ImageNet dataset.",15325272,5672648,"wrsa",0.628494206512124,"classification","Hybrid",NA,NA,NA,NA,NA,NA,NA,NA
"ResNet50-ClusterFit-16K-RotNet_selfsupervised","ResNet50-ClusterFit-16K-RotNet","selfsupervised","imagenet","ResNet50","Convolutional",175,"ResNet50-ClusterFit-16K-RotNet","ResNet50-ClusterFit-16K-RotNet, a self-supervised representation learner trained on ImageNet.",37562880,23508032,"wrsa",0.630281749582237,NA,NA,NA,NA,NA,NA,NA,"ClusterFit-16K-RotNet","Non-Contrastive",NA
"alexnet_classification","alexnet","classification","imagenet","alexnet","Convolutional",22,"AlexNet","AlexNet trained on image classification with the ImageNet dataset.",1099216,61100840,"wrsa",0.63339324352131,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"pit_b_224_classification","pit_b_224","classification","imagenet","pit_b_224","Transformer",254,"PiT-B-224","PiT-B-224 trained on image classification with the ImageNet dataset.",66195824,73518568,"wrsa",0.637994466852614,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,NA
"vit_small_patch32_224_classification","vit_small_patch32_224","classification","imagenet","vit_small_patch32_224","Transformer",225,"ViT-S-P32","ViT-S-P32 trained on image classification with the ImageNet dataset.",6728816,22859368,"wrsa",0.638369873254185,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,"imagenet"
"convit_base_classification","convit_base","classification","imagenet","convit_base","Hybrid",219,"ConViT-B","ConViT-B trained on image classification with the ImageNet dataset.",61295088,86388584,"wrsa",0.638883090175434,"classification","Hybrid",NA,NA,NA,NA,NA,NA,NA,NA
"deit_base_patch16_224_classification","deit_base_patch16_224","classification","imagenet","deit_base_patch16_224","Transformer",225,"DeiT-B-P16-224","DeiT-B-P16-224 trained on image classification with the ImageNet dataset.",57181664,86415592,"wrsa",0.639529915944539,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,NA
"ViT-L-CLIP-CC12M_slip","ViT-L-CLIP-CC12M","slip","YFCC15M","ViT-L","Transformer",225,"ViT-L-CLIP-CC12M","ViT-L-CLIP-CC12M trained via pure language supervision with the YFCC15M dataset.",57181200,85646592,"wrsa",0.640342373786992,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"mixer_b16_224_in21k_classification","mixer_b16_224_in21k","classification","imagenet21k","mixer_b16_224","MLP-Mixer",210,"Mixer-B16-IN22K","Mixer-B16-IN22K trained on image classification with the ImageNet21K dataset.",52808358,75908739,"wrsa",0.640712485905546,NA,NA,NA,NA,NA,NA,NA,NA,NA,"imagenet21k"
"vit_small_patch16_224_in21k_classification","vit_small_patch16_224_in21k","classification","imagenet21k","vit_small_patch16_224","Transformer",225,"ViT-S-P16-IN21K","ViT-S-P16-IN21K trained on image classification with the ImageNet21K dataset.",28633518,29999187,"wrsa",0.645145312348998,NA,NA,NA,NA,NA,NA,NA,NA,NA,"imagenet21k"
"vit_small_patch16_224_classification","vit_small_patch16_224","classification","imagenet","vit_small_patch16_224","Transformer",225,"ViT-S-P16","ViT-S-P16 trained on image classification with the ImageNet dataset.",28591832,21974632,"wrsa",0.647296163299784,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,"imagenet"
"vit_large_patch16_224_classification","vit_large_patch16_224","classification","imagenet","vit_large_patch16_224","Transformer",441,"ViT-L-P16","ViT-L-P16 trained on image classification with the ImageNet dataset.",151473488,304123880,"wrsa",0.647621046112705,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,"imagenet"
"resnet18_classification","resnet18","classification","imagenet","resnet18","Convolutional",69,"ResNet18","ResNet18 trained on image classification with the ImageNet dataset.",8231376,11689512,"wrsa",0.648354719706305,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"vit_base_patch32_224_in21k_classification","vit_base_patch32_224_in21k","classification","imagenet21k","vit_base_patch32_224","Transformer",225,"ViT-B-P32-IN21K","ViT-B-P32-IN21K trained on image classification with the ImageNet21K dataset.",13497318,104213331,"wrsa",0.651845382071588,NA,NA,NA,NA,NA,NA,NA,NA,NA,"imagenet21k"
"convnext_large_classification","convnext_large","classification","imagenet","convnext_large","Convolutional",382,"ConvNext-L","ConvNext-L trained on image classification with the ImageNet dataset.",137593808,197740264,"wrsa",0.653516812059427,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,"imagenet"
"vit_small_patch32_224_in21k_classification","vit_small_patch32_224_in21k","classification","imagenet21k","vit_small_patch32_224","Transformer",225,"ViT-S-P32-IN21K","ViT-S-P32-IN21K trained on image classification with the ImageNet21K dataset.",6770502,30883923,"wrsa",0.653830885145711,NA,NA,NA,NA,NA,NA,NA,NA,NA,"imagenet21k"
"crossvit_base_240_classification","crossvit_base_240","classification","imagenet","crossvit_base_240","Transformer",383,"CrossViT-B","CrossViT-B trained on image classification with the ImageNet dataset.",80095620,104718800,"wrsa",0.654918666442799,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,NA
"ViT-L-CLIP_slip","ViT-L-CLIP","slip","YFCC15M","ViT-L","Transformer",441,"ViT-L-CLIP","ViT-L-CLIP trained via pure language supervision with the YFCC15M dataset.",151473536,303098880,"wrsa",0.655002821281638,NA,NA,"CLIP",NA,NA,NA,NA,NA,NA,NA
"vit_base_patch16_224_classification","vit_base_patch16_224","classification","imagenet","vit_base_patch16_224","Transformer",225,"ViT-B-P16","ViT-B-P16 trained on image classification with the ImageNet dataset.",57181664,86415592,"wrsa",0.657162896785366,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,"imagenet"
"tnt_s_patch16_224_classification","tnt_s_patch16_224","classification","imagenet","tnt_s_patch16_224","Transformer",NA,"TnT-P16-224","TnT-P16-224 trained on image classification with the ImageNet dataset.",NA,NA,"wrsa",0.657387521482707,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,NA
"shufflenet_v2_x1_0_classification","shufflenet_v2_x1_0","classification","imagenet","shufflenet_v2_x1_0","Convolutional",168,"ShuffleNet-V2-x1.0","ShuffleNet-V2-x1.0 trained on image classification with the ImageNet dataset.",6284192,2278604,"wrsa",0.660366000117106,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"vit_base_patch32_224_classification","vit_base_patch32_224","classification","imagenet","vit_base_patch32_224","Transformer",225,"ViT-B-P32","ViT-B-P32 trained on image classification with the ImageNet dataset.",13455632,88185064,"wrsa",0.660730880736759,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,"imagenet"
"visformer_small_classification","visformer_small","classification","imagenet","visformer_small","Transformer",226,"Visformer","Visformer trained on image classification with the ImageNet dataset.",31879784,39956168,"wrsa",0.661018487752772,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,NA
"xception_classification","xception","classification","imagenet","xception","Convolutional",204,"XCeption","XCeption trained on image classification with the ImageNet dataset.",52151632,22855952,"wrsa",0.661419429960928,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"resnet152_classification","resnet152","classification","imagenet","resnet152","Convolutional",515,"ResNet152","ResNet152 trained on image classification with the ImageNet dataset.",79507920,60192808,"wrsa",0.662221249270844,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"pit_ti_224_classification","pit_ti_224","classification","imagenet","pit_ti_224","Transformer",236,"PiT-T-224","PiT-T-224 trained on image classification with the ImageNet dataset.",11698296,4800552,"wrsa",0.662315711231154,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,NA
"mixer_b16_224_classification","mixer_b16_224","classification","imagenet","mixer_b16_224","MLP-Mixer",210,"MLP-Mixer-B16","MLP-Mixer-B16 trained on image classification with the ImageNet dataset.",52766672,59880472,"wrsa",0.662343797298573,"classification","MLP-Mixer",NA,NA,NA,NA,NA,NA,NA,"imagenet"
"vit_large_patch16_224_in21k_classification","vit_large_patch16_224_in21k","classification","imagenet21k","vit_large_patch16_224","Transformer",441,"ViT-L-P16-IN21K","ViT-L-P16-IN21K trained on image classification with the ImageNet21K dataset.",151515174,325487955,"wrsa",0.663133304686734,NA,NA,NA,NA,NA,NA,NA,NA,NA,"imagenet21k"
"resnet101_classification","resnet101","classification","imagenet","resnet101","Convolutional",345,"ResNet101","ResNet101 trained on image classification with the ImageNet dataset.",56326608,44549160,"wrsa",0.663434311447176,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"vit_base_r50_s16_224_in21k_classification","vit_base_r50_s16_224_in21k","classification","imagenet21k","vit_base_r50_s16_224","Transformer",496,"ViT-B-R50-S16-IN21K","ViT-B-R50-S16-IN21K trained on image classification with the ImageNet21K dataset.",124710838,115125907,"wrsa",0.663970854542014,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"dla34_classification","dla34","classification","imagenet","dla34","Convolutional",151,"DLA34","DLA34 trained on image classification with the ImageNet dataset.",17578680,15742104,"wrsa",0.665072185179771,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"retinanet_R_50_FPN_3x_detection","retinanet_R_50_FPN_3x","detection","coco2017","retinanet_R_50_FPN_3x","Convolutional",NA,"RetinaNet-ResNet50-FPN","RetinaNet-ResNet50-FPN, trained on detection with the CoCo2017 dataset.",NA,NA,"wrsa",0.66527166763575,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"skresnext50_32x4d_classification","skresnext50_32x4d","classification","imagenet","skresnext50_32x4d","Convolutional",497,"SKResNext50-32x4D","SKResNext50-32x4D trained on image classification with the ImageNet dataset.",99238128,27479784,"wrsa",0.666463666026049,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"vgg16_classification","vgg16","classification","imagenet","vgg16","Convolutional",40,"VGG16","VGG16 trained on image classification with the ImageNet dataset.",28677072,138357544,"wrsa",0.66760877801388,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"mixer_l16_224_classification","mixer_l16_224","classification","imagenet","mixer_l16_224","MLP-Mixer",414,"MLP-Mixer-L16","MLP-Mixer-L16 trained on image classification with the ImageNet dataset.",149342160,208196168,"wrsa",0.667711534985612,"classification","MLP-Mixer",NA,NA,NA,NA,NA,NA,NA,"imagenet"
"jx_nest_tiny_classification","jx_nest_tiny","classification","imagenet","jx_nest_tiny","Transformer",213,"JX-NesT-Tiny","JX-NesT-Tiny trained on image classification with the ImageNet dataset.",52424528,16530760,"wrsa",0.667807231703633,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,NA
"densenet121_classification","densenet121","classification","imagenet","densenet121","Convolutional",429,"DenseNet121","DenseNet121 trained on image classification with the ImageNet dataset.",41096144,7978856,"wrsa",0.667968763709029,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"ViT-B-CLIP_slip","ViT-B-CLIP","slip","YFCC15M","ViT-B","Transformer",225,"ViT-B-CLIP","ViT-B-CLIP trained via pure language supervision with the YFCC15M dataset.",57181200,85646592,"wrsa",0.668024171404883,NA,NA,"CLIP",NA,NA,NA,NA,NA,NA,NA
"regnety_064_classification","regnety_064","classification","imagenet","regnety_064","Convolutional",658,"RegNetY-64","RegNetY-64 trained on image classification with the ImageNet dataset.",103013924,30583252,"wrsa",0.669790650866851,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"ViT-S-CLIP_slip","ViT-S-CLIP","slip","YFCC15M","ViT-S","Transformer",225,"ViT-S-CLIP","ViT-S-CLIP trained via pure language supervision with the YFCC15M dataset.",31384848,21589632,"wrsa",0.670207078589246,NA,NA,"CLIP",NA,NA,NA,NA,NA,NA,NA
"googlenet_classification","googlenet","classification","imagenet","googlenet","Convolutional",197,"GoogleNet","GoogleNet trained on image classification with the ImageNet dataset.",12335584,6624904,"wrsa",0.670522442873106,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"mask_rcnn_R_50_FPN_3x_segmentation","mask_rcnn_R_50_FPN_3x","segmentation","coco2017","mask_rcnn_R_50_FPN_3x","Convolutional",NA,"Mask-RCNN-ResNet50-FPN","Mask-RCNN-ResNet50-FPN, trained on segmentation with the CoCo2017 dataset.",NA,NA,"wrsa",0.670917144850728,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"ResNet50-PIRL_selfsupervised","ResNet50-PIRL","selfsupervised","imagenet","ResNet50","Convolutional",175,"ResNet50-PIRL","ResNet50-PIRL, a self-supervised representation learner trained on ImageNet.",37562880,23508032,"wrsa",0.672243604079862,NA,NA,NA,NA,NA,NA,NA,"PIRL","Contrastive",NA
"coat_lite_tiny_classification","coat_lite_tiny","classification","imagenet","coat_lite_tiny","Transformer",279,"CoaT-Lite-Tiny","CoaT-Lite-Tiny trained on image classification with the ImageNet dataset.",36283152,5878632,"wrsa",0.672618455680976,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,NA
"mnasnet1_0_classification","mnasnet1_0","classification","imagenet","mnasnet1_0","Convolutional",158,"MNASNet1.0","MNASNet1.0 trained on image classification with the ImageNet dataset.",16172496,4383312,"wrsa",0.673052513612464,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"regnetx_064_classification","regnetx_064","classification","imagenet","regnetx_064","Convolutional",373,"RegNetX-64","RegNetX-64 trained on image classification with the ImageNet dataset.",101428288,26209256,"wrsa",0.673858365291194,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"inception_v3_classification","inception_v3","classification","imagenet","inception_v3","Convolutional",300,"Inception-V3","Inception-V3 trained on image classification with the ImageNet dataset.",15467136,23834568,"wrsa",0.674591946293969,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"resmlp_12_224_classification","resmlp_12_224","classification","imagenet","resmlp_12_224","MLP-Mixer",150,"ResMLP-12","ResMLP-12 trained on image classification with the ImageNet dataset.",19269584,15322456,"wrsa",0.67463722969758,"classification","MLP-Mixer",NA,NA,NA,NA,NA,NA,NA,NA
"seresnext50_32x4d_classification","seresnext50_32x4d","classification","imagenet","seresnext50_32x4d","Convolutional",305,"SEResNext50-32x4D","SEResNext50-32x4D trained on image classification with the ImageNet dataset.",58496224,27559896,"wrsa",0.674712991800946,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"convmixer_768_32_classification","convmixer_768_32","classification","imagenet","convmixer_768_32","Hybrid",232,"ConvMixer-768-32","ConvMixer-768-32 trained on image classification with the ImageNet dataset.",178524368,21110248,"wrsa",0.675434465808741,"classification","Hybrid",NA,NA,NA,NA,NA,NA,NA,NA
"convnext_base_classification","convnext_base","classification","imagenet","convnext_base","Convolutional",382,"ConvNext-B","ConvNext-B trained on image classification with the ImageNet dataset.",91729872,88573416,"wrsa",0.675561003734044,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,"imagenet"
"ghostnet_100_classification","ghostnet_100","classification","imagenet","ghostnet_100","Convolutional",287,"GhostNet100","GhostNet100 trained on image classification with the ImageNet dataset.",13446920,5182508,"wrsa",0.675593260595292,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"faster_rcnn_R_50_FPN_3x_detection","faster_rcnn_R_50_FPN_3x","detection","coco2017","faster_rcnn_R_50_FPN_3x","Convolutional",NA,"Faster-RCNN-ResNet50-FPN","Faster-RCNN-ResNet50-FPN, trained on detection with the CoCo2017 dataset.",NA,NA,"wrsa",0.675598511260687,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"mobilenet_v2_classification","mobilenet_v2","classification","imagenet","mobilenet_v2","Convolutional",159,"MobileNet-V2","MobileNet-V2 trained on image classification with the ImageNet dataset.",20037616,3504872,"wrsa",0.675674271570439,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"mobilenetv3_large_100_classification","mobilenetv3_large_100","classification","imagenet","mobilenetv3_large_100","Convolutional",265,"MobileNet-V3-Large","MobileNet-V3-Large trained on image classification with the ImageNet dataset.",20046944,5483032,"wrsa",0.676226726272867,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"cspresnet50_classification","cspresnet50","classification","imagenet","cspresnet50","Convolutional",329,"CSP-ResNet50","CSP-ResNet50 trained on image classification with the ImageNet dataset.",51186592,21616168,"wrsa",0.676782479703953,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"vit_base_patch16_224_in21k_classification","vit_base_patch16_224_in21k","classification","imagenet21k","vit_base_patch16_224","Transformer",225,"ViT-B-P16-IN21K","ViT-B-P16-IN21K trained on image classification with the ImageNet21K dataset.",57223350,102443859,"wrsa",0.677361806006053,NA,NA,NA,NA,NA,NA,NA,NA,NA,"imagenet21k"
"swin_tiny_patch4_window7_224_classification","swin_tiny_patch4_window7_224","classification","imagenet","swin_tiny_patch4_window7_224","Transformer",NA,"Swin-T-P4-W7","Swin-T-P4-W7 trained on image classification with the ImageNet dataset.",NA,NA,"wrsa",0.67829146416013,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,NA
"swin_base_patch4_window7_224_classification","swin_base_patch4_window7_224","classification","imagenet","swin_base_patch4_window7_224","Transformer",NA,"Swin-B-P4-W7","Swin-B-P4-W7 trained on image classification with the ImageNet dataset.",NA,NA,"wrsa",0.678895864853623,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,"imagenet"
"ResNet50-BarlowTwins-BS2048_selfsupervised","ResNet50-BarlowTwins-BS2048","selfsupervised","imagenet","ResNet50","Convolutional",175,"ResNet50-BarlowTwins-BS2048","ResNet50-BarlowTwins-BS2048, a self-supervised representation learner trained on ImageNet.",37562880,23508032,"wrsa",0.679154468700829,NA,NA,NA,NA,NA,NA,NA,"BarlowTwins-BS2048","Contrastive",NA
"semnasnet_100_classification","semnasnet_100","classification","imagenet","semnasnet_100","Convolutional",274,"SemNASNet100","SemNASNet100 trained on image classification with the ImageNet dataset.",27843180,3887038,"wrsa",0.679201737925084,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"mixer_l16_224_in21k_classification","mixer_l16_224_in21k","classification","imagenet21k","mixer_l16_224","MLP-Mixer",414,"Mixer-L16-IN22K","Mixer-L16-IN22K trained on image classification with the ImageNet21K dataset.",149383846,229560243,"wrsa",0.680087558003426,NA,NA,NA,NA,NA,NA,NA,NA,NA,"imagenet21k"
"resnet50_classification","resnet50","classification","imagenet","resnet50","Convolutional",175,"ResNet50","ResNet50 trained on image classification with the ImageNet dataset.",37560784,25557032,"wrsa",0.680405447068476,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"efficientnet_b3_classification","efficientnet_b3","classification","imagenet","efficientnet_b3","Convolutional",492,"EfficientNet-B3","EfficientNet-B3 trained on image classification with the ImageNet dataset.",59058840,12233232,"wrsa",0.681269729611084,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"nfnet_l0_classification","nfnet_l0","classification","imagenet","nfnet_l0","Convolutional",220,"NF-Net-L0","NF-Net-L0 trained on image classification with the ImageNet dataset.",32566496,35041672,"wrsa",0.682639768390844,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"eca_nfnet_l0_classification","eca_nfnet_l0","classification","imagenet","eca_nfnet_l0","Convolutional",184,"ECA-NFNeT-L0","ECA-NFNeT-L0 trained on image classification with the ImageNet dataset.",32555168,24111108,"wrsa",0.683437964436189,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"ResNet50-SwAV-BS4096-2x224+6x96_selfsupervised","ResNet50-SwAV-BS4096-2x224+6x96","selfsupervised","imagenet","ResNet50","Convolutional",175,"ResNet50-SwAV-BS4096","ResNet50-SwAV-BS4096-2x224+6x96, a self-supervised representation learner trained on ImageNet.",37562880,23508032,"wrsa",0.683680597954077,NA,NA,NA,NA,NA,NA,NA,"SwAV-BS4096-2x224+6x96","Contrastive",NA
"gmixer_24_224_classification","gmixer_24_224","classification","imagenet","gmixer_24_224","Convolutional",414,"GMixer-24","GMixer-24 trained on image classification with the ImageNet dataset.",41701328,24721096,"wrsa",0.6837334720886,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"dino_vitb16_selfsupervised","dino_vitb16","selfsupervised","imagenet","vitb16","Transformer",NA,"Dino-VIT-B16","Dino-VIT-B16 trained via self supervision with the ImageNet dataset.",NA,NA,"wrsa",0.684039464722449,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"xcit_nano_12_p16_224_classification","xcit_nano_12_p16_224","classification","imagenet","xcit_nano_12_p16_224","Transformer",NA,"XCIT-N-12-P16","XCIT-N-12-P16 trained on image classification with the ImageNet dataset.",NA,NA,"wrsa",0.68465777648567,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,NA
"hardcorenas_a_classification","hardcorenas_a","classification","imagenet","hardcorenas_a","Convolutional",204,"HardCoreNAS-A","HardCoreNAS-A trained on image classification with the ImageNet dataset.",19698736,5260232,"wrsa",0.685037030009574,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"poolformer_s36_classification","poolformer_s36","classification","imagenet","poolformer_s36","Transformer",483,"PoolFormer-S36","PoolFormer-S36 trained on image classification with the ImageNet dataset.",78339280,30842792,"wrsa",0.685101452754617,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,NA
"swin_large_patch4_window7_224_classification","swin_large_patch4_window7_224","classification","imagenet","swin_large_patch4_window7_224","Transformer",NA,"Swin-L-P4-W7","Swin-L-P4-W7 trained on image classification with the ImageNet dataset.",NA,NA,"wrsa",0.685112966446932,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,"imagenet"
"resmlp_24_224_classification","resmlp_24_224","classification","imagenet","resmlp_24_224","MLP-Mixer",294,"ResMLP-24","ResMLP-24 trained on image classification with the ImageNet dataset.",38236112,29964616,"wrsa",0.685586299821049,"classification","MLP-Mixer",NA,NA,NA,NA,NA,NA,NA,NA
"dino_resnet50_selfsupervised","dino_resnet50","selfsupervised","imagenet","resnet50","Convolutional",NA,"Dino-ResNet50","Dino-ResNet50 trained via self supervision with the ImageNet dataset.",NA,NA,"wrsa",0.686916802693139,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"levit_128_classification","levit_128","classification","imagenet","levit_128","Transformer",NA,"LeViT128","LeViT128 trained on image classification with the ImageNet dataset.",NA,NA,"wrsa",0.687948373747472,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,NA
"ViT-S-SimCLR_slip","ViT-S-SimCLR","slip","YFCC15M","ViT-S","Transformer",225,"ViT-S-SimCLR","ViT-S-SimCLR trained via pure self-supervision with the YFCC15M dataset.",31384848,21589632,"wrsa",0.688482039895487,NA,NA,"SimCLR",NA,NA,NA,NA,NA,NA,NA
"ViT-S-SLIP_slip","ViT-S-SLIP","slip","YFCC15M","ViT-S","Transformer",225,"ViT-S-SLIP","ViT-S-SLIP trained via combined self- and language supervision with the YFCC15M dataset.",31384848,21589632,"wrsa",0.688661419493063,NA,NA,"SLIP",NA,NA,NA,NA,NA,NA,NA
"hardcorenas_f_classification","hardcorenas_f","classification","imagenet","hardcorenas_f","Convolutional",326,"HardCoreNAS-F","HardCoreNAS-F trained on image classification with the ImageNet dataset.",25099520,8199688,"wrsa",0.689066024979016,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"RegNet-128Gf-SEER-INFT_seer","RegNet-128Gf-SEER-INFT","seer","random1B","RegNet-128Gf","Convolutional",NA,"RegNet-128Gf-SEER-INFT","RegNet-128Gf trained via large-scale self-supervision on 1 billion images.",NA,NA,"wrsa",0.689252316003368,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"ResNet50-DeepClusterV2-2x224+6x96_selfsupervised","ResNet50-DeepClusterV2-2x224+6x96","selfsupervised","imagenet","ResNet50","Convolutional",175,"ResNet50-DeepClusterV2","ResNet50-DeepClusterV2-2x224+6x96, a self-supervised representation learner trained on ImageNet.",37562880,23508032,"wrsa",0.68987910091454,NA,NA,NA,NA,NA,NA,NA,"DeepClusterV2-2x224+6x96","Contrastive",NA
"BiT-Expert-ResNet-V2-Food_bit_expert","BiT-Expert-ResNet-V2-Food","bit_expert","big_transfer","ResNet50-V2","Convolutional",168,"BiT-Expert-ResNet-V2-Food","ResNet50-V2 trained first via ImageNet21K dataset, then as an expert on the Food subset.",35578624,23496256,"wrsa",0.690048975400583,NA,NA,NA,NA,NA,"Food",NA,NA,NA,NA
"ViT-L-SimCLR_slip","ViT-L-SimCLR","slip","YFCC15M","ViT-L","Transformer",441,"ViT-L-SimCLR","ViT-L-SimCLR trained via pure self-supervision with the YFCC15M dataset.",151473536,303098880,"wrsa",0.690094782212805,NA,NA,"SimCLR",NA,NA,NA,NA,NA,NA,NA
"gmlp_s16_224_classification","gmlp_s16_224","classification","imagenet","gmlp_s16_224","Convolutional",366,"GMLP-S16","GMLP-S16 trained on image classification with the ImageNet dataset.",49876944,19422656,"wrsa",0.690224548991095,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"BiT-Expert-ResNet-V2-Vehicle_bit_expert","BiT-Expert-ResNet-V2-Vehicle","bit_expert","big_transfer","ResNet50-V2","Convolutional",168,"BiT-Expert-ResNet-V2-Vehicle","ResNet50-V2 trained first via ImageNet21K dataset, then as an expert on the Vehicle subset.",35578624,23496256,"wrsa",0.690576645149307,NA,NA,NA,NA,NA,"Vehicle",NA,NA,NA,NA
"BiT-Expert-ResNet-V2-Instrument_bit_expert","BiT-Expert-ResNet-V2-Instrument","bit_expert","big_transfer","ResNet50-V2","Convolutional",168,"BiT-Expert-ResNet-V2-Instrument","ResNet50-V2 trained first via ImageNet21K dataset, then as an expert on the Instrument subset.",35578624,23496256,"wrsa",0.690903784261306,NA,NA,NA,NA,NA,"Instrument",NA,NA,NA,NA
"BiT-Expert-ResNet-V2-Flower_bit_expert","BiT-Expert-ResNet-V2-Flower","bit_expert","big_transfer","ResNet50-V2","Convolutional",168,"BiT-Expert-ResNet-V2-Flower","ResNet50-V2 trained first via ImageNet21K dataset, then as an expert on the Flower subset.",35578624,23496256,"wrsa",0.691078116793662,NA,NA,NA,NA,NA,"Flower",NA,NA,NA,NA
"BiT-Expert-ResNet-V2-Arthropod_bit_expert","BiT-Expert-ResNet-V2-Arthropod","bit_expert","big_transfer","ResNet50-V2","Convolutional",168,"BiT-Expert-ResNet-V2-Arthropod","ResNet50-V2 trained first via ImageNet21K dataset, then as an expert on the Arthropod subset.",35578624,23496256,"wrsa",0.69108283658869,NA,NA,NA,NA,NA,"Arthropod",NA,NA,NA,NA
"efficientnet_b1_classification","efficientnet_b1","classification","imagenet","efficientnet_b1","Convolutional",435,"EfficientNet-B1","EfficientNet-B1 trained on image classification with the ImageNet dataset.",42450128,7794184,"wrsa",0.691123208736203,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"ViT-B-SimCLR_slip","ViT-B-SimCLR","slip","YFCC15M","ViT-B","Transformer",225,"ViT-B-SimCLR","ViT-B-SimCLR trained via pure self-supervision with the YFCC15M dataset.",57181200,85646592,"wrsa",0.69144925266006,NA,NA,"SimCLR",NA,NA,NA,NA,NA,NA,NA
"nf_resnet50_classification","nf_resnet50","classification","imagenet","nf_resnet50","Convolutional",151,"NF-ResNet50","NF-ResNet50 trained on image classification with the ImageNet dataset.",33527712,25530472,"wrsa",0.691458182434738,"classification","Convolutional",NA,NA,NA,NA,NA,NA,NA,NA
"resmlp_36_224_classification","resmlp_36_224","classification","imagenet","resmlp_36_224","MLP-Mixer",438,"ResMLP-36","ResMLP-36 trained on image classification with the ImageNet dataset.",57202640,44606776,"wrsa",0.691810130887914,"classification","MLP-Mixer",NA,NA,NA,NA,NA,NA,NA,NA
"BiT-Expert-ResNet-V2-Relation_bit_expert","BiT-Expert-ResNet-V2-Relation","bit_expert","big_transfer","ResNet50-V2","Convolutional",168,"BiT-Expert-ResNet-V2-Relation","ResNet50-V2 trained first via ImageNet21K dataset, then as an expert on the Relation subset.",35578624,23496256,"wrsa",0.692788234002528,NA,NA,NA,NA,NA,"Relation",NA,NA,NA,NA
"yolov5l_yolo","yolov5l","yolo","coco,voc","yolov5l","Convolutional",NA,"YOLO-V5-L","YOLO-V5-L, an object detection model.",NA,NA,"wrsa",0.693639162017745,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"yolov5m_yolo","yolov5m","yolo","coco,voc","yolov5m","Convolutional",NA,"YOLO-V5-M","YOLO-V5-M, an object detection model.",NA,NA,"wrsa",0.694824935691202,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"yolov5s_yolo","yolov5s","yolo","coco,voc","yolov5s","Convolutional",NA,"YOLO-V5-S","YOLO-V5-S, an object detection model.",NA,NA,"wrsa",0.69534739015991,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"BiT-Expert-ResNet-V2-Bird_bit_expert","BiT-Expert-ResNet-V2-Bird","bit_expert","big_transfer","ResNet50-V2","Convolutional",168,"BiT-Expert-ResNet-V2-Bird","ResNet50-V2 trained first via ImageNet21K dataset, then as an expert on the Bird subset.",35578624,23496256,"wrsa",0.696079745511412,NA,NA,NA,NA,NA,"Bird",NA,NA,NA,NA
"ViT-L-SLIP-CC12M_slip","ViT-L-SLIP-CC12M","slip","YFCC15M","ViT-L","Transformer",225,"ViT-L-SLIP-CC12M","ViT-L-SLIP-CC12M trained via combined self- and language supervision with the YFCC15M dataset.",57181200,85646592,"wrsa",0.696148553354365,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"resmlp_big_24_224_classification","resmlp_big_24_224","classification","imagenet","resmlp_big_24_224","MLP-Mixer",294,"ResMLP-Big-24","ResMLP-Big-24 trained on image classification with the ImageNet dataset.",305874896,129026152,"wrsa",0.696506878161363,"classification","MLP-Mixer",NA,NA,NA,NA,NA,NA,NA,"imagenet"
"xcit_nano_12_p8_224_classification","xcit_nano_12_p8_224","classification","imagenet","xcit_nano_12_p8_224","Transformer",NA,"XCIT-N-12-P8","XCIT-N-12-P8 trained on image classification with the ImageNet dataset.",NA,NA,"wrsa",0.696689486717848,"classification","Transformer",NA,NA,NA,NA,NA,NA,NA,NA
"BiT-Expert-ResNet-V2-Animal_bit_expert","BiT-Expert-ResNet-V2-Animal","bit_expert","big_transfer","ResNet50-V2","Convolutional",168,"BiT-Expert-ResNet-V2-Animal","ResNet50-V2 trained first via ImageNet21K dataset, then as an expert on the Animal subset.",35578624,23496256,"wrsa",0.697022896514738,NA,NA,NA,NA,NA,"Animal",NA,NA,NA,NA
"RegNet-64Gf-SEER-INFT_seer","RegNet-64Gf-SEER-INFT","seer","random1B","RegNet-64Gf","Convolutional",NA,"RegNet-64Gf-SEER-INFT","RegNet-64Gf trained via large-scale self-supervision on 1 billion images.",NA,NA,"wrsa",0.697451246034098,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"RegNet-32Gf-SEER-INFT_seer","RegNet-32Gf-SEER-INFT","seer","random1B","RegNet-32Gf","Convolutional",NA,"RegNet-32Gf-SEER-INFT","RegNet-32Gf trained via large-scale self-supervision on 1 billion images.",NA,NA,"wrsa",0.697947767050315,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"BiT-Expert-ResNet-V2-Object_bit_expert","BiT-Expert-ResNet-V2-Object","bit_expert","big_transfer","ResNet50-V2","Convolutional",168,"BiT-Expert-ResNet-V2-Object","ResNet50-V2 trained first via ImageNet21K dataset, then as an expert on the Object subset.",35578624,23496256,"wrsa",0.699150587800203,NA,NA,NA,NA,NA,"Object",NA,NA,NA,NA
"ResNet50-SimCLR_selfsupervised","ResNet50-SimCLR","selfsupervised","imagenet","ResNet50","Convolutional",175,"ResNet50-SimCLR","ResNet50-SimCLR, a self-supervised representation learner trained on ImageNet.",37562880,23508032,"wrsa",0.699473263615655,NA,NA,NA,NA,NA,NA,NA,"SimCLR","Contrastive",NA
"BiT-Expert-ResNet-V2-Mammal_bit_expert","BiT-Expert-ResNet-V2-Mammal","bit_expert","big_transfer","ResNet50-V2","Convolutional",168,"BiT-Expert-ResNet-V2-Mammal","ResNet50-V2 trained first via ImageNet21K dataset, then as an expert on the Mammal subset.",35578624,23496256,"wrsa",0.699517243036545,NA,NA,NA,NA,NA,"Mammal",NA,NA,NA,NA
"swin_large_patch4_window7_224_in22k_classification","swin_large_patch4_window7_224_in22k","classification","imagenet21k","swin_large_patch4_window7_224","Transformer",NA,"Swin-L-P4-W7-IN21K","Swin-L-P4-W7-IN21K trained on image classification with the ImageNet21K dataset.",NA,NA,"wrsa",0.700238621225425,NA,NA,NA,NA,NA,NA,NA,NA,NA,"imagenet21k"
"swin_base_patch4_window7_224_in22k_classification","swin_base_patch4_window7_224_in22k","classification","imagenet21k","swin_base_patch4_window7_224","Transformer",NA,"Swin-B-P4-W7-IN21K","Swin-B-P4-W7-IN21K trained on image classification with the ImageNet21K dataset.",NA,NA,"wrsa",0.70031979735078,NA,NA,NA,NA,NA,NA,NA,NA,NA,"imagenet21k"
"BiT-Expert-ResNet-V2-Abstraction_bit_expert","BiT-Expert-ResNet-V2-Abstraction","bit_expert","big_transfer","ResNet50-V2","Convolutional",168,"BiT-Expert-ResNet-V2-Abstraction","ResNet50-V2 trained first via ImageNet21K dataset, then as an expert on the Abstraction subset.",35578624,23496256,"wrsa",0.701331421163162,NA,NA,NA,NA,NA,"Abstraction",NA,NA,NA,NA
"ViT-L-SLIP_slip","ViT-L-SLIP","slip","YFCC15M","ViT-L","Transformer",441,"ViT-L-SLIP","ViT-L-SLIP trained via combined self- and language supervision with the YFCC15M dataset.",151473536,303098880,"wrsa",0.701492489172923,NA,NA,"SLIP",NA,NA,NA,NA,NA,NA,NA
"convnext_base_in22k_classification","convnext_base_in22k","classification","imagenet21k","convnext_base","Convolutional",382,"ConvNext-Base-IN21K","ConvNext-Base-IN21K trained on image classification with the ImageNet21K dataset.",91771554,109935441,"wrsa",0.702359390195972,NA,NA,NA,NA,NA,NA,NA,NA,NA,"imagenet21k"
"ViT-L/14_clip","ViT-L/14","clip","openai400M","ViT-L/14","Transformer",173,"CLiP-ViT-L/14","CLiP-ViT-L/14, a hybrid vision-language model.",82898688,202153984,"wrsa",0.703746286411152,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"RegNet-32Gf-SEER_seer","RegNet-32Gf-SEER","seer","random1B","RegNet-32Gf","Convolutional",NA,"RegNet-32Gf-SEER","RegNet-32Gf trained via large-scale self-supervision on 1 billion images.",NA,NA,"wrsa",0.704536060575759,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"resmlp_big_24_224_in22ft1k_classification","resmlp_big_24_224_in22ft1k","classification","imagenet21k","resmlp_big_24_224","MLP-Mixer",294,"ResMLP-Big-24-IN21K","ResMLP-Big-24-IN21K trained on image classification with the ImageNet21K dataset.",305874896,129026152,"wrsa",0.704889655525824,NA,NA,NA,NA,NA,NA,NA,NA,NA,"imagenet21k"
"convnext_large_in22k_classification","convnext_large_in22k","classification","imagenet21k","convnext_large","Convolutional",382,"ConvNext-Large-IN21K","ConvNext-Large-IN21K trained on image classification with the ImageNet21K dataset.",137635490,229772881,"wrsa",0.705726131133814,NA,NA,NA,NA,NA,NA,NA,NA,NA,"imagenet21k"
"ViT-B-SLIP_slip","ViT-B-SLIP","slip","YFCC15M","ViT-B","Transformer",225,"ViT-B-SLIP","ViT-B-SLIP trained via combined self- and language supervision with the YFCC15M dataset.",57181200,85646592,"wrsa",0.70639757295833,NA,NA,"SLIP",NA,NA,NA,NA,NA,NA,NA
"ViT-B/16_clip","ViT-B/16","clip","openai400M","ViT-B/16","Transformer",89,"CLiP-ViT-B/32","CLiP-ViT-B/32, a hybrid vision-language model.",24056576,57298944,"wrsa",0.708478547506492,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"ViT-B/32_clip","ViT-B/32","clip","openai400M","ViT-B/32","Transformer",89,"CLiP-ViT-B/32","CLiP-ViT-B/32, a hybrid vision-language model.",6106112,59068416,"wrsa",0.709119710775104,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"RegNet-128Gf-SEER_seer","RegNet-128Gf-SEER","seer","random1B","RegNet-128Gf","Convolutional",NA,"RegNet-128Gf-SEER","RegNet-128Gf trained via large-scale self-supervision on 1 billion images.",NA,NA,"wrsa",0.710837143560364,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"RegNet-64Gf-SEER_seer","RegNet-64Gf-SEER","seer","random1B","RegNet-64Gf","Convolutional",NA,"RegNet-64Gf-SEER","RegNet-64Gf trained via large-scale self-supervision on 1 billion images.",NA,NA,"wrsa",0.711955047776726,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"RN101_clip","RN101","clip","openai400M","ResNet101","Convolutional",387,"CLiP-ResNet101","CLiP-ResNet101, a hybrid vision-language model.",63097344,42519392,"wrsa",0.714726451660284,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
"RN50_clip","RN50","clip","openai400M","ResNet50","Convolutional",200,"CLiP-ResNet50","CLiP-ResNet50, a hybrid vision-language model.",43479552,23527264,"wrsa",0.717295340720887,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
