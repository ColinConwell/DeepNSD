{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7166eedf-83ea-4b1f-bea0-281fe1ec23cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, pandas as pd\n",
    "sys.path += ['../aux_scripts']\n",
    "\n",
    "from models_to_run import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abb4e77a-cddd-493e-9cbe-912b30742b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_typology = pd.read_csv('../model_opts/model_typology.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "366c62c8-551a-46fd-a3bf-6fd0eff8edf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_contrasts = model_typology.copy()#[['architecture','model','train_type','train_data']]\n",
    "model_contrasts['model_string'] = model_contrasts['model'] + '_' + model_contrasts['train_type']\n",
    "\n",
    "def add_random(model_string):\n",
    "    return model_string.replace('classification','random')\n",
    "\n",
    "model_contrasts = model_contrasts[model_contrasts['model_string'].isin(models_to_run_redux) | \n",
    "                                  model_contrasts['model_string'].isin(map(add_random, models_to_run_redux)) |\n",
    "                                  model_contrasts['model_string'].str.contains('ipcl')]\n",
    "\n",
    "random_list = model_contrasts[model_contrasts['train_type'].isin(['random'])]\n",
    "def compare_training(row):\n",
    "    if row['model'] in random_list.model.to_list():\n",
    "        return row['train_type']\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def compare_architecture(row):\n",
    "    if row['train_data'] != 'imagenet' or row['train_type'] != 'classification':\n",
    "        return None\n",
    "    else:\n",
    "        return row['model_class']\n",
    "    \n",
    "def compare_goal_slip(row):\n",
    "    if row['model_source'] != 'slip':\n",
    "        return None\n",
    "    elif 'CC12M' in row['model']:\n",
    "        return None\n",
    "    else:\n",
    "        return row['model'].split('-')[2]\n",
    "    \n",
    "def compare_goal_taskonomy_tasks(row):\n",
    "    if row['model_source'] != 'taskonomy':\n",
    "        return None\n",
    "    else:\n",
    "        return row['model']\n",
    "    \n",
    "def compare_goal_taskonomy_cluster(row):\n",
    "    if row['model_source'] != 'taskonomy':\n",
    "        return None\n",
    "    else:\n",
    "        return row['task_cluster']\n",
    "\n",
    "def compare_goal_expertise(row):\n",
    "    if row['model_source'] != 'bit_expert':\n",
    "        return None\n",
    "    else:\n",
    "        return row['model'].split('-')[-1]\n",
    "    \n",
    "def compare_diet_ipcl(row):\n",
    "    if row['model_source'] != 'open_ipcl':\n",
    "        return None\n",
    "    else:\n",
    "        return row['train_data']\n",
    "    \n",
    "def compare_goal_selfsupervised(row):\n",
    "    if (row['model_source'] == 'vissl' and row['architecture'] == 'ResNet50' \n",
    "        and row['train_data'] == 'imagenet'):\n",
    "        return '-'.join(row['model'].split('-')[1:])\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "contrastive_list = ['PIRL','NPID-4KNegative','SimCLR','MoCoV2-BS256','NPID-32KNegative',\n",
    "                   'SwAV-BS4096-2x224+6x96','BarlowTwins-BS2048','DeepClusterV2-2x224+6x96']\n",
    "\n",
    "def compare_goal_contrastive(row):\n",
    "    if (row['model_source'] == 'vissl' and row['architecture'] == 'ResNet50' \n",
    "        and row['train_data'] == 'imagenet'):\n",
    "        model = '-'.join(row['model'].split('-')[1:])\n",
    "        return 'Contrastive' if model in contrastive_list else 'Non-Contrastive'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "imagenet21k_list = model_contrasts[model_contrasts['train_data'] == 'imagenet21k']['architecture'].to_list()\n",
    "imagenet21k_list.pop(imagenet21k_list.index('vit_base_r50_s16_224'))\n",
    "def compare_diet_imagenetsize(row):\n",
    "    if row['architecture'] in imagenet21k_list:\n",
    "        return row['train_data']\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "compare_funcs = [key for key,value in locals().items() if 'compare' in key and callable(value)]\n",
    "\n",
    "for compare_func in compare_funcs:\n",
    "    row_func = locals()[compare_func]\n",
    "    model_contrasts[compare_func] = model_contrasts.apply(lambda row: row_func(row), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "232c7d30-0f85-407e-9cba-8109c4636d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classification    65\n",
       "random            65\n",
       "Name: compare_training, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_contrasts.compare_training.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d115d5a5-85ab-46f7-8e53-7cc28cb49c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Convolutional    34\n",
       "Transformer      22\n",
       "MLP-Mixer         6\n",
       "Hybrid            3\n",
       "Name: compare_architecture, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_contrasts.compare_architecture.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c1b776a-eef4-40bc-af93-bc522897adeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimCLR    3\n",
       "CLIP      3\n",
       "SLIP      3\n",
       "Name: compare_goal_slip, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_contrasts.compare_goal_slip.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9abd9363-b623-41fb-abe8-4bfa842a9174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "autoencoding        1\n",
       "keypoints2d         1\n",
       "vanishing_point     1\n",
       "segment_unsup2d     1\n",
       "segment_unsup25d    1\n",
       "segment_semantic    1\n",
       "room_layout         1\n",
       "reshading           1\n",
       "point_matching      1\n",
       "normal              1\n",
       "nonfixated_pose     1\n",
       "keypoints3d         1\n",
       "jigsaw              1\n",
       "class_object        1\n",
       "inpainting          1\n",
       "fixated_pose        1\n",
       "egomotion           1\n",
       "edge_texture        1\n",
       "edge_occlusion      1\n",
       "depth_zbuffer       1\n",
       "depth_euclidean     1\n",
       "denoising           1\n",
       "curvature           1\n",
       "class_scene         1\n",
       "random_weights      1\n",
       "Name: compare_goal_taskonomy_tasks, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_contrasts.compare_goal_taskonomy_tasks.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c950eed8-ebc9-4444-a7de-762e9e6846ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3D           8\n",
       "Geometric    7\n",
       "2D           5\n",
       "Semantic     3\n",
       "Other        1\n",
       "Random       1\n",
       "Name: compare_goal_taskonomy_cluster, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_contrasts.compare_goal_taskonomy_cluster.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "816af31e-9a32-4baf-8f5b-25575115c871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Food           1\n",
       "Vehicle        1\n",
       "Instrument     1\n",
       "Flower         1\n",
       "Animal         1\n",
       "Object         1\n",
       "Bird           1\n",
       "Mammal         1\n",
       "Arthropod      1\n",
       "Relation       1\n",
       "Abstraction    1\n",
       "Name: compare_goal_expertise, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_contrasts.compare_goal_expertise.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6be2c132-defa-4bcf-8829-cd8687dfb132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JigSaw-P100                 1\n",
       "JigSaw-Goyal19              1\n",
       "RotNet                      1\n",
       "ClusterFit-16K-RotNet       1\n",
       "PIRL                        1\n",
       "SimCLR                      1\n",
       "DeepClusterV2-2x224+6x96    1\n",
       "SwAV-BS4096-2x224+6x96      1\n",
       "MoCoV2-BS256                1\n",
       "BarlowTwins-BS2048          1\n",
       "Name: compare_goal_selfsupervised, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_contrasts.compare_goal_selfsupervised.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00cea098-3727-4643-b74b-7cdb5b37aed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Contrastive        6\n",
       "Non-Contrastive    4\n",
       "Name: compare_goal_contrastive, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_contrasts.compare_goal_contrastive.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32f9c419-ca1a-40dd-9ebb-f6f9e4cf2ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "imagenet      1\n",
       "openimages    1\n",
       "places256     1\n",
       "vggface2      1\n",
       "Name: compare_diet_ipcl, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_contrasts.compare_diet_ipcl.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe505847-606b-4b44-a16c-ed3c41cf8f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "imagenet       12\n",
       "imagenet21k    12\n",
       "Name: compare_diet_imagenetsize, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_contrasts.compare_diet_imagenetsize.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8dbaae20-a3db-4762-a8bc-13cd1c7a9fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_contrasts[model_contrasts.architecture.str.contains('50')];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f002c70b-3944-4121-9636-0f6c952abcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_contrasts.to_csv('../model_contrasts.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd04981-a381-4347-8531-6c3a3f875fe7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Synthese",
   "language": "python",
   "name": "synthese"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
